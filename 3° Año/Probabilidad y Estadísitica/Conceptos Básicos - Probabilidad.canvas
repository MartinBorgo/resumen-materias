{
	"nodes":[
		{"type":"text","text":"# C√°lculo de Probabilidad","id":"6404508117cc7eb6","x":593,"y":-525,"width":447,"height":60,"color":"6"},
		{"type":"text","text":"## Probabilidad Emp√≠rica o Frecuencial\n\nLa probabilidad emp√≠rica o frecuencial relativa, se basa en el n√∫mero de veces que ocurre el evento como proporci√≥n del n√∫mero de intentos conocidos.\nEl enfoque emp√≠rico de la probabilidad se basa en la llamada *ley de los grandes n√∫meros*. En la que se afirma que a mayor sea la cantidad de observaciones de un experimento mayor ser√° su precisi√≥n y los c√°lculos ser√°n m√°s precisos.\n\n>[!tldr] Ley de los Grandes N√∫meros\n>En una gran cantidad de intentos, la probabilidad emp√≠rica de un evento se aproximar√° a su probabilidad real.\n","id":"e0f4177ec32ff022","x":-946,"y":-182,"width":373,"height":562},
		{"type":"text","text":"# Variables Aleatorias","id":"d64abf732ab5496f","x":1080,"y":-2071,"width":399,"height":71,"color":"6"},
		{"type":"text","text":"## Variables Aleatorias Discretas\n\nUna variable aleatoria se dice que es discreta si para todos los eventos que forman parte de $x$, solo pueden tomar valores enteros","id":"38fc1d99a7e63691","x":1640,"y":-2740,"width":413,"height":180},
		{"type":"text","text":"## Distribuci√≥n Binomal de Probabilidad\n\nUn experimento se puede considerar binomial si tiene estas cinco caracter√≠sticas:\n1. El experimento consiste en $n$ intentos id√©nticos.\n2. Cada intento resulta en uno de dos resultados. Por falta de un mejor nombre, el resultado uno se llama √©xito, $S$, y el otro se llama fracaso, $F$.\n3. La probabilidad de √©xito en un solo intento es igual a $p$ y es igual de un intento a otro. La probabilidad de fracaso es igual a $(1 ‚àí p) = q$.\n4. Los intentos son independientes.\n5. Estamos interesados en $x$, el n√∫mero de √©xitos observado durante los $n$ intentos, para $x = 0, 1, 2, ..., n$.\n\nEn este tipo de modelos la probabilidad de √©xito se mantiene constante de un intento a otro, es decir, Los intentos son *independientes* unos de otros.\nUn experimento binomial consta de $n$ intentos id√©nticos con probabilidad $p$ de √©xito en cada intento. La probabilidad de $k$ √©xitos en $n$ intentos se determina de la siguiente manera.\n\n$$P(x = k) = C^n_kp^kq^{n-k} = \\frac{n!}{k!(n-k)!}p^kq^{n-k}$$\n Para esta distribuci√≥n de probabilidad la media, varianza y desviaci√≥n est√°ndar se pueden calcular de la siguiente manera\n\n- Media: $\\mu = np$\n- Varianza: $\\sigma^2 = npq$\n- Desviaci√≥n Est√°ndar: $\\sigma = \\sqrt{npq}$\n\n>[!tldr] Regla Pr√°ctica\n> Existe una regla pr√°ctica que nos indica que si el tama√±o muestral es grande con respecto al tama√±o poblacional, en particular si $n \\leq 0.05 \\times N$, entonces el experimento resultante es binomial, si eso resulta falso, entonces el problema se podr√≠a representar mediante un ***modelo hipergeom√©trico***.","id":"6584780310c72eb8","x":2313,"y":-3763,"width":507,"height":1100},
		{"type":"text","text":"## Distribuci√≥n Hipergeom√©trica de Probabilidad\n\nSi el n√∫mero de elementos en la poblaci√≥n es peque√±o con respecto al tama√±o muestral, generalmente cuando $n/N ‚â• 0,5$, la probabilidad de un √©xito para un intento determinado depende de los resultados de intentos precedentes. Entonces, el n√∫mero $x$ de √©xitos sigue lo que se conoce como una distribuci√≥n hipergeom√©trica de probabilidad.\n\nUna poblaci√≥n contiene $M$ √©xitos y $N - M$ fracasos, donde $N$ es el tama√±o de la poblaci√≥n. La probabilidad de exactamente $k$ √©xitos en una muestra aleatoria de tama√±o $n$ es\n\n$$P(x = k) = \\frac{C^M_kC^{N-M}_{n-k}}{C^N_n}$$\nLa media y la varianza de una variable aleatoria hipergeom√©trica son muy semejantes a las de una variable aleatoria binomial con una correcci√≥n para el tama√±o finito de poblaci√≥n:\n\n- Media: $\\mu = n(\\frac{M}{N})$\n- Varianza: $\\sigma^2 = n(\\frac{M}{N})(\\frac{N-M}{N})(\\frac{N-n}{N-1})$\n- Desviaci√≥n Est√°ndar: $\\sigma = \\sqrt{n(\\frac{M}{N})(\\frac{N-M}{N})(\\frac{N-n}{N-1})}$\n\nComo se mencion√≥ en un principio, debido al escaso tama√±o de la poblaci√≥n con respecto al con respecto a la muestra, los resultados de un evento van a depender de los anteriores, lo que significa que los intentos son *dependientes*.","id":"7b97f1a6da9f85a6","x":2267,"y":-2587,"width":600,"height":727},
		{"type":"text","text":" ## Distribuci√≥n de Poisson\n\nOtra variable aleatoria discreta que tiene numerosas aplicaciones pr√°cticas es la variable aleatoria de Poisson. Su distribuci√≥n de probabilidad da un buen modelo para datos que representa el n√∫mero de sucesos de un evento especificado en una unidad determinada de tiempo o espacio.\nSea $\\mu$ el n√∫mero promedio de veces que ocurre un evento en cierto tiempo o espacio. La probabilidad de $k$ sucesos de este evento es:\n\n$$P(x=k) = \\frac{\\mu^ke^{-\\mu}}{k!}$$\n para valores de $k = 0, 1, 2, 3, ...$ La media y desviaci√≥n est√°ndar de la variable aleatoria de Poisson $x$ son:\n\n- Media: $\\mu$\n- Varianza: $\\mu$\n- Desviaci√≥n Est√°ndar: $\\sqrt{\\mu}$\n\nLa distribuci√≥n de probabilidad de Poisson da una aproximaci√≥n sencilla, f√°cil de calcular y precisa a probabilidades binomiales cuando $n$ es grande y $Œº = np$ es peque√±a, de preferencia con $Œº < 7$.","id":"dbe7a093e1c7e4b3","x":1520,"y":-3763,"width":397,"height":786},
		{"type":"text","text":"## Reglas de Conteo\n\nSupongamos que un experimento comprende un gran n√∫mero ùëÅ de resultados posibles y se sabe que todos son igualmente probables. Entonces, cada resultado tiene una probabilidad 1/ùëÅ de ocurrir y la probabilidad de un evento A se puede calcular como:\n\n$$P(A)= \\frac{n_A}{N}$$\n\nDonde $n_A$ es el n√∫mero de resultados o elementos del conjunto A.\n\n#### Regla $m.n$\n\nSupongamos un experimento que se realiza en dos etapas. Si la primera etapa se puede efectuar en ùëö formas y, para cada una de estas, la segunda etapa se puede lograr en $n$ formas, entonces hay $m.n$ formas para efectuar el experimento.\nEn caso de que un experimento se realiza en m√°s de dos pasos, existe una forma extendida de este m√©todo, de la forma:\n\n$$n_1.n_2.n3 ... n_k$$\n\nDonde $n_x$ representa la cantidad de formas de hacer una etapa y $k$ la cantidad de etapas de ese experimento.\n\n#### Factorial de un N√∫mero\n\nEn caso de que se quiera saber la cantidad de formas en la que se puede formar u ordenar un grupo de cosas, en donde las repeticiones son v√°lidas, entonces la cantidad de formas de ordenarlas es de la forma $n!$ donde ***n*** es la cantidad de objetos a agrupar u ordenar.\n\n#### Reglas de Conteo para Permutaciones\n\nEl n√∫mero de formas en que podemos acomodar n objetos distintos, tom√°ndolos una cantidad r a la vez, es:\n\n$$P^n_r = \\frac{n!}{(n-r)!}$$\nComo se seleccionan $r$ objetos, √©ste es un experimento de r-etapas. El primer objeto se puede escoger en $n$ formas, el segundo en (n - 1) formas, el tercero en (n - 2) formas y el r-√©simo en (n - r +1 1) formas.\n\n#### Regla de Conteo para Conmutaciones\n\nEl n√∫mero de combinaciones distintas de $n$ objetos distintos que se pueden formar, tomando $r$ de ellos a un tiempo, es:\n\n$$C^n_r= \\frac{n!}{r!(n-r)} = (^n_r)$$\nEl n√∫mero de combinaciones y el n√∫mero de permutaciones est√°n relacionados:\n\n$$C^n_r = \\frac{P^n_r}{r!}$$\n\nSe puede ver que $C^n_r$ resulta cuando se divide el n√∫mero de permutaciones entre $r!$, el n√∫mero de formas de reacomodar cada grupo distinto de $r$ objetos escogidos de entre el total n.","id":"83115b9942f1d95f","x":1280,"y":-211,"width":540,"height":1691,"color":"2"},
		{"type":"text","text":"## Conceptos a Tener en Cuenta\n\n1. La media en probabilidad tambi√©n es llamada ***esperanza***.","id":"429b094d5e7af96d","x":526,"y":-1040,"width":457,"height":140,"color":"3"},
		{"type":"text","text":"## C√°lculo de Probabilidad Mediante las Operaciones de Conjuntos\n\n\n#### Reglas especiales de la Adicion o Union\n\nDado dos eventos A y B, la probabilidad de su uni√≥n se calcula de la siguiente manera:\n\n$$P(A \\bigcup B) = P(A) + P(B) - P(A \\bigcap B)$$\n\nEn el caso de que A y B sean mutuamente excluyentes o disjuntos, ùë® ‚à© ùë© = ‚àÖ, entonces ùë∑(ùë® ‚à© ùë©) = ùüé y la Regla de la adici√≥n se simplifica, quedando:\n\n$$P(A \\bigcup B) = P(A) + P(B)$$\n\n#### Reglas del Complemento\n\nSea el suceso ùë® y su complemento $ùë®^c$ entonces tenemos que:\n\n1. $$P(A) + P(A^c) = 1$$\n2. $$P(A^c) = 1 - P(A)$$\n\n#### Probabilidad Condicionada\n\nLa probabilidad de un evento A, dado que el evento B ha ocurrido, se denomina probabilidad condicional de A, dado que B ha ocurrido, denotada por ùë∑(ùë®|ùë©). La barra vertical se lee ‚Äúdado‚Äù y los eventos que aparecen a la derecha de la barra son aquellos que se sabe han ocurrido.\n\n>[!tldr] Aclaraci√≥n\n>En este tipo de casos P(A|B) es totalmente diferente a P(B|A).\n\n- La probabilidad condicional del evento A, dado que el evento B ha ocurrido, es: \n\n$$P(A|B)= \\frac{P(A \\bigcap B)}{P(B)}$$\n- La probabilidad condicional del evento B, dado que el evento A ha ocurrido, es:\n\n$$P(A|B)= \\frac{P(A \\bigcap B)}{P(A)}$$\n\n#### Regla General de la Multiplicaci√≥n\n\nLa probabilidad de que dos eventos A y B ocurran cuando el experimento se realiza es:\n\n1. $$P(A \\bigcap B) = P(A).P(B|A)$$\n2. $$P(A \\bigcap B)= P(B).P(A|B)$$\nEn el caso de que A y B sean eventos independientes entonces la regla se simplifica:\n\n$$P(A \\bigcap B)= P(A).P(B)$$","id":"e58feafb7a8371ec","x":760,"y":-211,"width":475,"height":1811},
		{"type":"text","text":"## Probabilidad Subjetiva\n\nDefine la probabilidad de un evento a base del grado de confianza que una persona tiene de que el evento ocurra, teniendo en cuenta toda la evidencia que tiene disponible (experiencia personal, creencias, presentimiento, opiniones, etc.).\nEl mejor ejemplo de este tipo de enfoque es cuando un meteor√≥logo afirma que hay una probabilidad de 0,7 de que llueva ma√±ana.","id":"93e9cccf7f1f46da","x":-946,"y":820,"width":373,"height":380},
		{"type":"text","text":"# Enfoques de la Probabilidad","id":"89fcc2d8f2d5e399","x":-1920,"y":660,"width":496,"height":80,"color":"6"},
		{"type":"text","text":"## Probabilidad Cl√°sica\n\nLa probabilidad cl√°sica parte del supuesto de que los resultados de un experimento son igualmente posibles.\nDe acuerdo con el punto de vista cl√°sico, la probabilidad de un evento que se esta llevando a cabo se calcula dividiendo el numero de resultados favorables entre el numero de posibles resultados.","id":"d31375876a015aa3","x":-946,"y":440,"width":373,"height":300},
		{"type":"text","text":"## C√°lculo de Probabilidad en el uso de eventos Sencillos\n\nLa probabilidad de un evento A es una medida de nuestra creencia de que el evento A ocurrir√°. Una manera pr√°ctica de interpretar esta medida es con el concepto de frecuencia relativa. Recuerde que si un experimento se realiza *n* veces, entonces la frecuencia relativa de un suceso particular, por ejemplo A, es\n\n$$\\text{Frecuencia relativa} = \\frac{Frecuencia}{n}$$\n\nSi hacemos que el n√∫mero *n* de repeticiones del experimento se haga cada vez m√°s grande (n -> $\\infty$), en √∫ltima instancia se genera toda la poblaci√≥n. En √©sta, la frecuencia relativa del evento A se define como la ***probabilidad del evento A***. Esto es:\n\n$$P(A) = \\lim_{n \\to \\infty} \\frac{Frecuencia}{n}$$\n","id":"1f847c830f18e5de","x":260,"y":-211,"width":449,"height":600},
		{"type":"text","text":"# Lenguaje Espec√≠fico\n\n- **Experimento:** El m√©todo mediante el cual se obtienen una observaci√≥n o medici√≥n. Un experimento es aleatorio cuando no se puede predecir el resultado que se va a obtener.\n- **Evento simple:** Es el resultado obtenido de realizar el experimento una √∫nica vez.\n- **Evento:** Es un conjunto de eventos simples, com√∫nmente denotados con letras may√∫sculas.\n- **Eventos Mutuamente Excluyentes:** Dos eventos son mutuamente excluyentes si cuando ocurre uno el otro es imposible que ocurra.\n- **Espacio Muestral:** El conjunto de todos los eventos sencillos de un experimento.","id":"4ffef1e0a56c8fd6","x":-1113,"y":-735,"width":540,"height":480,"color":"1"},
		{"type":"text","text":"# Distribuci√≥n Uniforme\n\nLa variable aleatoria uniforme se emplea para modelar el comportamiento de una variable aleatoria continua cuyos valores est√©n uniformemente distribuidos en un intervalo dado. La forma es rectangular y posee un valor m√≠nimo $a$ y un m√°ximo $b$. La altura de la distribuci√≥n es constante para todos los valores entre $a$ y $b$. La distribuci√≥n queda representada con la siguiente f√≥rmula:\n\n$$f(x) = \\frac{1}{b-a}\\ /\\  a \\leq x \\leq b$$\n\n###### Media\n$$\\mu = \\frac{a+b}{2}$$\n\n###### Desviaci√≥n Est√°ndar\n$$\\sigma = \\sqrt{\\frac{(b-a)^2}{12}}$$","id":"6864476751f96f0e","x":3260,"y":-2223,"width":460,"height":679},
		{"type":"text","text":"## Variables Aleatorias Continuas\n\nUna variable aleatoria se dice que es continua si para todos los eventos que forman parte de $x$, estos pueden tomar valores decimales.\n\nLa distribuci√≥n de probabilidad es creada al distribuir una unidad de probabilidad a lo largo de la recta. La profundidad o densidad de la probabilidad, que var√≠a con $x$, puede ser descrita por una f√≥rmula matem√°tica $f(x)$, llamada **distribuci√≥n continua de probabilidad** o **funci√≥n de densidad** de probabilidad para la variable aleatoria $x$. Si existe dicha funci√≥n $f(x)$ tal que:\n\n1. $f(x) \\geq 0, -\\infty < x < \\infty$  \n2. $\\int_{-\\infty}^{\\infty} f(x)\\ dx = 1$\n3. $P(a \\leq x \\leq b) = \\int_{a}^{b}f(x)\\  dx$ \n\nPara cualesquiera $a$ y $b$, entonces $f(x)$ es la funci√≥n de densidad de probabilidad de la variable aleatoria continua $x$.\n\n### Propiedades de las Distribuciones Continuas\n\n1. El √°rea bajo una distribuci√≥n continua de probabilidad es igual a 1.\n2. La probabilidad de que $x$ caiga en un intervalo particular, por ejemplo, de $a$ hasta $b$, es igual al √°rea bajo la curva entre los dos puntos $a$ y $b$.\n3. $P(x = a) = 0$ para variables aleatorias continuas. Eso quiere decir que $P(x \\geq a) = P(x > a)$ y $P(x \\leq a) = P(x < a)$.\n\n### Media y Varianza en Variables Continuas\n\n**Media o Esperanza**\n$$\\mu = E(x) = \\int_{-\\infty}^{\\infty} x.f(x)\\  dx$$\n\n**Varianza**\n\n$$\\sigma^2 = E[(x_i - \\mu)^2] = \\int_{-\\infty}^{\\infty} (x - \\mu)^2.f(x)\\  dx$$","id":"76506be88f54e525","x":2367,"y":-1723,"width":500,"height":1220},
		{"type":"text","text":"# Distribuci√≥n Exponencial\n\nLa variable aleatoria exponencial se utiliza para modelar variables aleatorias continuas tales como tiempos de espera hasta la ocurrencia de un evento o vidas √∫tiles asociadas con componentes electr√≥nicos. La funci√≥n que representa este tipo de distribuci√≥n es la siguiente:\n\n$$f(x) = \\frac{1}{\\mu}e^{-\\frac{1}{\\mu}x}$$\nEn donde $\\mu$ es el tiempo promedio de espera del problema que estemos realizando.\n\n---\n- Media: $E(x) = \\mu$\n- Varianza: $Var(x) = \\mu^2$\n- Desviaci√≥n Est√°ndar: $\\sigma = \\mu$\n","id":"126930e3c119b310","x":3260,"y":-1393,"width":460,"height":561},
		{"type":"text","text":"# Distribuci√≥n Normal\n\nMuchas variables aleatorias continuas tienen distribuciones de frecuencias en forma de campana. Esta distribuci√≥n queda representada por la siguiente f√≥rmula:\n\n$$f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{-(x - \\mu)^2(2\\sigma^2)}$$\n\n###### Caracter√≠sticas principales de la distribuci√≥n normal\n\n1. Es una distribuci√≥n de probabilidad continua, asint√≥tica al eje abscisas.\n2. Tiene forma de campana y se la suele llamar campana de Gauss.\n3. Sus par√°metros son la media $Œº$ y la desviaci√≥n est√°ndar $œÉ$.\n4. La media $Œº$ localiza el centro de la distribuci√≥n, siendo sim√©trica respecto al eje vertical donde est√° la media.\n5. La desviaci√≥n est√°ndar œÉ determina la forma de la distribuci√≥n.\n6. Una distribuci√≥n normal se distingue de otra distribuci√≥n normal por sus par√°metros. Si las medias y las desviaciones son iguales, entonces las distribuciones normales son iguales.","id":"81231c1e0d5d5e51","x":3260,"y":-703,"width":460,"height":780},
		{"type":"text","text":"## Importante\n\nNo hay que confundir el modelo con la realidad, en situaciones reales la distribuci√≥n de los datos no se ajusta al 100% a ninguna de las distribuciones de variables continuas que se vieron. Pero estas son un buen modelo que permite realizar estimaciones con suficiente precisi√≥n a efectos pr√°cticos, pero que no deja de ser un modelo te√≥rico que no coincide exactamente con la realidad.","id":"9382e573ce297c3f","x":1964,"y":-1040,"width":349,"height":364,"color":"5"},
		{"type":"text","text":"# Reglas de Bayes\n\n### Teorema de la Probabilidad Total\n\nDado un conjunto de eventos $S_1,S_2,S_3 ...,S_k$ que son mutuamente excluyentes y exhaustivos y un evento A, la probabilidad del evento A se puede expresar como:\n\n$$P(A)= P(S_1)P(A|S_1)+P(S_2)P(A|S_2)+ P(S_3)P(A|S_3)... P(S_k)P(A|S_k )$$\n\no pas√°ndolo en limpio nos quedar√≠a la siguiente f√≥rmula:\n\n$$\\sum_{i=1}^k P(S_i)P(A|S_i)$$\n\n### Teorema de Bayes\n\nCon $S_1, S_2, ... , S_k$ representemos $k$ subpoblaciones mutuamente excluyentes y exhaustivas con probabilidades previas $P(S_1), P(S_2), ... , P(S_k)$. Si ocurre un evento A, la\nprobabilidad posterior de Si dada A es la probabilidad condicional\n\n$$P(S_i|A)= \\frac{P(S_i)P(A|S_i)}{\\sum_{j=1}^k P(S_j)P(A|S_j)}$$\n\n>[!caution] Problemas del Teorema de Bayes\n>El teorema de Bayes es aplicable solo a casos en los que se cuenta con datos a priori, es decir, ya se tiene informaci√≥n necesaria para poder aplicar el teorema, de lo contrario este teorema queda con nula validez o aplicaci√≥n efectiva.\n>Adem√°s, el m√©todo de Bayes no permite calcular ni revisar las \"*probabilidades a priori objetivas*\" de la hip√≥tesis, sino las \"*probabilidades a priori subjetivas*\" de dicha hip√≥tesis, la cual es establecida por cada investigador. Es decir, su grado personal de creencia en la veracidad de la hip√≥tesis.","id":"ce75589d8ff3d2ee","x":-460,"y":-1700,"width":720,"height":900,"color":"4"},
		{"type":"text","text":"#### Muestreo Estratificado\n\nA partir de ciertas caracter√≠sticas, se divide a la poblaci√≥n en grupos, llamados estratos, y se extrae una muestra de cada uno, con el fin de garantizar su representatividad.\nEl tama√±o de la muestra extra√≠da de cada estrato puede ser:\n1. igual para todos los estratos.\n2. proporcional al tama√±o del estrato en la poblaci√≥n (el m√°s usado).\n\nUna caracter√≠stica de los estratos es que los elementos dentro de cada uno tienden a ser m√°s similares (homog√©neos) que los elementos entre estratos.","id":"096aca83eaced7ff","x":-2480,"y":-3330,"width":404,"height":454},
		{"type":"text","text":"### Muestreos Probabil√≠sticos\n\nUtilizan alguna forma de selecci√≥n aleatoria de las unidades muestrales. La ventaja es que permiten realizar inferencias, con la desventaja de que son m√°s complejo en su realizaci√≥n.","id":"471f9e7f337d2449","x":-2480,"y":-2706,"width":404,"height":243,"color":"5"},
		{"type":"text","text":"#### Muestreo Aleatorio Simple\n\nSi una muestra de $n$ elementos se selecciona de entre una poblaci√≥n de $N$ elementos, donde cada uno tiene la misma probabilidad de ser elegido, entonces se dice que el muestreo es aleatorio y la muestra resultante es una muestra aleatoria simple. Este tipo de muestreo es muy dif√≠cil de llevar a cabo en la pr√°ctica.","id":"059ecedcbd266d0b","x":-1920,"y":-2996,"width":360,"height":320},
		{"type":"text","text":"#### Muestreo Sist√©mico\n\nUna muestra aleatoria sistem√°tica involucra la selecci√≥n aleatoria de uno de los primeros $k$ elementos de una poblaci√≥n ordenada y luego la selecci√≥n sistem√°tica de cada k-√©simo elemento hasta completar el tama√±o muestral. El valor de $k$ es el resultado de dividir el tama√±o de la poblaci√≥n entre el tama√±o de la muestra $(k = N/n)$.\n\n![[PE-sistemica.png]]","id":"0df376b228a6fb71","x":-1920,"y":-2584,"width":360,"height":688},
		{"type":"text","text":"### Muestreo Multiet√°pico\n\nSe trata de un dise√±o muestral en el cual los elementos del marco muestral son subdivididos en grupos y la muestra es seleccionada en m√°s de una etapa. ***Este muestreo combina los m√©todos vistos anteriormente***.\n\n![[PE-multietapico.png]] ","id":"900521211430d3a3","x":-2480,"y":-2418,"width":404,"height":735,"color":"2"},
		{"id":"42ab07e4e4ce3315","type":"text","text":"## Teorema Central del L√≠mite\n\nSi muestras aleatorias de $n$ observaciones se sacan de una poblaci√≥n ***no normal*** con media finita $\\mu$ y desviaci√≥n est√°ndar $\\sigma$, entonces, cuando ùëõ es grande, la distribuci√≥n de muestreo de la media muestral $\\overline{x}$ est√° distribuida normalmente en forma aproximada, con media ùúá y desviaci√≥n est√°ndar $\\sigma / \\sqrt{n}$. La aproximaci√≥n se hace m√°s precisa cuando ùëõ se hace grande. \n\n>[!note] Nota\n>Este teorema resulta extremadamente √∫til para realizar inferencia estad√≠stica, obviamente no hay que olvidar que este teorema se basa en la distribuci√≥n muestral de la media muestral, y eso no deja de ser un concepto te√≥rico y muy dif√≠cil de poner en pr√°ctica realmente.","x":-4248,"y":-4043,"width":400,"height":603,"color":"4"},
		{"id":"e9b69a7cefcbb5ef","type":"text","text":"## Distribuci√≥n Muestral de la Media Muestral\n\nCuando nosotros tenemos m√∫ltiples muestras de tama√±o $n$ (que sean representativas con respecto a la poblaci√≥n), lo que podemos hacer es crear una distribuci√≥n muestral de los estad√≠sticos que se pueden calcular de esa muestra.\n***La distribuci√≥n muestral de la media muestral***, es una distribuci√≥n creada a partir de todas las medias de las distintas muestras de tama√±o $n$ que se sacaron de una misma poblaci√≥n.","x":-4248,"y":-3263,"width":400,"height":421},
		{"type":"text","text":"#### Muestreo por Conglomerado\n\nSe divide a la poblaci√≥n en conglomerados a partir de los l√≠mites naturales geogr√°ficos o de otra clase. A continuaci√≥n, se seleccionan algunos conglomerados al azar y se toma una muestra de forma aleatoria de elementos de cada conglomerado. Este tipo de muestreo se emplea a menudo para reducir el costo de muestrear una poblaci√≥n dispersa en cierta √°rea geogr√°fica.\n A diferencia de los estratos, los elementos dentro de los conglomerados tienden a ser heterog√©neos entre s√≠.","id":"941ccdd362b87783","x":-2995,"y":-3330,"width":399,"height":438},
		{"type":"text","text":"# M√©todos de Muestreo\n\n#### Razones para realizar un muestreo\n\n1. Establecer contacto con toda la poblaci√≥n requerir√≠a mucho tiempo.\n2. El costo de estudiar todos los elementos de la poblaci√≥n es excesivo.\n3. Es imposible verificar de manera f√≠sica todos los elementos de la poblaci√≥n.\n4. Algunas pruebas son de naturaleza destructiva.\n5. Los resultados de la muestra son adecuados.","id":"c28a47843cfa8893","x":-3500,"y":-2558,"width":387,"height":478,"color":"6"},
		{"type":"text","text":"# Tipos de Muestreo","id":"cb231fc58ebf364b","x":-2960,"y":-2357,"width":329,"height":60},
		{"type":"text","text":"## Conceptos\n\n- **Plan o Dise√±o Muestral**: Es una descripci√≥n detallada de c√≥mo se llevar√° a cabo el proceso de selecci√≥n de una muestra en una investigaci√≥n o estudio. Conocer el plan muestral empleado en una situaci√≥n en particular permite medir la confiabilidad o bondad de las inferencias.\n- **Marco Muestral**: Es una lista de todos los elementos que componen la poblaci√≥n que queremos estudiar y de la cual se extrae la muestra.\n- **Unidad Muestral**: Cada uno de estos elementos presentes en el marco muestral.","id":"0f00cb24fe3d9f78","x":-4140,"y":-2538,"width":456,"height":422,"color":"1"},
		{"id":"dd0ce1dfc2645db1","type":"text","text":"## Distribuci√≥n Muestral de la Proporci√≥n Muestral\n\nPara poblaciones que siguen una distribuci√≥n binomial, podemos realizar una distribuci√≥n muestral de la proporci√≥n muestral.\nLa proporci√≥n de una muestra se calcula de la siguiente manera:\n\n$$\\hat{p} = \\frac{x}{n}$$\n\nEsta proporci√≥n muestral se puede utilizar para estimar la proporci√≥n $p$ de una poblaci√≥n.\nSi $x$ es una variable aleatoria binomial, entonces tiene una distribuci√≥n de probabilidad $P(x)$, con una media $\\mu = np$ y una desviaci√≥n est√°ndar $\\sigma = \\sqrt{npq}$.\nComo $\\hat{p}$ es simplemente el valor de $x$, expresado como proporci√≥n de una muestra. La distribuci√≥n muestral de $\\hat{p}$ es id√©ntica a la distribuci√≥n de probabilidad de $x$, con la diferencia de que existe un cambio de escala, ya que las distribuciones binomiales son con variables discretas.\nSi una muestra aleatoria de $n$ observaciones se selecciona de una poblaci√≥n binomial con par√°metro $p$, entonces la distribuci√≥n muestral de la proporci√≥n muestral $\\hat{p}$ tendr√° una media $p$ y una desviaci√≥n est√°ndar:\n\n$$SE(\\hat{p}) = \\sqrt{\\frac{pq}{n}}$$\n\n>[!note] Nota\n>Cuando el tama√±o muestral $n$ es grande, la distribuci√≥n muestra $\\hat{p}$ puede ser aproximada por una **distribuci√≥n normal**. La aproximaci√≥n ser√° adecuada si ùëõùëù > 5 y ùëõùëû > 5.","x":-3640,"y":-3775,"width":527,"height":933},
		{"id":"c7caf6cf367d11b6","type":"text","text":"## Conceptos\n\n- **Error de Muestreo o Margen de Error**: A la diferencia entre un *estad√≠stico* y el *par√°metro* correspondiente se la denomina ***error de muestreo*** o ***margen de error***. Tambi√©n se lo suele llamar, ***error de estimaci√≥n***. Por Ej.: $\\mu$ = 3,8 y $\\overline{x}$ = 3, entonces el *error de muestreo* es: 3,8 - 3 = 0,8\n- **Error Est√°ndar de la Media**: Se denomina as√≠ a la desviaci√≥n est√°ndar de la distribuci√≥n muestral de la media muestral, y normalmente se lo conoce como error ***est√°ndar de la media***, ya que se refiere a la precisi√≥n de la media muestral como estimador.","x":-4880,"y":-3263,"width":500,"height":421,"color":"1"},
		{"type":"text","text":"### Muestreos no Probabil√≠sticos\n\nNo involucran una selecci√≥n aleatoria de las unidades muestrales, lo que lo vuelve una opci√≥n m√°s econ√≥mica y de f√°cil realizaci√≥n, con la desventaja de que no permiten realizar inferencias acerca de la poblaci√≥n.","id":"3428db25ce142354","x":-2995,"y":-1735,"width":404,"height":243,"color":"5"},
		{"id":"b0c028b5ecf0e70e","type":"text","text":"### Estimaci√≥n Puntual\n\nEn una situaci√≥n pr√°ctica, puede haber varios *estad√≠sticos* que podr√≠an usarse como estimadores puntuales para un par√°metro. Para determinar cu√°l de las opciones es mejor, se necesita saber c√≥mo se comporta el estimador en muestreo repetido, descripto por su distribuci√≥n muestral.\n\n>[!nota] Nota\n>Si lo que se quiere estimar es la media poblacional, el mejor estimador es la media muestral, esto es as√≠ debido al teorema del l√≠mite central\n\n##### Propiedades de un Buen Estimador\n\n1. **Insesgado**: Un estimador es insesgado si la media de su distribuci√≥n muestral es igual al valor del par√°metro, de otra forma se dice que el estimador est√° sesgado.\n2. **Eficiente**: Un estimador es m√°s eficiente que otro estimador, si la varianza de la distribuci√≥n muestral del primer estimador es menor que la del segundo estimador.\n3. **Consistente**: Un estimador es consistente si al aumentar el tama√±o de la muestra, su valor se aproxima cada vez m√°s al valor del par√°metro. Es decir, si a medida que aumenta el tama√±o de la muestra, las estimaciones que el estimador proporciona son cada vez m√°s pr√≥ximas al valor del par√°metro.\n4. **Suficiente**: Un estimador es suficiente si utiliza, para su c√°lculo, toda la informaci√≥n contenida en la muestra.","x":-5660,"y":-1778,"width":480,"height":960},
		{"id":"cc4f435ab64ff69f","type":"text","text":"## M√©todos de Estimaci√≥n\n\nsirven para estimar o predecir el valor del par√°metro. Por ejemplo: estimar la proporci√≥n de pobres de nuestro pa√≠s.","x":-4914,"y":-1465,"width":360,"height":189},
		{"id":"dcb9a54dc9320e8f","type":"text","text":"# Inferencia Estad√≠stica\n\nLa inferencia estad√≠stica es el conjunto de m√©todos y t√©cnicas que permiten inducir, a partir de la informaci√≥n emp√≠rica proporcionada por una muestra, cu√°l es el comportamiento de una determinada poblaci√≥n con un riesgo de error medible en t√©rminos de probabilidad\n\n>[!tldr] Bondad de la Inferencia\n>Un estudio estad√≠stico, que comprende planeaci√≥n, an√°lisis e inferencias, est√° incompleto sin una medida de la bondad de la inferencia. Es decir, qu√© tan preciso o confiable es el m√©todo empleado.","x":-4348,"y":-1499,"width":417,"height":499,"color":"6"},
		{"id":"4d0dc9c91d1fc89b","type":"text","text":"### Intervalos de Confianza\n\nExisten ocasiones en las que lo que se calcula para realizar la inferencia es dos valores. Estos valores van a determinar un intervalo en que, si tomamos una muestra probabil√≠stica, se espera que se encuentre nuestro par√°metro a estimar.\nPara construir este intervalo primero tenemos que asegurar la fiabilidad que va a tener ese intervalo. Recordemos que por el ***teorema central del l√≠mite***, si el tama√±o de la muestra es lo suficientemente grande, la distribuci√≥n muestral de ese *estad√≠stico* se aproximar√° cada vez m√°s a una distribuci√≥n normal, y gracias a eso nosotros podemos asegurar la fiabilidad de nuestro intervalo de confianza.\nNosotros para construir ese intervalo de confianza debemos calcular primero el ***margen de error***, el mismo se calcula de la siguiente manera\n$$ME= z \\cdot SE(\\overline{x})$$\nO en caso de que sea una distribuci√≥n binomial\n$$ME = z \\cdot SE(\\hat{p})$$\n>[!note] Nota\n>En esa ecuaci√≥n $z$ es un valor que se basa en el teorema de Chebyshev, en donde a m√°s grande sea $z$ m√°s fiable ser√° el itervalo.\n\nEn caso de que cuando se est√° realizando el an√°lisis de una determinada muestra y se intenta inferir algo de esta mediante intervalos de confianza, y para el mismo an√°lisis existen varios m√°rgenes de error, en ese caso se toma el margen de error m√°s grande, as√≠ nos aseguramos de que todos los par√°metros que se quieran inferir se encuentren dentro del intervalo.\n\n>[!caution] M√°rgenes de Errores Bajos y Altos\n>Por lo general, a nivel te√≥rico un margen de error mayor al 5% ya es elevado, pero eso solo es tenido en cuenta cuando la informaci√≥n que nosotros calculamos es utilizada para la toma de decisiones cr√≠ticas. Pero en general el considerar a un margen de error elevado o no depende del problema que se est√© analizando o para que se est√©n utilizando","x":-5660,"y":-643,"width":480,"height":1273},
		{"id":"4205fad2bcd5b6c2","type":"text","text":" ### Margen de Error\n\nPara cualquier estimador puntual con una distribuci√≥n normal, el 95% de todas las estimaciones puntuales estar√°n a no m√°s de 2 (exactamente a 1,96) desviaciones est√°ndar de la media de esa distribuci√≥n, esto es as√≠ debido al teorema de Chebyshev.\nPara estimadores ***insesgados***, esto implica que la diferencia entre el estimador puntual y el verdadero valor del par√°metro, es decir, el error muestral ser√°, el 95% de las veces, menor a 1,96 desviaciones est√°ndar o 1,96 errores est√°ndar (SE).\n\n![[PE-margen-error.png]]\n\nEsa cantidad de 1,96 errores est√°ndar (SE), llamada margen de error, da un l√≠mite superior pr√°ctico para el error de estimaci√≥n o error de muestreo. Es posible que el error de estimaci√≥n exceda ese margen de error, pero eso es muy poco probable, de aproximadamente 5% de las veces. Esto quiere decir que tengo un 5% de posibilidades de tomar una muestra aleatoria y que esta no me sirva para inferir ning√∫n par√°metro de la poblaci√≥n. ","x":-6420,"y":-293,"width":564,"height":923,"color":"2"},
		{"id":"bc5992932edff36e","type":"text","text":"## Tipos de Estimadores\n\nPara estimar el valor de un par√°metro poblacional, se puede usar informaci√≥n de una muestra aleatoria en la forma de un **estimador**. Los estimadores son todos los posibles valores que se calculan usando informaci√≥n de las observaciones muestrales y, en consecuencia, por definici√≥n son tambi√©n estad√≠sticos.\nLos estimadores se usan en dos formas diferentes:\n\n- **Estimaci√≥n Puntual**: Con base en datos muestrales, se calcula un solo n√∫mero para estimar el par√°metro poblacional. La regla o f√≥rmula que describe este c√°lculo se denomina estimador puntual y el n√∫mero resultante recibe el nombre de estimaci√≥n puntual.\n- **Estimaci√≥n por Intervalo**: Con base en datos muestrales, se calculan dos n√∫meros para formar un intervalo dentro del cual se espera est√© el par√°metro. La regla o f√≥rmula que describe este c√°lculo se denomina estimador de intervalo y el par de n√∫meros resultantes se llama estimaci√≥n por intervalo o intervalo de confianza.","x":-5011,"y":-938,"width":564,"height":591},
		{"id":"80a7ac923e8aee14","type":"text","text":"## Estimaci√≥n de una Media o Proporci√≥n Poblacional\n\nLa ***variabilidad*** del estimador se mide usando su error est√°ndar (SE) pero como el error est√°ndar depende de par√°metros desconocidos, como $\\sigma$ o $p$, los mismos deben estimarse usando estad√≠sticos muestrales como son $s$ y $\\hat{p}$. Si bien no es correcto, por lo general, los investigadores se refieren al error est√°ndar estimado, es decir, el calculado utilizando los estad√≠sticos como el *error est√°ndar*.\nLo √∫nico que se hace en estos casos es reemplazar los par√°metros presentes en el c√°lculo del error est√°ndar por sus equivalencias en estad√≠sticos.\n\n>[!note] Nota\n>A la hora de calcular el margen de error utilizando estad√≠sticos se debe asegurar que la muestras sean lo suficientemente grandes para poder acercarse lo m√°s posible al par√°metro a estimar.\n\nSolo se debe tener en cuenta que para el caso del margen de error para poblaciones cuantitativas la formula:\n\n$$\\pm 1,96 \\times \\frac{s}{\\sqrt{n}}$$\nsolo se va a poder utilizar si el tama√±o de nuestra muestra $n \\geq 30$. Si la muestra es menor a 30 y conocemos o intuimos que la poblaci√≥n se distribuye de manera normal, entonces podremos calcular el margen de error con la siguiente f√≥rmula:\n\n$$\\pm 2,997 \\times \\frac{s}{\\sqrt{n}}$$\n\nSi no se puede saber si la poblaci√≥n est√° distribuida de manera normal, entonces no se puede usar esta aproximaci√≥n.\nPara el caso de la proporci√≥n poblacional, el estimador $\\hat{p}$ es un estimador insesgado y puede utilizarse para calcular el margen de error con la siguiente f√≥rmula:\n\n$$\\pm 1,96 \\times \\sqrt{\\frac{\\hat{p}\\hat{q}}{n}}$$\n\nEsto es v√°lido siempre y cuando nos aseguremos que $n\\hat{p} \\gt 5$ y $n\\hat{q} \\gt 5$, de lo contrario no se podr√° utilizar ese intervalo de confianza para realizar inferencia.","x":-5011,"y":-236,"width":600,"height":1160,"color":"2"},
		{"id":"ca6d15fb0f694a6d","x":-4151,"y":-848,"width":542,"height":411,"type":"text","text":"## Calcular Tama√±o de la Muestra\n\n La cantidad total de informaci√≥n en una muestra es controlada por dos factores, el ***plan muestral*** y el ***tama√±o de la muestra***, se puede aumentar la cantidad de informaci√≥n recolectada al aumentar el tama√±o muestral o quiz√° al cambiar el tipo de plan muestral que se utilice.\n La cantidad total de informaci√≥n de la muestra afectar√° la **confiabilidad** de las inferencias y es esta confiabilidad se debe especificar. Por otro lado, la precisi√≥n de la estimaci√≥n es medida por el margen de error o el ancho del intervalo de confianza. Como estas dos mediciones dependen del tama√±o muestral, *se debe especificar la precisi√≥n para determinar el tama√±o muestral necesario*.\n\n"},
		{"id":"1323ff90fae04548","x":-4139,"y":-241,"width":519,"height":881,"type":"text","text":"##### Tama√±o de la Muestra para Estimar $p$\n\nEl tama√±o adecuado de la muestra para calcular estimar $p$, va a depender de tres factores:\n\n1. El nivel de confianza deseado.\n2. El margen de error que tolerar√° el investigador.\n3. Una aproximaci√≥n de la proporci√≥n de la poblaci√≥n. Si se desconoce, se toma $p = q = 0,5$.\n\nSi $E$ representa el m√°ximo margen de error con el que queremos trabajar y $z$ el valor correspondiente al nivel de confianza deseado, el tama√±o muestral se obtiene despejando $n$ de la f√≥rmula:\n\n$$z\\sqrt{\\frac{p \\cdot q}{n}} \\leq E$$\n\nUna vez despejada $n$ nos queda la siguiente f√≥rmula:\n\n$$n \\geq \\frac{z^2 \\cdot p \\cdot q}{E^2}$$\n\nPara la estimaci√≥n de la proporci√≥n poblacional, la ***precisi√≥n*** tambi√©n depende del porcentaje de la muestra que elige una respuesta en particular. Por ejemplo, si el 99% de tu muestra dijo \"S√≠\" y el 1% dijo \"No\", la probabilidad de un error es remota, independientemente del tama√±o de la muestra. Sin embargo, si los porcentajes son 51% (S√≠) y 49% (No), el tama√±o de la muestra juega un rol central.\nPara determinar el *margen de error para una respuesta espec√≠fica de la muestra, se puede utilizar el porcentaje de esa respuesta y obtener el error m√°ximo*. En las investigaciones y encuestas es com√∫n optar por el mayor margen de error que se da cuando $p = q = 0,5$.\n\n"},
		{"id":"dc448f85ded7f21b","x":-3426,"y":-907,"width":519,"height":940,"type":"text","text":"##### Tama√±o de la Muestra para Estimar $\\mu$\n\n El tama√±o adecuado de una muestra para estimar $\\mu$ depende de tres factores:\n1. El nivel de confianza deseado.\n2. El margen de error que tolerar√° el investigador.\n3. La variabilidad de la poblaci√≥n que se est√° estudiando.\n\nComo la variabilidad de la poblaci√≥n es desconocida a priori, lo que podemos hacer es establecer tanto el nivel de confianza como el margen de error aceptado por la investigaci√≥n. De esta manera la f√≥rmula para calcular el tama√±o de una muestra es la siguiente:\n\n$$z \\left(\\frac{\\sigma}{\\sqrt{n}}\\right) \\leq E$$\n\nUna vez despejada $n$, nos queda la siguiente ecuaci√≥n:\n\n$$n \\geq \\left( \\frac{z \\cdot \\sigma}{E} \\right)^2$$\n\nDonde $E$ es el m√°ximo margen de error aceptado, $z$ el nivel de confianza utilizado para nuestra muestra y $\\sigma$ la desviaci√≥n est√°ndar poblacional\n\n>[!nota] Estimadores para $\\sigma$\n>Si $\\sigma$ es desconocida, se puede usar la mejor aproximaci√≥n disponible:\n>- Una estimaci√≥n $s$ que se obtiene de una muestra previa.\n>- Una estimaci√≥n a partir del rango basada en el conocimiento de las mediciones m√°ximas y m√≠nimas posibles, es decir, $\\sigma \\cong Rango/4$."},
		{"id":"b5cb68fe721ea135","x":-3426,"y":200,"width":580,"height":1135,"type":"text","text":"### Factor de Correcci√≥n para Poblaci√≥n Finita de Tama√±o $N$\n\nCuando la muestra es grande en comparaci√≥n con la poblaci√≥n, en general cuando $n$ es mayor al 5% de $N$, se hace una correcci√≥n por poblaci√≥n finita. Se multiplica el error est√°ndar por el ***factor de correcci√≥n***:\n\n$$FC = \\frac{N - n}{N - 1}$$\n\nEn qued√°ndonos el Error est√°ndar de la siguiente manera:\n\n$$SE(\\overline{x}) = \\frac{\\sigma}{\\sqrt{n}} \\cdot \\sqrt{\\frac{N - n}{N - 1}}$$\n\nAl corregir el error est√°ndar, la f√≥rmula del margen de error cambia, con lo que la formula para calcular el tama√±o muestral para estimar $\\mu$, se ve afectada:\n\n$$n \\geq \\frac{N \\cdot z^2 \\cdot \\sigma^2}{E^2 \\cdot (N - 1) + z^2 \\cdot \\sigma^2}$$\n\n>[!note] Nota\n>Si bien siempre las poblaciones son finitas, cuando la poblaci√≥n no es grande respecto a la muestra (n/N>0,05), es importante usar esta f√≥rmula para calcular el tama√±o muestral porque la diferencia respecto a la f√≥rmula para poblaciones grandes puede ser considerable.\n\n Algo muy similar ocurre a la hora de calcular el error est√°ndar de la proporci√≥n para muestras mayores al 5% de la poblaci√≥n, en este caso el error est√°ndar nos queda de la siguiente manera:\n\n$$SE(\\hat{p}) = \\sqrt{\\frac{p \\cdot q}{n}} \\cdot \\sqrt{\\frac{N - n}{N - 1}}$$\n\nY al momento de calcular el tama√±o de la muestra para estimar $p$ nos queda la siguiente f√≥rmula:\n\n$$n \\geq \\frac{N \\cdot z^2 \\cdot p \\cdot q}{E^2 \\cdot (N - 1) + z^2 \\cdot p \\cdot q}$$"},
		{"id":"8b2a9feaa093d74e","x":-2680,"y":200,"width":455,"height":346,"color":"2","type":"text","text":"### Aumento del Tama√±o Muestral\n\nEntre mayor sea el tama√±o de la muestra, mayor ser√° la precisi√≥n de las estimaciones. Esto indica que, para un nivel de confianza determinado, entre mayor sea el tama√±o de la muestra, menor ser√° el margen de error o la amplitud del intervalo de confianza. Sin embargo, la relaci√≥n no es proporcional es decir, duplicar el tama√±o de la muestra no reduce a la mitad el margen de error, por lo que muchas veces aumentar el tama√±o de la muestra no es algo tan conveniente."}
	],
	"edges":[
		{"id":"a1f3b1ae03236d75","fromNode":"6404508117cc7eb6","fromSide":"bottom","toNode":"1f847c830f18e5de","toSide":"top","toEnd":"none"},
		{"id":"3d22610f4a9226a8","fromNode":"6404508117cc7eb6","fromSide":"bottom","toNode":"e58feafb7a8371ec","toSide":"top","toEnd":"none"},
		{"id":"d463bf7673ab74e5","fromNode":"6404508117cc7eb6","fromSide":"top","toNode":"ce75589d8ff3d2ee","toSide":"bottom","toEnd":"none","color":"4"},
		{"id":"85291f5ed2eb955a","fromNode":"d31375876a015aa3","fromSide":"right","toNode":"e58feafb7a8371ec","toSide":"left","label":"Formas de Calcular la Probabilidad en este Enfoque"},
		{"id":"042d5d4116fc6519","fromNode":"e0f4177ec32ff022","fromSide":"right","toNode":"1f847c830f18e5de","toSide":"left","label":"Formas de Calcular la Probabilidad en este Enfoque"},
		{"id":"14d12e2d0b766240","fromNode":"89fcc2d8f2d5e399","fromSide":"right","toNode":"e0f4177ec32ff022","toSide":"left","toEnd":"none"},
		{"id":"a2c245df8889ab0f","fromNode":"89fcc2d8f2d5e399","fromSide":"right","toNode":"d31375876a015aa3","toSide":"left","toEnd":"none"},
		{"id":"328608acb6a2c04a","fromNode":"89fcc2d8f2d5e399","fromSide":"right","toNode":"93e9cccf7f1f46da","toSide":"left","toEnd":"none"},
		{"id":"859772d9271834ea","fromNode":"d64abf732ab5496f","fromSide":"right","toNode":"38fc1d99a7e63691","toSide":"left","toEnd":"none"},
		{"id":"d60e7335ee196379","fromNode":"d64abf732ab5496f","fromSide":"right","toNode":"76506be88f54e525","toSide":"left","toEnd":"none"},
		{"id":"31756f9efcd77d41","fromNode":"38fc1d99a7e63691","fromSide":"right","toNode":"6584780310c72eb8","toSide":"left"},
		{"id":"fce0ca99f24c6661","fromNode":"38fc1d99a7e63691","fromSide":"right","toNode":"7b97f1a6da9f85a6","toSide":"left"},
		{"id":"8ce795c3bbfef9df","fromNode":"38fc1d99a7e63691","fromSide":"top","toNode":"dbe7a093e1c7e4b3","toSide":"bottom"},
		{"id":"400040ed2332422c","fromNode":"76506be88f54e525","fromSide":"right","toNode":"6864476751f96f0e","toSide":"left"},
		{"id":"2bc09652f36690b0","fromNode":"76506be88f54e525","fromSide":"right","toNode":"126930e3c119b310","toSide":"left"},
		{"id":"f7027f7f9853d552","fromNode":"76506be88f54e525","fromSide":"right","toNode":"81231c1e0d5d5e51","toSide":"left"},
		{"id":"4699d1325b96d9ab","fromNode":"c28a47843cfa8893","fromSide":"right","toNode":"cb231fc58ebf364b","toSide":"left"},
		{"id":"b520e521b3f38d3e","fromNode":"cb231fc58ebf364b","fromSide":"right","toNode":"471f9e7f337d2449","toSide":"left"},
		{"id":"9a9ffd898afebacb","fromNode":"cb231fc58ebf364b","fromSide":"bottom","toNode":"3428db25ce142354","toSide":"top"},
		{"id":"3d5b52b68698819e","fromNode":"471f9e7f337d2449","fromSide":"right","toNode":"059ecedcbd266d0b","toSide":"left"},
		{"id":"087ac6f39664fcc5","fromNode":"471f9e7f337d2449","fromSide":"right","toNode":"0df376b228a6fb71","toSide":"left"},
		{"id":"ff0d70ee5e8e3a84","fromNode":"471f9e7f337d2449","fromSide":"top","toNode":"096aca83eaced7ff","toSide":"bottom"},
		{"id":"e2da6a2b541187f3","fromNode":"471f9e7f337d2449","fromSide":"top","toNode":"941ccdd362b87783","toSide":"bottom"},
		{"id":"71b15cf00c961324","fromNode":"c28a47843cfa8893","fromSide":"top","toNode":"e9b69a7cefcbb5ef","toSide":"bottom"},
		{"id":"cbaae007efca23a3","fromNode":"e9b69a7cefcbb5ef","fromSide":"top","toNode":"42ab07e4e4ce3315","toSide":"bottom"},
		{"id":"beb7a7d1ec7168e0","fromNode":"c28a47843cfa8893","fromSide":"top","toNode":"dd0ce1dfc2645db1","toSide":"bottom"},
		{"id":"05271cdb20ee33c2","fromNode":"dcb9a54dc9320e8f","fromSide":"left","toNode":"cc4f435ab64ff69f","toSide":"right"},
		{"id":"e63d1823032a4ee1","fromNode":"4d0dc9c91d1fc89b","fromSide":"left","toNode":"4205fad2bcd5b6c2","toSide":"right"},
		{"id":"2f5bc3ab8274dffd","fromNode":"4d0dc9c91d1fc89b","fromSide":"right","toNode":"80a7ac923e8aee14","toSide":"left"},
		{"id":"bae5a1434220809e","fromNode":"bc5992932edff36e","fromSide":"left","toNode":"b0c028b5ecf0e70e","toSide":"right"},
		{"id":"ce7355a8cd494b6f","fromNode":"bc5992932edff36e","fromSide":"left","toNode":"4d0dc9c91d1fc89b","toSide":"right"},
		{"id":"ef17b5ae24a620af","fromNode":"cc4f435ab64ff69f","fromSide":"bottom","toNode":"bc5992932edff36e","toSide":"top"},
		{"id":"b0df8014db408a67","fromNode":"ca6d15fb0f694a6d","fromSide":"right","toNode":"dc448f85ded7f21b","toSide":"left"},
		{"id":"f473252c73e6af14","fromNode":"ca6d15fb0f694a6d","fromSide":"bottom","toNode":"1323ff90fae04548","toSide":"top"},
		{"id":"d20815a685477cd0","fromNode":"dcb9a54dc9320e8f","fromSide":"bottom","toNode":"ca6d15fb0f694a6d","toSide":"top"},
		{"id":"ed3a622e3dd471af","fromNode":"dc448f85ded7f21b","fromSide":"bottom","toNode":"b5cb68fe721ea135","toSide":"top"},
		{"id":"198fde2bacf02c32","fromNode":"1323ff90fae04548","fromSide":"right","toNode":"b5cb68fe721ea135","toSide":"left"},
		{"id":"fd70af2bc3dbf257","fromNode":"b5cb68fe721ea135","fromSide":"right","toNode":"8b2a9feaa093d74e","toSide":"left"}
	]
}