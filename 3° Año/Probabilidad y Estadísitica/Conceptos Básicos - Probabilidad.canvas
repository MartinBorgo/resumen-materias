{
	"nodes":[
		{"type":"text","text":"# Variables Aleatorias","id":"d64abf732ab5496f","x":1080,"y":-2071,"width":399,"height":71,"color":"6"},
		{"type":"text","text":"## Variables Aleatorias Discretas\n\nUna variable aleatoria se dice que es discreta si para todos los eventos que forman parte de $x$, solo pueden tomar valores enteros","id":"38fc1d99a7e63691","x":1640,"y":-2740,"width":413,"height":180},
		{"type":"text","text":"## Distribución Binomal de Probabilidad\n\nUn experimento se puede considerar binomial si tiene estas cinco características:\n1. El experimento consiste en $n$ intentos idénticos.\n2. Cada intento resulta en uno de dos resultados. Por falta de un mejor nombre, el resultado uno se llama éxito, $S$, y el otro se llama fracaso, $F$.\n3. La probabilidad de éxito en un solo intento es igual a $p$ y es igual de un intento a otro. La probabilidad de fracaso es igual a $(1 − p) = q$.\n4. Los intentos son independientes.\n5. Estamos interesados en $x$, el número de éxitos observado durante los $n$ intentos, para $x = 0, 1, 2, ..., n$.\n\nEn este tipo de modelos la probabilidad de éxito se mantiene constante de un intento a otro, es decir, Los intentos son *independientes* unos de otros.\nUn experimento binomial consta de $n$ intentos idénticos con probabilidad $p$ de éxito en cada intento. La probabilidad de $k$ éxitos en $n$ intentos se determina de la siguiente manera.\n\n$$P(x = k) = C^n_kp^kq^{n-k} = \\frac{n!}{k!(n-k)!}p^kq^{n-k}$$\n Para esta distribución de probabilidad la media, varianza y desviación estándar se pueden calcular de la siguiente manera\n\n- Media: $\\mu = np$\n- Varianza: $\\sigma^2 = npq$\n- Desviación Estándar: $\\sigma = \\sqrt{npq}$\n\n>[!tldr] Regla Práctica\n> Existe una regla práctica que nos indica que si el tamaño muestral es grande con respecto al tamaño poblacional, en particular si $n \\leq 0.05 \\times N$, entonces el experimento resultante es binomial, si eso resulta falso, entonces el problema se podría representar mediante un ***modelo hipergeométrico***.","id":"6584780310c72eb8","x":2313,"y":-3763,"width":507,"height":1100},
		{"type":"text","text":"## Distribución Hipergeométrica de Probabilidad\n\nSi el número de elementos en la población es pequeño con respecto al tamaño muestral, generalmente cuando $n/N ≥ 0,5$, la probabilidad de un éxito para un intento determinado depende de los resultados de intentos precedentes. Entonces, el número $x$ de éxitos sigue lo que se conoce como una distribución hipergeométrica de probabilidad.\n\nUna población contiene $M$ éxitos y $N - M$ fracasos, donde $N$ es el tamaño de la población. La probabilidad de exactamente $k$ éxitos en una muestra aleatoria de tamaño $n$ es\n\n$$P(x = k) = \\frac{C^M_kC^{N-M}_{n-k}}{C^N_n}$$\nLa media y la varianza de una variable aleatoria hipergeométrica son muy semejantes a las de una variable aleatoria binomial con una corrección para el tamaño finito de población:\n\n- Media: $\\mu = n(\\frac{M}{N})$\n- Varianza: $\\sigma^2 = n(\\frac{M}{N})(\\frac{N-M}{N})(\\frac{N-n}{N-1})$\n- Desviación Estándar: $\\sigma = \\sqrt{n(\\frac{M}{N})(\\frac{N-M}{N})(\\frac{N-n}{N-1})}$\n\nComo se mencionó en un principio, debido al escaso tamaño de la población con respecto al con respecto a la muestra, los resultados de un evento van a depender de los anteriores, lo que significa que los intentos son *dependientes*.","id":"7b97f1a6da9f85a6","x":2267,"y":-2587,"width":600,"height":727},
		{"type":"text","text":" ## Distribución de Poisson\n\nOtra variable aleatoria discreta que tiene numerosas aplicaciones prácticas es la variable aleatoria de Poisson. Su distribución de probabilidad da un buen modelo para datos que representa el número de sucesos de un evento especificado en una unidad determinada de tiempo o espacio.\nSea $\\mu$ el número promedio de veces que ocurre un evento en cierto tiempo o espacio. La probabilidad de $k$ sucesos de este evento es:\n\n$$P(x=k) = \\frac{\\mu^ke^{-\\mu}}{k!}$$\n para valores de $k = 0, 1, 2, 3, ...$ La media y desviación estándar de la variable aleatoria de Poisson $x$ son:\n\n- Media: $\\mu$\n- Varianza: $\\mu$\n- Desviación Estándar: $\\sqrt{\\mu}$\n\nLa distribución de probabilidad de Poisson da una aproximación sencilla, fácil de calcular y precisa a probabilidades binomiales cuando $n$ es grande y $μ = np$ es pequeña, de preferencia con $μ < 7$.","id":"dbe7a093e1c7e4b3","x":1520,"y":-3763,"width":397,"height":786},
		{"type":"text","text":"# Distribución Uniforme\n\nLa variable aleatoria uniforme se emplea para modelar el comportamiento de una variable aleatoria continua cuyos valores estén uniformemente distribuidos en un intervalo dado. La forma es rectangular y posee un valor mínimo $a$ y un máximo $b$. La altura de la distribución es constante para todos los valores entre $a$ y $b$. La distribución queda representada con la siguiente fórmula:\n\n$$f(x) = \\frac{1}{b-a}\\ /\\  a \\leq x \\leq b$$\n\n###### Media\n$$\\mu = \\frac{a+b}{2}$$\n\n###### Desviación Estándar\n$$\\sigma = \\sqrt{\\frac{(b-a)^2}{12}}$$","id":"6864476751f96f0e","x":3260,"y":-2223,"width":460,"height":679},
		{"type":"text","text":"## Variables Aleatorias Continuas\n\nUna variable aleatoria se dice que es continua si para todos los eventos que forman parte de $x$, estos pueden tomar valores decimales.\n\nLa distribución de probabilidad es creada al distribuir una unidad de probabilidad a lo largo de la recta. La profundidad o densidad de la probabilidad, que varía con $x$, puede ser descrita por una fórmula matemática $f(x)$, llamada **distribución continua de probabilidad** o **función de densidad** de probabilidad para la variable aleatoria $x$. Si existe dicha función $f(x)$ tal que:\n\n1. $f(x) \\geq 0, -\\infty < x < \\infty$  \n2. $\\int_{-\\infty}^{\\infty} f(x)\\ dx = 1$\n3. $P(a \\leq x \\leq b) = \\int_{a}^{b}f(x)\\  dx$ \n\nPara cualesquiera $a$ y $b$, entonces $f(x)$ es la función de densidad de probabilidad de la variable aleatoria continua $x$.\n\n### Propiedades de las Distribuciones Continuas\n\n1. El área bajo una distribución continua de probabilidad es igual a 1.\n2. La probabilidad de que $x$ caiga en un intervalo particular, por ejemplo, de $a$ hasta $b$, es igual al área bajo la curva entre los dos puntos $a$ y $b$.\n3. $P(x = a) = 0$ para variables aleatorias continuas. Eso quiere decir que $P(x \\geq a) = P(x > a)$ y $P(x \\leq a) = P(x < a)$.\n\n### Media y Varianza en Variables Continuas\n\n**Media o Esperanza**\n$$\\mu = E(x) = \\int_{-\\infty}^{\\infty} x.f(x)\\  dx$$\n\n**Varianza**\n\n$$\\sigma^2 = E[(x_i - \\mu)^2] = \\int_{-\\infty}^{\\infty} (x - \\mu)^2.f(x)\\  dx$$","id":"76506be88f54e525","x":2367,"y":-1723,"width":500,"height":1220},
		{"type":"text","text":"# Distribución Exponencial\n\nLa variable aleatoria exponencial se utiliza para modelar variables aleatorias continuas tales como tiempos de espera hasta la ocurrencia de un evento o vidas útiles asociadas con componentes electrónicos. La función que representa este tipo de distribución es la siguiente:\n\n$$f(x) = \\frac{1}{\\mu}e^{-\\frac{1}{\\mu}x}$$\nEn donde $\\mu$ es el tiempo promedio de espera del problema que estemos realizando.\n\n---\n- Media: $E(x) = \\mu$\n- Varianza: $Var(x) = \\mu^2$\n- Desviación Estándar: $\\sigma = \\mu$\n","id":"126930e3c119b310","x":3260,"y":-1393,"width":460,"height":561},
		{"type":"text","text":"# Distribución Normal\n\nMuchas variables aleatorias continuas tienen distribuciones de frecuencias en forma de campana. Esta distribución queda representada por la siguiente fórmula:\n\n$$f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{-(x - \\mu)^2(2\\sigma^2)}$$\n\n###### Características principales de la distribución normal\n\n1. Es una distribución de probabilidad continua, asintótica al eje abscisas.\n2. Tiene forma de campana y se la suele llamar campana de Gauss.\n3. Sus parámetros son la media $μ$ y la desviación estándar $σ$.\n4. La media $μ$ localiza el centro de la distribución, siendo simétrica respecto al eje vertical donde está la media.\n5. La desviación estándar σ determina la forma de la distribución.\n6. Una distribución normal se distingue de otra distribución normal por sus parámetros. Si las medias y las desviaciones son iguales, entonces las distribuciones normales son iguales.","id":"81231c1e0d5d5e51","x":3260,"y":-703,"width":460,"height":780},
		{"type":"text","text":"## Importante\n\nNo hay que confundir el modelo con la realidad, en situaciones reales la distribución de los datos no se ajusta al 100% a ninguna de las distribuciones de variables continuas que se vieron. Pero estas son un buen modelo que permite realizar estimaciones con suficiente precisión a efectos prácticos, pero que no deja de ser un modelo teórico que no coincide exactamente con la realidad.","id":"9382e573ce297c3f","x":1964,"y":-1040,"width":349,"height":364,"color":"5"},
		{"id":"4d0dc9c91d1fc89b","type":"text","text":"### Intervalos de Confianza\n\nExisten ocasiones en las que lo que se calcula para realizar la inferencia es dos valores. Estos valores van a determinar un intervalo en que, si tomamos una muestra probabilística, se espera que se encuentre nuestro parámetro a estimar.\nPara construir este intervalo primero tenemos que asegurar la fiabilidad que va a tener ese intervalo. Recordemos que por el ***teorema central del límite***, si el tamaño de la muestra es lo suficientemente grande, la distribución muestral de ese *estadístico* se aproximará cada vez más a una distribución normal, y gracias a eso nosotros podemos asegurar la fiabilidad de nuestro intervalo de confianza.\nNosotros para construir ese intervalo de confianza debemos calcular primero el ***margen de error***, el mismo se calcula de la siguiente manera\n$$ME= z \\cdot SE(\\overline{x})$$\nO en caso de que sea una distribución binomial\n$$ME = z \\cdot SE(\\hat{p})$$\n>[!note] Nota\n>En esa ecuación $z$ es un valor que se basa en el teorema de Chebyshev, en donde a más grande sea $z$ más fiable será el itervalo.\n\nEn caso de que cuando se está realizando el análisis de una determinada muestra y se intenta inferir algo de esta mediante intervalos de confianza, y para el mismo análisis existen varios márgenes de error, en ese caso se toma el margen de error más grande, así nos aseguramos de que todos los parámetros que se quieran inferir se encuentren dentro del intervalo.\n\n>[!caution] Márgenes de Errores Bajos y Altos\n>Por lo general, a nivel teórico un margen de error mayor al 5% ya es elevado, pero eso solo es tenido en cuenta cuando la información que nosotros calculamos es utilizada para la toma de decisiones críticas. Pero en general el considerar a un margen de error elevado o no depende del problema que se esté analizando o para que se estén utilizando","x":-7400,"y":-514,"width":480,"height":1273},
		{"id":"bc5992932edff36e","type":"text","text":"## Tipos de Estimadores\n\nPara estimar el valor de un parámetro poblacional, se puede usar información de una muestra aleatoria en la forma de un **estimador**. Los estimadores son todos los posibles valores que se calculan usando información de las observaciones muestrales y, en consecuencia, por definición son también estadísticos.\nLos estimadores se usan en dos formas diferentes:\n\n- **Estimación Puntual**: Con base en datos muestrales, se calcula un solo número para estimar el parámetro poblacional. La regla o fórmula que describe este cálculo se denomina estimador puntual y el número resultante recibe el nombre de estimación puntual.\n- **Estimación por Intervalo**: Con base en datos muestrales, se calculan dos números para formar un intervalo dentro del cual se espera esté el parámetro. La regla o fórmula que describe este cálculo se denomina estimador de intervalo y el par de números resultantes se llama estimación por intervalo o intervalo de confianza.","x":-6751,"y":-809,"width":564,"height":591},
		{"id":"80a7ac923e8aee14","type":"text","text":"## Estimación de una Media o Proporción Poblacional\n\nLa ***variabilidad*** del estimador se mide usando su error estándar (SE) pero como el error estándar depende de parámetros desconocidos, como $\\sigma$ o $p$, los mismos deben estimarse usando estadísticos muestrales como son $s$ y $\\hat{p}$. Si bien no es correcto, por lo general, los investigadores se refieren al error estándar estimado, es decir, el calculado utilizando los estadísticos como el *error estándar*.\nLo único que se hace en estos casos es reemplazar los parámetros presentes en el cálculo del error estándar por sus equivalencias en estadísticos.\n\n>[!note] Nota\n>A la hora de calcular el margen de error utilizando estadísticos se debe asegurar que la muestras sean lo suficientemente grandes para poder acercarse lo más posible al parámetro a estimar.\n\nSolo se debe tener en cuenta que para el caso del margen de error para poblaciones cuantitativas la formula:\n\n$$\\pm 1,96 \\times \\frac{s}{\\sqrt{n}}$$\nsolo se va a poder utilizar si el tamaño de nuestra muestra $n \\geq 30$. Si la muestra es menor a 30 y conocemos o intuimos que la población se distribuye de manera normal, entonces la población puede asemejarse a una distribución de **T de Strudent** y podremos calcular el margen de error con la siguiente fórmula:\n\n$$\\pm 2,997 \\times \\frac{s}{\\sqrt{n}}$$\n\nSi no se puede saber si la población está distribuida de manera normal, entonces no se puede usar esta aproximación.\nPara el caso de la proporción poblacional, el estimador $\\hat{p}$ es un estimador insesgado y puede utilizarse para calcular el margen de error con la siguiente fórmula:\n\n$$\\pm 1,96 \\times \\sqrt{\\frac{\\hat{p}\\hat{q}}{n}}$$\n\nEsto es válido siempre y cuando nos aseguremos que $n\\hat{p} \\gt 5$ y $n\\hat{q} \\gt 5$, de lo contrario no se podrá utilizar ese intervalo de confianza para realizar inferencia.","x":-6751,"y":-107,"width":600,"height":1176,"color":"2"},
		{"id":"cc4f435ab64ff69f","type":"text","text":"## Métodos de Estimación\n\nsirven para estimar o predecir el valor del parámetro. Por ejemplo: estimar la proporción de pobres de nuestro país.","x":-6649,"y":-1324,"width":360,"height":189},
		{"id":"8b2a9feaa093d74e","type":"text","text":"### Aumento del Tamaño Muestral\n\nEntre mayor sea el tamaño de la muestra, mayor será la precisión de las estimaciones. Esto indica que, para un nivel de confianza determinado, entre mayor sea el tamaño de la muestra, menor será el margen de error o la amplitud del intervalo de confianza. Sin embargo, la relación no es proporcional es decir, duplicar el tamaño de la muestra no reduce a la mitad el margen de error, por lo que muchas veces aumentar el tamaño de la muestra no es algo tan conveniente.","x":-4403,"y":-150,"width":455,"height":346,"color":"2"},
		{"id":"dcb9a54dc9320e8f","type":"text","text":"# Inferencia Estadística\n\nLa inferencia estadística es el conjunto de métodos y técnicas que permiten inducir, a partir de la información empírica proporcionada por una muestra, cuál es el comportamiento de una determinada población con un riesgo de error medible en términos de probabilidad\n\n>[!tldr] Bondad de la Inferencia\n>Un estudio estadístico, que comprende planeación, análisis e inferencias, está incompleto sin una medida de la bondad de la inferencia. Es decir, qué tan preciso o confiable es el método empleado.","x":-6071,"y":-1849,"width":417,"height":499,"color":"6"},
		{"id":"ca6d15fb0f694a6d","type":"text","text":"## Calcular Tamaño de la Muestra\n\n La cantidad total de información en una muestra es controlada por dos factores, el ***plan muestral*** y el ***tamaño de la muestra***, se puede aumentar la cantidad de información recolectada al aumentar el tamaño muestral o quizá al cambiar el tipo de plan muestral que se utilice.\n La cantidad total de información de la muestra afectará la **confiabilidad** de las inferencias y es esta confiabilidad se debe especificar. Por otro lado, la precisión de la estimación es medida por el margen de error o el ancho del intervalo de confianza. Como estas dos mediciones dependen del tamaño muestral, *se debe especificar la precisión para determinar el tamaño muestral necesario*.\n\n","x":-5874,"y":-1198,"width":542,"height":411},
		{"id":"1323ff90fae04548","type":"text","text":"##### Tamaño de la Muestra para Estimar $p$\n\nEl tamaño adecuado de la muestra para calcular estimar $p$, va a depender de tres factores:\n\n1. El nivel de confianza deseado.\n2. El margen de error que tolerará el investigador.\n3. Una aproximación de la proporción de la población. Si se desconoce, se toma $p = q = 0,5$.\n\nSi $E$ representa el máximo margen de error con el que queremos trabajar y $z$ el valor correspondiente al nivel de confianza deseado, el tamaño muestral se obtiene despejando $n$ de la fórmula:\n\n$$z\\sqrt{\\frac{p \\cdot q}{n}} \\leq E$$\n\nUna vez despejada $n$ nos queda la siguiente fórmula:\n\n$$n \\geq \\frac{z^2 \\cdot p \\cdot q}{E^2}$$\n\nPara la estimación de la proporción poblacional, la ***precisión*** también depende del porcentaje de la muestra que elige una respuesta en particular. Por ejemplo, si el 99% de tu muestra dijo \"Sí\" y el 1% dijo \"No\", la probabilidad de un error es remota, independientemente del tamaño de la muestra. Sin embargo, si los porcentajes son 51% (Sí) y 49% (No), el tamaño de la muestra juega un rol central.\nPara determinar el *margen de error para una respuesta específica de la muestra, se puede utilizar el porcentaje de esa respuesta y obtener el error máximo*. En las investigaciones y encuestas es común optar por el mayor margen de error que se da cuando $p = q = 0,5$.\n\n","x":-5862,"y":-591,"width":519,"height":881},
		{"id":"dc448f85ded7f21b","type":"text","text":"##### Tamaño de la Muestra para Estimar $\\mu$\n\n El tamaño adecuado de una muestra para estimar $\\mu$ depende de tres factores:\n1. El nivel de confianza deseado.\n2. El margen de error que tolerará el investigador.\n3. La variabilidad de la población que se está estudiando.\n\nComo la variabilidad de la población es desconocida a priori, lo que podemos hacer es establecer tanto el nivel de confianza como el margen de error aceptado por la investigación. De esta manera la fórmula para calcular el tamaño de una muestra es la siguiente:\n\n$$z \\left(\\frac{\\sigma}{\\sqrt{n}}\\right) \\leq E$$\n\nUna vez despejada $n$, nos queda la siguiente ecuación:\n\n$$n \\geq \\left( \\frac{z \\cdot \\sigma}{E} \\right)^2$$\n\nDonde $E$ es el máximo margen de error aceptado, $z$ el nivel de confianza utilizado para nuestra muestra y $\\sigma$ la desviación estándar poblacional\n\n>[!nota] Estimadores para $\\sigma$\n>Si $\\sigma$ es desconocida, se puede usar la mejor aproximación disponible:\n>- Una estimación $s$ que se obtiene de una muestra previa.\n>- Una estimación a partir del rango basada en el conocimiento de las mediciones máximas y mínimas posibles, es decir, $\\sigma \\cong Rango/4$.","x":-5149,"y":-1257,"width":519,"height":940},
		{"id":"b5cb68fe721ea135","type":"text","text":"### Factor de Corrección para Población Finita de Tamaño $N$\n\nCuando la muestra es grande en comparación con la población, en general cuando $n$ es mayor al 5% de $N$, se hace una corrección por población finita. Se multiplica el error estándar por el ***factor de corrección***:\n\n$$FC = \\frac{N - n}{N - 1}$$\n\nQuedándonos el Error estándar de la siguiente manera:\n\n$$SE(\\overline{x}) = \\frac{\\sigma}{\\sqrt{n}} \\cdot \\sqrt{\\frac{N - n}{N - 1}}$$\n\nAl corregir el error estándar, la fórmula del margen de error cambia, con lo que la formula para calcular el tamaño muestral para estimar $\\mu$, se ve afectada:\n\n$$n \\geq \\frac{N \\cdot z^2 \\cdot \\sigma^2}{E^2 \\cdot (N - 1) + z^2 \\cdot \\sigma^2}$$\n\n Algo muy similar ocurre a la hora de calcular el error estándar de la proporción para muestras mayores al 5% de la población, en este caso el error estándar nos queda de la siguiente manera:\n\n$$SE(\\hat{p}) = \\sqrt{\\frac{p \\cdot q}{n}} \\cdot \\sqrt{\\frac{N - n}{N - 1}}$$\n\nY al momento de calcular el tamaño de la muestra para estimar $p$ nos queda la siguiente fórmula:\n\n$$n \\geq \\frac{N \\cdot z^2 \\cdot p \\cdot q}{E^2 \\cdot (N - 1) + z^2 \\cdot p \\cdot q}$$\n>[!note] Nota\n>Si bien todas las poblaciones son finitas, cuando la población no es grande respecto a la muestra (n/N>0,05), es importante usar esta fórmula para calcular el tamaño muestral porque la diferencia respecto a la fórmula para poblaciones grandes puede ser considerable.","x":-5149,"y":-150,"width":580,"height":1160},
		{"id":"6fa92b34d50cfdac","type":"text","text":"### Intervalo de confianza para la diferencia de dos proporciones poblacionales\n\nUna simple extensión de la estimación de una proporción $p$ es la estimación de la diferencia entre dos proporciones $p_1$ y $p_2$. Estas comparaciones pueden hacerse con la diferencia ($p_1$ − $p_2$) entre muestras aleatorias independientes formadas por $n_1$ y $n_2$ intentos se sacan de poblaciones 1 y 2, respectivamente, donde a continuación se calculan las proporciones muestrales $\\hat{p}_1$ y $\\hat{p}_2$. Cabe recalcar que la mejor estimación a ($p_1 − p_2$) es ($\\hat{p}_1 − \\hat{p}_2$).\nLa distribución muestral de la diferencia entre proporciones muestrales tiene estas propiedades:\n\n1. La media ($\\hat{p}_1 − \\hat{p}_2$) es ($p_1 − p_2$)\n2. El error estándar SE denotado como:\n\n$$SE = \\sqrt{\\frac{p_1 \\cdot q_1}{n_1} + \\frac{p_2 \\cdot q_2}{n_2}} \\cong \\sqrt{\\frac{\\hat{p}_1 \\cdot \\hat{q}_1}{n_1} + \\frac{\\hat{p}_2 \\cdot \\hat{q}_2}{n_2}}$$\n\n3. La distribución muestral de ($\\hat{p}_1 − \\hat{p}_2$) puede ser aproximada por una distribución normal cuando $n_1$ y $n_2$ son grandes.\n\n>[!note] Recordatorio\n>Como la proporción individual puede tomar valores entre 0 y 1, la diferencia entre dos proporciones toma valores entre -1 y 1. Para usar una distribución normal para aproximar la distribución de ($\\hat{p}_1 − \\hat{p}_2$), las distribuciones de $\\hat{p}_1$ y $\\hat{p}_2$ deben ser aproximadamente normales, esto es: $n_1\\hat{p}_1 > 5, n_1\\hat{q}_1 > 5$ y $n_2\\hat{p}_2 > 5, n_2\\hat{q}_2 > 5$.\n\n##### Construcción del Intervalo de Confianza\n\nEl margen de error de nuestro intervalo de confianza estará determinado por la siguiente fórmula:\n\n$$z \\cdot SE(\\hat{p}_1 - \\hat{p}_2)$$\n\nEntonces nuestro intervalo de confianza se obtendrá de la siguiente manera:\n\n$$(\\hat{p}_1 - \\hat{p}_2) \\pm z \\cdot SE(\\hat{p}_1 - \\hat{p}_2)$$\n\n>[!note] Nota\n>Si el intervalo de confianza contiene al 0 nosotros no podemos afirmar que exista ninguna diferencia entre ambas proporciones, ya que el valor real de la proporción puede ser 0 lo que significaría que ambas proporciones son iguales.","x":-8160,"y":-107,"width":564,"height":1320},
		{"id":"4205fad2bcd5b6c2","type":"text","text":" ### Margen de Error\n\nPara cualquier estimador puntual con una distribución normal, el 95% de todas las estimaciones puntuales estarán a no más de 2 (exactamente a 1,96) desviaciones estándar de la media de esa distribución, esto es así debido al teorema de Chebyshev.\nPara estimadores ***insesgados***, esto implica que la diferencia entre el estimador puntual y el verdadero valor del parámetro, es decir, el error muestral será, el 95% de las veces, menor a 1,96 desviaciones estándar o 1,96 errores estándar (SE).\n\n![[PE-margen-error.png]]\n\nEsa cantidad de 1,96 errores estándar (SE), llamada margen de error, da un límite superior práctico para el error de estimación o error de muestreo. Es posible que el error de estimación exceda ese margen de error, pero eso es muy poco probable, de aproximadamente 5% de las veces. Esto quiere decir que tengo un 5% de posibilidades de tomar una muestra aleatoria y que esta no me sirva para inferir ningún parámetro de la población. ","x":-8160,"y":-1080,"width":564,"height":923,"color":"2"},
		{"id":"607df8a5bcbc294f","type":"text","text":"### Lo Esencial de la Prueba\n\nSupongamos que tenemos una prueba de hipótesis donde $H_0$ es $\\mu = k$, donde $k$ es un valor cualquiera, y $H_a$ es $\\mu > k$, para comenzar a realizar el test de hipótesis, primero tomamos una muestra aleatoria, esta muestra debe ser lo suficientemente grande como para que se acerque a una distribución normal por el teorema central de límite, una vez tengamos la muestra calculamos $\\overline{x}$, ya que la media muestral es el mejor estimador de $\\mu$. Si los valores de $\\overline{x}$ son extremadamente grandes implicaría que $\\mu$ es mayor que lo hipotético, en consecuencia se debe rechazar $H_0$.\nEl siguiente problema es definir que es lo ***demasiado grande***, esto se puede definir determinando a la cantidad de desviaciones estándar que se encuentra $\\overline{x}$ de $\\mu_0$.\nEl número de desviaciones estándar de la que se encuentra $\\overline{x}$ de $\\mu_0$ se puede calcular mediante el ***estadístico estandarizado de la prueba***, cuya fórmula es la siguiente\n\n$$z = \\frac{\\overline{x} - \\mu_0}{\\frac{s}{\\sqrt{n}}}$$\n","x":-6135,"y":-3004,"width":481,"height":680,"color":"2"},
		{"id":"b0c028b5ecf0e70e","type":"text","text":"### Estimación Puntual\n\nEn una situación práctica, puede haber varios *estadísticos* que podrían usarse como estimadores puntuales para un parámetro. Para determinar cuál de las opciones es mejor, se necesita saber cómo se comporta el estimador en muestreo repetido, descripto por su distribución muestral.\n\n>[!nota] Nota\n>Si lo que se quiere estimar es la media poblacional, el mejor estimador es la media muestral, esto es así debido al teorema del límite central\n\n##### Propiedades de un Buen Estimador\n\n1. **Insesgado**: Un estimador es insesgado si la media de su distribución muestral es igual al valor del parámetro, de otra forma se dice que el estimador está sesgado.\n2. **Eficiente**: Un estimador es más eficiente que otro estimador, si la varianza de la distribución muestral del primer estimador es menor que la del segundo estimador.\n3. **Consistente**: Un estimador es consistente si al aumentar el tamaño de la muestra, su valor se aproxima cada vez más al valor del parámetro. Es decir, si a medida que aumenta el tamaño de la muestra, las estimaciones que el estimador proporciona son cada vez más próximas al valor del parámetro.\n4. **Suficiente**: Un estimador es suficiente si utiliza, para su cálculo, toda la información contenida en la muestra.","x":-7400,"y":-1544,"width":480,"height":960},
		{"id":"ac894de25150d87e","type":"text","text":"## Prueba de Hipótesis\n\nA diferencia de una estimación por intervalo, donde se construye un intervalo de valores en el que se espera que se encuentre el parámetro de interés, el objetivo de una prueba o test de hipótesis es *tomar decisiones acerca del valor del parámetro*.\nLos ***test*** pueden ser de tipo paramétrico o no paramétrico, según se refieran o no a parámetros de una población.\n\n- Una ***hipótesis paramétrica*** es una afirmación sobre uno o más parámetros. Por ejemplo: El tiempo de respuesta promedio de una aplicación web es de 2 segundos (𝜇 = 2). \n- Una ***hipótesis no paramétrica*** es una afirmación donde no intervienen parámetros. Por ejemplo: Las notas de una asignatura siguen una distribución normal (la variable $X$ = ”nota” se distribuye normalmente).\n\nUna hipótesis estadística no es más que una afirmación que se hace sobre una población y está sujeta a verificación.\n\n#### Partes de una Prueba de Hipótesis\n\n1. **Hipótesis nula**, denotada como $H_0$.\n2. **Hipótesis alternativa**, denotada como $H_1$ o $H_a$.\n3. Estadístico de prueba y su valor p.\n4. Región de rechazo.\n5. Conclusión\n\nCada una de estas partes es única para cada prueba de hipótesis, si cambio algunos de estos componentes, entonces estaría hablando de otra prueba de hipótesis distinta.\n\n>[!note] Sobre la Hipótesis Nula\n>El investigador siempre empieza por suponer que la hipótesis nula $H_0$ es verdadera. Utiliza entonces los datos muestrales para decidir si la evidencia está a favor de 𝐻1 más que de 𝐻0 y saca una de dos conclusiones, rechaza $H_0$ y toma como valida a $H_a$ o no rechazar $H_0$ como verdadera.\n\n Un principio general de la investigación científica es escoger como hipótesis nula (𝐻0) ***siempre la hipótesis más simple capaz de explicar la realidad observada***. La razón es que una hipótesis simple es más fácil de contrastar empíricamente y descubrir sus deficiencias.\n\n>[!caution] Importante a Tener en Cuenta\n>Si la hipótesis nula $𝐻_0$ no se rechaza con base en los datos de la muestra, no es posible concluir que la hipótesis nula sea verdadera. El hecho de no rechazar $𝐻_0$ no prueba que sea verdadera, sino que no contamos con suficiente evidencia para rechazarla. Para probar sin lugar a dudas que la hipótesis nula es verdadera, sería necesario acceder a toda la población.","x":-6840,"y":-3000,"width":540,"height":1460},
		{"id":"7c83d8c89a5f1897","type":"text","text":"### El Valor $p$\n\nEl valor $p$ o nivel de significancia observado, se puede interpretar como la probabilidad de que $\\overline{x}$ de una muestra sea un valor obtenido por casualidad.\nEl valor $p$ representa el ***riesgo real*** de cometer el error de tipo $I$. Por lo general, si el valor $p$ es menor o igual a un nivel de significancia $\\alpha$ que se quiere tener, entonces $H_0$ es rechazada.\n\nNumerosos investigadores usan una “escala de cálculo” para clasificar sus resultados.\n- Si el valor $p$ es menor a .01, $H_0$ se rechaza. Los resultados son altamente significativos.\n- Si el valor $p$ está entre .01 y .05, $H_0$ se rechaza. Los resultados son estadísticamente significativos.\n- Si el valor $p$ está entre .05 y .10, $H_0$ por lo general no se rechaza. Los resultados son sólo tendentes hacia significancia estadística.\n- Si el valor $p$ es mayor a .10, $H_0$ no es rechazada. Los resultados no son estadísticamente significativos.\n\n>[!note] Nota\n>- Cabe aclarar que no existe un nivel de significancia estándar aplicable a cada test de hipótesis, eso va a depender del tipo de problema o situación que se aborde.\n>- El valor crítico de $\\alpha$ es el punto mínimo, dado por un determinado $z$ (estadístico de prueba), con el cual vamos a rechazar la hipótesis nula.","x":-7500,"y":-3520,"width":520,"height":840},
		{"id":"b5d529d891ead585","type":"text","text":"## Valores para $z$ en un intervalo de Confianza\n\n![[PE-tabla-valorz 1.png]]","x":-7400,"y":920,"width":480,"height":401,"color":"5"},
		{"type":"text","text":"# Enfoques de la Probabilidad","id":"89fcc2d8f2d5e399","x":421,"y":2550,"width":496,"height":80,"color":"6"},
		{"type":"text","text":"# Lenguaje Específico\n\n- **Experimento:** El método mediante el cual se obtienen una observación o medición. Un experimento es aleatorio cuando no se puede predecir el resultado que se va a obtener.\n- **Evento simple:** Es el resultado obtenido de realizar el experimento una única vez.\n- **Evento:** Es un conjunto de eventos simples, comúnmente denotados con letras mayúsculas.\n- **Eventos Mutuamente Excluyentes:** Dos eventos son mutuamente excluyentes si cuando ocurre uno el otro es imposible que ocurra.\n- **Espacio Muestral:** El conjunto de todos los eventos sencillos de un experimento.","id":"4ffef1e0a56c8fd6","x":1228,"y":1155,"width":540,"height":480,"color":"1"},
		{"type":"text","text":"## Probabilidad Empírica o Frecuencial\n\nLa probabilidad empírica o frecuencial relativa, se basa en el número de veces que ocurre el evento como proporción del número de intentos conocidos.\nEl enfoque empírico de la probabilidad se basa en la llamada *ley de los grandes números*. En la que se afirma que a mayor sea la cantidad de observaciones de un experimento mayor será su precisión y los cálculos serán más precisos.\n\n>[!tldr] Ley de los Grandes Números\n>En una gran cantidad de intentos, la probabilidad empírica de un evento se aproximará a su probabilidad real.\n","id":"e0f4177ec32ff022","x":1395,"y":1708,"width":405,"height":562},
		{"type":"text","text":"## Probabilidad Clásica\n\nLa probabilidad clásica parte del supuesto de que los resultados de un experimento son igualmente posibles.\nDe acuerdo con el punto de vista clásico, la probabilidad de un evento que se esta llevando a cabo se calcula dividiendo el numero de resultados favorables entre el numero de posibles resultados.","id":"d31375876a015aa3","x":1395,"y":2330,"width":405,"height":300},
		{"type":"text","text":"## Probabilidad Subjetiva\n\nDefine la probabilidad de un evento a base del grado de confianza que una persona tiene de que el evento ocurra, teniendo en cuenta toda la evidencia que tiene disponible (experiencia personal, creencias, presentimiento, opiniones, etc.).\nEl mejor ejemplo de este tipo de enfoque es cuando un meteorólogo afirma que hay una probabilidad de 0,7 de que llueva mañana.","id":"93e9cccf7f1f46da","x":1395,"y":2710,"width":405,"height":330},
		{"type":"text","text":"## Cálculo de Probabilidad en el uso de eventos Sencillos\n\nLa probabilidad de un evento A es una medida de nuestra creencia de que el evento A ocurrirá. Una manera práctica de interpretar esta medida es con el concepto de frecuencia relativa. Recuerde que si un experimento se realiza *n* veces, entonces la frecuencia relativa de un suceso particular, por ejemplo A, es\n\n$$\\text{Frecuencia relativa} = \\frac{Frecuencia}{n}$$\n\nSi hacemos que el número *n* de repeticiones del experimento se haga cada vez más grande (n -> $\\infty$), en última instancia se genera toda la población. En ésta, la frecuencia relativa del evento A se define como la ***probabilidad del evento A***. Esto es:\n\n$$P(A) = \\lim_{n \\to \\infty} \\frac{Frecuencia}{n}$$\n","id":"1f847c830f18e5de","x":2601,"y":1679,"width":449,"height":600},
		{"type":"text","text":"## Conceptos a Tener en Cuenta\n\n1. La media en probabilidad también es llamada ***esperanza***.","id":"429b094d5e7af96d","x":2867,"y":850,"width":457,"height":140,"color":"3"},
		{"type":"text","text":"# Cálculo de Probabilidad","id":"6404508117cc7eb6","x":2934,"y":1365,"width":447,"height":60,"color":"6"},
		{"type":"text","text":"## Cálculo de Probabilidad Mediante las Operaciones de Conjuntos\n\n\n#### Reglas especiales de la Adicion o Union\n\nDado dos eventos A y B, la probabilidad de su unión se calcula de la siguiente manera:\n\n$$P(A \\bigcup B) = P(A) + P(B) - P(A \\bigcap B)$$\n\nEn el caso de que A y B sean mutuamente excluyentes o disjuntos, 𝑨 ∩ 𝑩 = ∅, entonces 𝑷(𝑨 ∩ 𝑩) = 𝟎 y la Regla de la adición se simplifica, quedando:\n\n$$P(A \\bigcup B) = P(A) + P(B)$$\n\n#### Reglas del Complemento\n\nSea el suceso 𝑨 y su complemento $𝑨^c$ entonces tenemos que:\n\n1. $$P(A) + P(A^c) = 1$$\n2. $$P(A^c) = 1 - P(A)$$\n\n#### Probabilidad Condicionada\n\nLa probabilidad de un evento A, dado que el evento B ha ocurrido, se denomina probabilidad condicional de A, dado que B ha ocurrido, denotada por 𝑷(𝑨|𝑩). La barra vertical se lee “dado” y los eventos que aparecen a la derecha de la barra son aquellos que se sabe han ocurrido.\n\n>[!tldr] Aclaración\n>En este tipo de casos P(A|B) es totalmente diferente a P(B|A).\n\n- La probabilidad condicional del evento A, dado que el evento B ha ocurrido, es: \n\n$$P(A|B)= \\frac{P(A \\bigcap B)}{P(B)}$$\n- La probabilidad condicional del evento B, dado que el evento A ha ocurrido, es:\n\n$$P(A|B)= \\frac{P(A \\bigcap B)}{P(A)}$$\n\n#### Regla General de la Multiplicación\n\nLa probabilidad de que dos eventos A y B ocurran cuando el experimento se realiza es:\n\n1. $$P(A \\bigcap B) = P(A).P(B|A)$$\n2. $$P(A \\bigcap B)= P(B).P(A|B)$$\nEn el caso de que A y B sean eventos independientes entonces la regla se simplifica:\n\n$$P(A \\bigcap B)= P(A).P(B)$$","id":"e58feafb7a8371ec","x":3101,"y":1679,"width":475,"height":1811},
		{"type":"text","text":"## Reglas de Conteo\n\nSupongamos que un experimento comprende un gran número 𝑁 de resultados posibles y se sabe que todos son igualmente probables. Entonces, cada resultado tiene una probabilidad 1/𝑁 de ocurrir y la probabilidad de un evento A se puede calcular como:\n\n$$P(A)= \\frac{n_A}{N}$$\n\nDonde $n_A$ es el número de resultados o elementos del conjunto A.\n\n#### Regla $m.n$\n\nSupongamos un experimento que se realiza en dos etapas. Si la primera etapa se puede efectuar en 𝑚 formas y, para cada una de estas, la segunda etapa se puede lograr en $n$ formas, entonces hay $m.n$ formas para efectuar el experimento.\nEn caso de que un experimento se realiza en más de dos pasos, existe una forma extendida de este método, de la forma:\n\n$$n_1.n_2.n3 ... n_k$$\n\nDonde $n_x$ representa la cantidad de formas de hacer una etapa y $k$ la cantidad de etapas de ese experimento.\n\n#### Factorial de un Número\n\nEn caso de que se quiera saber la cantidad de formas en la que se puede formar u ordenar un grupo de cosas, en donde las repeticiones son válidas, entonces la cantidad de formas de ordenarlas es de la forma $n!$ donde ***n*** es la cantidad de objetos a agrupar u ordenar.\n\n#### Reglas de Conteo para Permutaciones\n\nEl número de formas en que podemos acomodar n objetos distintos, tomándolos una cantidad r a la vez, es:\n\n$$P^n_r = \\frac{n!}{(n-r)!}$$\nComo se seleccionan $r$ objetos, éste es un experimento de r-etapas. El primer objeto se puede escoger en $n$ formas, el segundo en (n - 1) formas, el tercero en (n - 2) formas y el r-ésimo en (n - r +1 1) formas.\n\n#### Regla de Conteo para Conmutaciones\n\nEl número de combinaciones distintas de $n$ objetos distintos que se pueden formar, tomando $r$ de ellos a un tiempo, es:\n\n$$C^n_r= \\frac{n!}{r!(n-r)} = (^n_r)$$\nEl número de combinaciones y el número de permutaciones están relacionados:\n\n$$C^n_r = \\frac{P^n_r}{r!}$$\n\nSe puede ver que $C^n_r$ resulta cuando se divide el número de permutaciones entre $r!$, el número de formas de reacomodar cada grupo distinto de $r$ objetos escogidos de entre el total n.","id":"83115b9942f1d95f","x":3621,"y":1679,"width":540,"height":1691,"color":"2"},
		{"type":"text","text":"# Reglas de Bayes\n\n### Teorema de la Probabilidad Total\n\nDado un conjunto de eventos $S_1,S_2,S_3 ...,S_k$ que son mutuamente excluyentes y exhaustivos y un evento A, la probabilidad del evento A se puede expresar como:\n\n$$P(A)= P(S_1)P(A|S_1)+P(S_2)P(A|S_2)+ P(S_3)P(A|S_3)... P(S_k)P(A|S_k )$$\n\no pasándolo en limpio nos quedaría la siguiente fórmula:\n\n$$\\sum_{i=1}^k P(S_i)P(A|S_i)$$\n\n### Teorema de Bayes\n\nCon $S_1, S_2, ... , S_k$ representemos $k$ subpoblaciones mutuamente excluyentes y exhaustivas con probabilidades previas $P(S_1), P(S_2), ... , P(S_k)$. Si ocurre un evento A, la\nprobabilidad posterior de Si dada A es la probabilidad condicional\n\n$$P(S_i|A)= \\frac{P(S_i)P(A|S_i)}{\\sum_{j=1}^k P(S_j)P(A|S_j)}$$\n\n>[!caution] Problemas del Teorema de Bayes\n>El teorema de Bayes es aplicable solo a casos en los que se cuenta con datos a priori, es decir, ya se tiene información necesaria para poder aplicar el teorema, de lo contrario este teorema queda con nula validez o aplicación efectiva.\n>Además, el método de Bayes no permite calcular ni revisar las \"*probabilidades a priori objetivas*\" de la hipótesis, sino las \"*probabilidades a priori subjetivas*\" de dicha hipótesis, la cual es establecida por cada investigador. Es decir, su grado personal de creencia en la veracidad de la hipótesis.","id":"ce75589d8ff3d2ee","x":1881,"y":190,"width":720,"height":900,"color":"4"},
		{"type":"text","text":"#### Muestreo Estratificado\n\nA partir de ciertas características, se divide a la población en grupos, llamados estratos, y se extrae una muestra de cada uno, con el fin de garantizar su representatividad.\nEl tamaño de la muestra extraída de cada estrato puede ser:\n1. igual para todos los estratos.\n2. proporcional al tamaño del estrato en la población (el más usado).\n\nUna característica de los estratos es que los elementos dentro de cada uno tienden a ser más similares (homogéneos) que los elementos entre estratos.","id":"096aca83eaced7ff","x":-1108,"y":-3050,"width":404,"height":454},
		{"type":"text","text":"### Muestreos Probabilísticos\n\nUtilizan alguna forma de selección aleatoria de las unidades muestrales. La ventaja es que permiten realizar inferencias, con la desventaja de que son más complejo en su realización.","id":"471f9e7f337d2449","x":-1108,"y":-2426,"width":404,"height":243,"color":"5"},
		{"type":"text","text":"### Muestreo Multietápico\n\nSe trata de un diseño muestral en el cual los elementos del marco muestral son subdivididos en grupos y la muestra es seleccionada en más de una etapa. ***Este muestreo combina los métodos vistos anteriormente***.\n\n![[PE-multietapico.png]] ","id":"900521211430d3a3","x":-1108,"y":-2138,"width":404,"height":735,"color":"2"},
		{"type":"text","text":"#### Muestreo Aleatorio Simple\n\nSi una muestra de $n$ elementos se selecciona de entre una población de $N$ elementos, donde cada uno tiene la misma probabilidad de ser elegido, entonces se dice que el muestreo es aleatorio y la muestra resultante es una muestra aleatoria simple. Este tipo de muestreo es muy difícil de llevar a cabo en la práctica.","id":"059ecedcbd266d0b","x":-548,"y":-2716,"width":360,"height":320},
		{"type":"text","text":"#### Muestreo Sistémico\n\nUna muestra aleatoria sistemática involucra la selección aleatoria de uno de los primeros $k$ elementos de una población ordenada y luego la selección sistemática de cada k-ésimo elemento hasta completar el tamaño muestral. El valor de $k$ es el resultado de dividir el tamaño de la población entre el tamaño de la muestra $(k = N/n)$.\n\n![[PE-sistemica.png]]","id":"0df376b228a6fb71","x":-548,"y":-2304,"width":360,"height":688},
		{"id":"42ab07e4e4ce3315","type":"text","text":"## Teorema Central del Límite\n\nSi muestras aleatorias de $n$ observaciones se sacan de una población ***no normal*** con media finita $\\mu$ y desviación estándar $\\sigma$, entonces, cuando 𝑛 es grande, la distribución de muestreo de la media muestral $\\overline{x}$ está distribuida normalmente en forma aproximada, con media 𝜇 y desviación estándar $\\sigma / \\sqrt{n}$. La aproximación se hace más precisa cuando 𝑛 se hace grande. \n\n>[!note] Nota\n>Este teorema resulta extremadamente útil para realizar inferencia estadística, obviamente no hay que olvidar que este teorema se basa en la distribución muestral de la media muestral, y eso no deja de ser un concepto teórico y muy difícil de poner en práctica realmente.","x":-2876,"y":-3763,"width":400,"height":603,"color":"4"},
		{"id":"e9b69a7cefcbb5ef","type":"text","text":"## Distribución Muestral de la Media Muestral\n\nCuando nosotros tenemos múltiples muestras de tamaño $n$ (que sean representativas con respecto a la población), lo que podemos hacer es crear una distribución muestral de los estadísticos que se pueden calcular de esa muestra.\n***La distribución muestral de la media muestral***, es una distribución creada a partir de todas las medias de las distintas muestras de tamaño $n$ que se sacaron de una misma población.","x":-2876,"y":-2983,"width":400,"height":421},
		{"type":"text","text":"# Métodos de Muestreo\n\n#### Razones para realizar un muestreo\n\n1. Establecer contacto con toda la población requeriría mucho tiempo.\n2. El costo de estudiar todos los elementos de la población es excesivo.\n3. Es imposible verificar de manera física todos los elementos de la población.\n4. Algunas pruebas son de naturaleza destructiva.\n5. Los resultados de la muestra son adecuados.","id":"c28a47843cfa8893","x":-2128,"y":-2278,"width":387,"height":478,"color":"6"},
		{"type":"text","text":"#### Muestreo por Conglomerado\n\nSe divide a la población en conglomerados a partir de los límites naturales geográficos o de otra clase. A continuación, se seleccionan algunos conglomerados al azar y se toma una muestra de forma aleatoria de elementos de cada conglomerado. Este tipo de muestreo se emplea a menudo para reducir el costo de muestrear una población dispersa en cierta área geográfica.\n A diferencia de los estratos, los elementos dentro de los conglomerados tienden a ser heterogéneos entre sí.","id":"941ccdd362b87783","x":-1623,"y":-3050,"width":399,"height":438},
		{"type":"text","text":"# Tipos de Muestreo","id":"cb231fc58ebf364b","x":-1588,"y":-2077,"width":329,"height":60},
		{"type":"text","text":"## Conceptos\n\n- **Plan o Diseño Muestral**: Es una descripción detallada de cómo se llevará a cabo el proceso de selección de una muestra en una investigación o estudio. Conocer el plan muestral empleado en una situación en particular permite medir la confiabilidad o bondad de las inferencias.\n- **Marco Muestral**: Es una lista de todos los elementos que componen la población que queremos estudiar y de la cual se extrae la muestra.\n- **Unidad Muestral**: Cada uno de estos elementos presentes en el marco muestral.","id":"0f00cb24fe3d9f78","x":-2768,"y":-2258,"width":456,"height":422,"color":"1"},
		{"id":"dd0ce1dfc2645db1","type":"text","text":"## Distribución Muestral de la Proporción Muestral\n\nPara poblaciones que siguen una distribución binomial, podemos realizar una distribución muestral de la proporción muestral.\nLa proporción de una muestra se calcula de la siguiente manera:\n\n$$\\hat{p} = \\frac{x}{n}$$\n\nEsta proporción muestral se puede utilizar para estimar la proporción $p$ de una población.\nSi $x$ es una variable aleatoria binomial, entonces tiene una distribución de probabilidad $P(x)$, con una media $\\mu = np$ y una desviación estándar $\\sigma = \\sqrt{npq}$.\nComo $\\hat{p}$ es simplemente el valor de $x$, expresado como proporción de una muestra. La distribución muestral de $\\hat{p}$ es idéntica a la distribución de probabilidad de $x$, con la diferencia de que existe un cambio de escala, ya que las distribuciones binomiales son con variables discretas.\nSi una muestra aleatoria de $n$ observaciones se selecciona de una población binomial con parámetro $p$, entonces la distribución muestral de la proporción muestral $\\hat{p}$ tendrá una media $p$ y una desviación estándar:\n\n$$SE(\\hat{p}) = \\sqrt{\\frac{pq}{n}}$$\n\n>[!note] Nota\n>Cuando el tamaño muestral $n$ es grande, la distribución muestra $\\hat{p}$ puede ser aproximada por una **distribución normal**. La aproximación será adecuada si 𝑛𝑝 > 5 y 𝑛𝑞 > 5.","x":-2268,"y":-3495,"width":527,"height":933},
		{"type":"text","text":"### Muestreos no Probabilísticos\n\nNo involucran una selección aleatoria de las unidades muestrales, lo que lo vuelve una opción más económica y de fácil realización, con la desventaja de que no permiten realizar inferencias acerca de la población.","id":"3428db25ce142354","x":-1623,"y":-1455,"width":404,"height":243,"color":"5"},
		{"id":"c7caf6cf367d11b6","type":"text","text":"## Conceptos\n\n- **Error de Muestreo o Margen de Error**: A la diferencia entre un *estadístico* y el *parámetro* correspondiente se la denomina ***error de muestreo*** o ***margen de error***. También se lo suele llamar, ***error de estimación***. Por Ej.: $\\mu$ = 3,8 y $\\overline{x}$ = 3, entonces el *error de muestreo* es: 3,8 - 3 = 0,8\n- **Error Estándar de la Media**: Se denomina así a la desviación estándar de la distribución muestral de la media muestral, y normalmente se lo conoce como error ***estándar de la media***, ya que se refiere a la precisión de la media muestral como estimador.","x":-3508,"y":-2983,"width":500,"height":421,"color":"1"},
		{"id":"018c50c5b55e2dd7","type":"text","text":"## Análisis de Correlación Lineal\n\nLa ***covarianza*** es un valor que indica el grado de variación conjunta entre dos variables $𝑥$ e $𝑦$ respecto a sus medias $\\overline{x}$ 𝑥 e $\\overline{y}$, respectivamente.\n\n$$S_{xy} = \\frac{\\sum (x_i - \\overline{x})(y_i - \\overline{y})}{n -1}$$\n\nEl ***coeficiente de correlación lineal***, también llamado ***coeficiente de correlación de Pearson***, mide la fuerza de la relación lineal entre dos variables. Se define como:\n\n$$r = \\frac{S_{xy}}{S_xS_y}$$\n\nDonde $S_x$ y $S_y$ son las desviaciones estándar muestrales para las variables $x$ e $y$.\n\n>[!note] Nota\n>Este coeficiente no puede ser expresado en términos de porcentajes o ser utilizado para otras cosas, solo muestra el grado de ***correlación lineal*** que posee un conjunto de datos.\n\nEl ***coeficiente de determinación*** ($r^2$) determina la calidad del modelo de regresión, es decir, la bondad del ajuste.  Indica la proporción de la variación de los resultados que es explicada por el modelo.\n\n>[!important] Correlación no Implica Causalidad\n>Cuando hay una regresión significativa entre $𝑥$ e $𝑦$, es tentador concluir que $𝑥$ causa a $𝑦$. Pero es posible que una o más variables escondidas, que ni siquiera se hayan medido y que no estén incluidas en el análisis, puedan estar causando la relación observada.","x":-3112,"y":-1040,"width":580,"height":953},
		{"id":"a18f7a07d1f2ccbb","type":"text","text":"## Modelo Probabilístico Lineal Simple\n\nPara construir el modelo población se empieza por suponer que la variable de interés, $y$ está ***linealmente*** relacionada a una variable independiente $x$. Para describir la relación lineal, se puede usar el **modelo determinista**:\n\n$$y = \\alpha + \\beta x$$\n>[!note] Nota\n>Cuando realizamos un gráfico de dispersión, los puntos no están exactamente sobre una recta, sino que parecen ser desviaciones alrededor de una recta. La ecuación se puede corregir sumándole $\\epsilon$ que representaría el error aleatorio para cada valor de x.\n\n","x":-2341,"y":-654,"width":415,"height":567},
		{"id":"46575969191e6d18","type":"text","text":"# Análisis de Regresión y Correlación Lineal\n\nEl objetivo del Análisis de Regresión es crear una ecuación de predicción que exprese $y$ como función de una o más variables independientes.\nSi se pueden medir las variables independientes, se pueden sustituir esos valores en la ecuación de predicción y obtener la predicción para $y$.\nCuando tratamos de construir una función que explique o trate de predecir los valores de $y$, las relaciones se pueden de dar de muchas formas:\n\n- Lineal.\n- Cuadrática.\n- Exponencial.\n- Logarítmica.\n- Cuadrática Invertida.","x":-1841,"y":-494,"width":420,"height":580,"color":"6"},
		{"id":"eab3acd500d5cf4d","type":"text","text":"## El Método de Mínimos cuadrados\n\nEl procedimiento estadístico para hallar la recta de mejor ajuste para un conjunto de datos bivariados hace, matemáticamente, lo que en forma visual se realiza cuando se mueve una recta hasta que se hayan reducido al mínimo las distancias verticales o desviaciones de la recta a un conjunto de puntos. La fórmula de la recta de mejor ajuste es:\n\n$$\\hat{y} = a + bx$$\nDonde $a$ son la estimación del parámetro $\\alpha$ y $b$ es el estimador del parámetro $\\beta$.\n\n#### Principio de Mínimos Cuadrados\n\nLa recta que reduce al mínimo la suma de cuadrados de las desviaciones de los valores observados de $𝑦$ desde los pronosticados es la recta de mejor ajuste. La suma del cuadrado de las desviaciones por lo general se denomina suma de cuadrados de error (SSE) y se define como:\n\n$$SSE = \\sum(y_i - \\hat{y}_i)^2 = \\sum (y_i - a-bx_i)^2$$\n\n>[!important] Importante a Tener en Cuenta\n>Un conjunto de datos pueden tener las mismas estadísticas, pero su dispersión si se realiza de forma gráfica es completamente diferente, el  mejor ejemplo de este es el Cuarteto de Anscombe.\n\nLos valores de $a$ y $b$ pueden ser calculados de la siguiente manera:\n\n$$b =  \\frac{S_{xy}}{S_{xx}}$$\n$$a = \\overline{y} - b\\overline{x}$$\nDonde $S_{xy}$ y $S_{xx}$ se calculan de la siguiente manera:\n\n$$S_{xy} = \\sum (x_i - \\overline{x})(y_i -  \\overline{y})$$\n\n$$S_{xx} = \\sum (x_i - \\overline{x})^2$$\n","x":-2644,"y":86,"width":606,"height":980},
		{"id":"2532cb54dd3a860a","type":"text","text":"## Errores en las Pruebas de Hipótesis\n\nAl momento de realizar las pruebas de hipótesis pueden ocurrir dos tipos de errores muy comunes:\n\n- Error de Tipo $I$: Aceptar $H_0$ como válida, cuando en realidad en falsa.\n- Error de Tipo $II$: No se rechaza $H_0$ cuando esta es falsa, y una de las hipótesis alternativas es verdadera.\n\n![[PS-errores.png]]\n\nLa probabilidad de cometer error de tipo $I$ viene dada por el nivel de significación o significancia, representado por $\\alpha$, el cual es ***fijado de antemano***. Entonces:\n$$𝛼 = P(\\text{Rechazar } 𝐻_0|𝐻_0 \\text{ es verdadera})$$\nLa probabilidad de cometer error de tipo $II$ está representado por $\\beta$.\n$$𝛽 = P(\\text{No rechazar } 𝐻_0|𝐻_0 \\text{ es falsa})$$\nLa probabilidad $1 − \\beta$ se ***llama potencia de la prueba***, que es la probabilidad de rechazar la hipótesis nula cuando es falsa. Entonces:\n\n$$1 − 𝛽 = P(\\text{Rechazar } 𝐻_0|𝐻_0 \\text{ es falsa})$$","x":-7500,"y":-2600,"width":520,"height":820}
	],
	"edges":[
		{"id":"a1f3b1ae03236d75","fromNode":"6404508117cc7eb6","fromSide":"bottom","toNode":"1f847c830f18e5de","toSide":"top","toEnd":"none"},
		{"id":"3d22610f4a9226a8","fromNode":"6404508117cc7eb6","fromSide":"bottom","toNode":"e58feafb7a8371ec","toSide":"top","toEnd":"none"},
		{"id":"d463bf7673ab74e5","fromNode":"6404508117cc7eb6","fromSide":"top","toNode":"ce75589d8ff3d2ee","toSide":"bottom","toEnd":"none","color":"4"},
		{"id":"85291f5ed2eb955a","fromNode":"d31375876a015aa3","fromSide":"right","toNode":"e58feafb7a8371ec","toSide":"left","label":"Formas de Calcular la Probabilidad en este Enfoque"},
		{"id":"042d5d4116fc6519","fromNode":"e0f4177ec32ff022","fromSide":"right","toNode":"1f847c830f18e5de","toSide":"left","label":"Formas de Calcular la Probabilidad en este Enfoque"},
		{"id":"14d12e2d0b766240","fromNode":"89fcc2d8f2d5e399","fromSide":"right","toNode":"e0f4177ec32ff022","toSide":"left","toEnd":"none"},
		{"id":"a2c245df8889ab0f","fromNode":"89fcc2d8f2d5e399","fromSide":"right","toNode":"d31375876a015aa3","toSide":"left","toEnd":"none"},
		{"id":"328608acb6a2c04a","fromNode":"89fcc2d8f2d5e399","fromSide":"right","toNode":"93e9cccf7f1f46da","toSide":"left","toEnd":"none"},
		{"id":"859772d9271834ea","fromNode":"d64abf732ab5496f","fromSide":"right","toNode":"38fc1d99a7e63691","toSide":"left","toEnd":"none"},
		{"id":"d60e7335ee196379","fromNode":"d64abf732ab5496f","fromSide":"right","toNode":"76506be88f54e525","toSide":"left","toEnd":"none"},
		{"id":"31756f9efcd77d41","fromNode":"38fc1d99a7e63691","fromSide":"right","toNode":"6584780310c72eb8","toSide":"left"},
		{"id":"fce0ca99f24c6661","fromNode":"38fc1d99a7e63691","fromSide":"right","toNode":"7b97f1a6da9f85a6","toSide":"left"},
		{"id":"8ce795c3bbfef9df","fromNode":"38fc1d99a7e63691","fromSide":"top","toNode":"dbe7a093e1c7e4b3","toSide":"bottom"},
		{"id":"400040ed2332422c","fromNode":"76506be88f54e525","fromSide":"right","toNode":"6864476751f96f0e","toSide":"left"},
		{"id":"2bc09652f36690b0","fromNode":"76506be88f54e525","fromSide":"right","toNode":"126930e3c119b310","toSide":"left"},
		{"id":"f7027f7f9853d552","fromNode":"76506be88f54e525","fromSide":"right","toNode":"81231c1e0d5d5e51","toSide":"left"},
		{"id":"4699d1325b96d9ab","fromNode":"c28a47843cfa8893","fromSide":"right","toNode":"cb231fc58ebf364b","toSide":"left"},
		{"id":"b520e521b3f38d3e","fromNode":"cb231fc58ebf364b","fromSide":"right","toNode":"471f9e7f337d2449","toSide":"left"},
		{"id":"9a9ffd898afebacb","fromNode":"cb231fc58ebf364b","fromSide":"bottom","toNode":"3428db25ce142354","toSide":"top"},
		{"id":"3d5b52b68698819e","fromNode":"471f9e7f337d2449","fromSide":"right","toNode":"059ecedcbd266d0b","toSide":"left"},
		{"id":"087ac6f39664fcc5","fromNode":"471f9e7f337d2449","fromSide":"right","toNode":"0df376b228a6fb71","toSide":"left"},
		{"id":"ff0d70ee5e8e3a84","fromNode":"471f9e7f337d2449","fromSide":"top","toNode":"096aca83eaced7ff","toSide":"bottom"},
		{"id":"e2da6a2b541187f3","fromNode":"471f9e7f337d2449","fromSide":"top","toNode":"941ccdd362b87783","toSide":"bottom"},
		{"id":"71b15cf00c961324","fromNode":"c28a47843cfa8893","fromSide":"top","toNode":"e9b69a7cefcbb5ef","toSide":"bottom"},
		{"id":"cbaae007efca23a3","fromNode":"e9b69a7cefcbb5ef","fromSide":"top","toNode":"42ab07e4e4ce3315","toSide":"bottom"},
		{"id":"beb7a7d1ec7168e0","fromNode":"c28a47843cfa8893","fromSide":"top","toNode":"dd0ce1dfc2645db1","toSide":"bottom"},
		{"id":"05271cdb20ee33c2","fromNode":"dcb9a54dc9320e8f","fromSide":"left","toNode":"cc4f435ab64ff69f","toSide":"right"},
		{"id":"e63d1823032a4ee1","fromNode":"4d0dc9c91d1fc89b","fromSide":"left","toNode":"4205fad2bcd5b6c2","toSide":"right"},
		{"id":"2f5bc3ab8274dffd","fromNode":"4d0dc9c91d1fc89b","fromSide":"right","toNode":"80a7ac923e8aee14","toSide":"left"},
		{"id":"bae5a1434220809e","fromNode":"bc5992932edff36e","fromSide":"left","toNode":"b0c028b5ecf0e70e","toSide":"right"},
		{"id":"ce7355a8cd494b6f","fromNode":"bc5992932edff36e","fromSide":"left","toNode":"4d0dc9c91d1fc89b","toSide":"right"},
		{"id":"ef17b5ae24a620af","fromNode":"cc4f435ab64ff69f","fromSide":"bottom","toNode":"bc5992932edff36e","toSide":"top"},
		{"id":"b0df8014db408a67","fromNode":"ca6d15fb0f694a6d","fromSide":"right","toNode":"dc448f85ded7f21b","toSide":"left"},
		{"id":"f473252c73e6af14","fromNode":"ca6d15fb0f694a6d","fromSide":"bottom","toNode":"1323ff90fae04548","toSide":"top"},
		{"id":"d20815a685477cd0","fromNode":"dcb9a54dc9320e8f","fromSide":"bottom","toNode":"ca6d15fb0f694a6d","toSide":"top"},
		{"id":"ed3a622e3dd471af","fromNode":"dc448f85ded7f21b","fromSide":"bottom","toNode":"b5cb68fe721ea135","toSide":"top"},
		{"id":"198fde2bacf02c32","fromNode":"1323ff90fae04548","fromSide":"right","toNode":"b5cb68fe721ea135","toSide":"left"},
		{"id":"fd70af2bc3dbf257","fromNode":"b5cb68fe721ea135","fromSide":"right","toNode":"8b2a9feaa093d74e","toSide":"left"},
		{"id":"0f0bb16285367e99","fromNode":"4d0dc9c91d1fc89b","fromSide":"left","toNode":"6fa92b34d50cfdac","toSide":"right"},
		{"id":"f23a2e9c67e40b9e","fromNode":"dcb9a54dc9320e8f","fromSide":"left","toNode":"ac894de25150d87e","toSide":"right"},
		{"id":"77c5612cf8cb04c5","fromNode":"ac894de25150d87e","fromSide":"left","toNode":"2532cb54dd3a860a","toSide":"right"},
		{"id":"8df0b609217c5ecd","fromNode":"ac894de25150d87e","fromSide":"top","toNode":"607df8a5bcbc294f","toSide":"top"},
		{"id":"38cf2c2734e0fec9","fromNode":"ac894de25150d87e","fromSide":"left","toNode":"7c83d8c89a5f1897","toSide":"right"},
		{"id":"f287d1e86a4f4c22","fromNode":"46575969191e6d18","fromSide":"left","toNode":"a18f7a07d1f2ccbb","toSide":"right"},
		{"id":"72808b1d8894bd47","fromNode":"a18f7a07d1f2ccbb","fromSide":"bottom","toNode":"eab3acd500d5cf4d","toSide":"top"},
		{"id":"c4268a643d36612e","fromNode":"4d0dc9c91d1fc89b","fromSide":"bottom","toNode":"b5d529d891ead585","toSide":"top"},
		{"id":"a0e75f735b3eba9f","fromNode":"a18f7a07d1f2ccbb","fromSide":"left","toNode":"018c50c5b55e2dd7","toSide":"right"}
	]
}