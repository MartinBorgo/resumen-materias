La concurrencia es la existencia de varios procesos simultáneos, con alguna relación entre sí, con uno o más procesadores. Por lo que, sé necesita una sincronización para que actúen en conjunto. Si la computadora tiene un solo procesador habrá multiprogramación y *pseudo-paralelismo*.
El paralelismo se da en aquellos equipos con más de un procesador, donde dos procesadores están ejecutando procesos de manera simultánea.

## Problemas de Concurrencia

Si dos o más procesos concurrentes comparten el acceso a un recurso compartido en forma descontrolada, pueden causar que, los datos se vuelvan inconsistentes cuando esos sean actualizados. Esto se puede solucionar, *controlando* o *sincronizando* el acceso a los datos compartidos para asegurar un ordenamiento serial en los procesos a ejecutarse, esto se consigue prohibiendo que más de un proceso lea y escriba datos compartidos al mismo tiempo, a esto se lo denomina ***exclusión mutua***. Aunque aun así, existen muchos otros problemas adicionales que surgen de la concurrencia.

- **Condiciones de Carrera o Competencia (race condition)**: cuando múltiples hilos o procesos leen y escriben un dato compartido y el resultado depende del orden de llegada. Es decir, el valor final depende del orden de ejecución.
- **Postergación indefinida**: Uno o varios procesos nunca reciben el suficiente tiempo de ejecución para terminar con su ejecución.
- **Condición de espera circular**: Ocurre cuando dos o más procesos forman una cadena de espera que los involucra a todos. Supongamos que $P_0$ espera recurso de $P_1$, $P_1$ de $P_n$, y $P_n$ de $P_0$, esto hará que se cree una espera indefinida.
- **Condición de apropiación de recursos**: Si un proceso tiene asignado un recurso, éste no estará disponible para los otros procesos hasta que lo libere el proceso que lo tomó. La liberación siempre es voluntaria por parte del proceso que lo adquirió.
- **Condición de espera ocupada**: Un proceso pide un recurso asignado a otro proceso con condición de apropiación. Por lo que el proceso gastará su quántum en una espera inútil.
- **Condición de exclusión mutua**: Uso exclusivo en el tiempo. Cuando un proceso usa un recurso del sistema, realiza operaciones sobre dicho recurso y luego lo libera. A la sección de código que usa ese recurso se le llama ***región crítica***, permite que en cualquier momento solamente un proceso pueda usar un recurso a la vez.
- **Condición de ocupar y esperar un recurso**: Un proceso pide un recurso y se le asigna. Antes de soltarlo, pide otro recurso que ya ha sido asignado a otro proceso.

Existe un problema con las regiones críticas, y es que si en un sistema se ejecutan varios procesos en cada uno de ellos puede existir una parte de código donde se modifican variables globales, tablas o archivos. Es por eso que es importante asegurar la consistencia de la información y para ello es necesario que no se le permita a ningún otro proceso ejecutarla cuando alguien lo hace. Una solución para este problema es el asegurar que se cumplan los siguientes requerimientos:

1. Exclusión mutua, es decir, solo un proceso debe poder acceder a la región crítica.
2. Continuidad, el hecho de que una vez el proceso utiliza la región crítica, de paso a que otro proceso pueda utilizarlo.
3. Espera limitada, con el fin de que el proceso no se apropie de la región crítica, el proceso tendrá un tiempo asignado para el uso de esta misma.

La estructura general del proceso debe tener una parte previa a la sección crítica donde se requiere permiso para entrar.

## Sincronización

La ***sincronización*** es necesaria, ya que con esta podemos impedir que un proceso acceda a datos compartidos mientras otro proceso está accediendo en ese momento. Debe asegurarse que sólo un proceso esté haciendo algo en un instante determinado y los demás estén excluidos. Los algoritmos para asegurar la exclusión mutua pueden agruparse en:

- **Espera activa**: la espera activa significa que el proceso va a seguir compitiendo por el procesador, pero en caso de que un proceso que esté esperando para acceder a una región crítica y esta se encuentre ocupada por otro proceso, solo gastara todo su quántum en esperar, es decir el procesador tiene tiempo ocioso.
- **Espera no activa**: En este caso los procesos que esperan por una región crítica no van a competir por el procesador, en su lugar van a ser colocados en una cola propia de la región crítica a la que quieren acceder.
- **Mecanismos de Hardware**: esta es el método más antiguo e inadecuado, en este caso cuando un proceso accede a una región crítica se inhabilitan las interrupciones, haciendo que el proceso se apropie del procesador hasta que deje de hacer uso de esa región, una vez este termina se vuelve a habilitar las interrupciones.

#### Algoritmos de Espera Activa

- **Espera con Mutex**: Un Mutex es una estructura de datos que actúa como un semáforo binario que permite a un solo hilo o proceso acceder a una sección crítica de código a la vez. Cuando un hilo o proceso desea acceder a una sección crítica protegida por un Mutex, primero intenta adquirirlo. Si el Mutex está disponible, es decir, no está siendo utilizado por otro hilo o proceso en ese momento, el hilo o proceso adquiere el Mutex y puede ingresar a la sección crítica. De lo contrario, continúa esperando hasta que esté disponible.
- **Alternancia**: Es una mejor del Mutex, ya que, funciona de la misma manera, pero se agrega una variable TURNO para realizar el sincronismo entre procesos.
- **Algoritmo de Dekker**: El algoritmo de Dekker se basa en el uso de variables compartidas y una serie de turnos para controlar qué hilo tiene el acceso a la sección crítica en un determinado momento. El algoritmo consta de 5 turnos:
	1. Cada hilo tiene asociado una variable booleana que indica si está interesado en adquirir los recursos de la sección crítica.
	2. Los hilos se turnan para declarar su interés en adquirir los recursos. Por ejemplo, el hilo 0 puede indicar su interés estableciendo su variable booleana en verdadero, mientras que el hilo 1 espera a que el hilo 0 complete su turno.
	3. Una vez que un hilo indica su interés, entra en un bucle esperando a que sea su turno. El hilo compara su número de turno con el número de turno del otro hilo y solo procede si es su turno.
	4. Una vez que un hilo tiene el turno, verifica si el otro hilo también tiene interés en adquirir los recursos. Si es así, espera a que el otro hilo complete su turno antes de proceder.
	5. Una vez que el hilo ha adquirido los recursos de la sección crítica, realiza sus operaciones y luego cede el turno al otro hilo antes de salir de la sección crítica.

#### Algoritmos de Espera no Activa

- **Semáforo de Dijkstra**: Un semáforo es una variable numérica que se utiliza para controlar el acceso a una sección crítica o para indicar el estado de disponibilidad de un recurso compartido. El algoritmo del semáforo de Dijkstra se utiliza para evitar condiciones de carrera y garantizar la exclusión mutua en el acceso a recursos compartidos. En este algoritmo se utilizan dos operaciones principales:
	1. **Operación "P" (esperar)**: Esta operación decrementa el valor del semáforo. Si el valor resultante es negativo, el hilo o proceso que realiza esta operación se bloquea, lo que significa que entra en un estado de espera pasiva hasta que el valor del semáforo sea mayor o igual a cero.
	2. **Operación "V" (notificar o liberar)**: Esta operación incrementa el valor del semáforo. Si hay otros hilos o procesos bloqueados esperando por este semáforo, uno de ellos se desbloquea y puede continuar su ejecución.
- **Monitor**: Permite compartir datos entre procesos, garantizando la exclusión mutua. No hay necesidad de que el programador tenga que suministrarla. Se reunen todos los datos compartidos por los diferentes procesos en un solo módulo para que los accesos a esos datos estén forzados a utilizar esas funciones.
- **Contador de Eventos**: Es un mecanismo para sincronizar procesos sin que sea necesario forzar a la exclusión mutua. Se basa en una variable entera dedicada a contar determinadas operaciones.
- **Mensajes**: Permite a los procesos, intercambiar la información necesaria durante la ejecución de los mismos. Es más una cooperación que una sincronización. La comunicación es de dos tipos: Directa e Indirecta.
- **Llamadas remotas**: La unión entre el paso de mensajes entre procesos y parámetros a una rutina se llama procedimientos remotos. Cuando estos son ejecutados se crea una copia del mismo y a esto se llama llamadas remotas.
- **Regiones críticas**: establece protecciones contra la mala utilización de los usuarios. Permite acceder a datos compartidos solamente desde determinadas regiones.

#### Mecanismos de Hardware para la Sincronización

- **Pesimistas**: Resuelven la exclusión mutua pero con un costo muy elevado para el sistema. Suponen el peor caso posible y se defienden contra él.
	- **Inhabilitación/Habilitación de interrupciones**: cuando un proceso pide entrar en su región crítica, se inhabilitan las interrupciones. Con esto se asegura que el proceso no será interrumpido por ningún otro proceso. Al terminar de ejecutar la sección crítica se habilitan las interrupciones.
- **Optimistas**: Supone que no habrá conflictos o serán muy pocos. Hay instrucciones que realizan dos acciones atómicamente tales como leer/escribir y leer/examinar y son:
	- **Instrucción TS (Test and Set)**: se basa en que el acceso a posición de memoria excluye el acceso de otros procesos a esa posición de memoria.
	- **Instrucción CS (Compare and Swap)**: propias de máquinas IBM, se utiliza para actualizar una variable. Se realiza una copia de la variable y a posterioridad se verifica el contenido de la variable, si cambió es que entró otro proceso, por lo que se copian nuevamente los datos y si coincide se actualiza la información
	- **Instrucción de intercambio**: intercambia el contenido de un registro con una posición de memoria. Durante la ejecución se bloquea el acceso a esa posición de memoria.

Las ventajas de este tipo de métodos es que funcionan en sistemas con cualquier número de procesos, ya sea mono-procesador o multiprocesador, además de ser simple y fácil de verificar. Con la desventaja que se emplea, la espera activa y puede existir aplazamiento indefinido, ya que cuando un proceso abandona la sección crítica y hay más de un proceso esperando, la selección es arbitraria y se puede negar indefinidamente el procesador a un proceso. Sin mencionar que pueden producirse interbloqueos entre procesos.

## Interbloqueo Entre Procesos

El interbloqueo también es llamado normalmente como Abrazo Mortal, y esto ocurre cuando un conjunto de procesos está en espera por recursos y nunca cambia de estado porque los recursos por los que espera están siendo utilizados por otros procesos en estado de espera.
Hay cuatro condiciones necesarias para que haya interbloqueo, conociéndoles se puede prevenirlos:

1. **Condición de Exclusión Mutua**. Solo un proceso puede acceder a una región crítica a la vez.
2. **Condición de ocupar y esperar un recurso**. Un proceso ha adquirido al menos un recurso y está esperando para adquirir más recursos que son necesarios para completar su tarea
3. **Condición de No apropiación**. Cada proceso tiene un tiempo definido para ocupar un recurso.
4. **Condición de Espera circular**. Ocurre cuando un proceso $P_1$ está esperando algo de un segundo proceso $P_2$ al mismo tiempo que $P_2$ está esperando algo de $P_1$.

Existen varias estrategias que pueden utilizar los sistemas operativos para evitar los interbloqueos:

1. Prevenir y evitar el bloqueo, esta opción es la más costosa porque implica que el sistema operativo realice chequeos constantes a todos los proceso, lo que le quita tiempo de procesador a los procesos de usuario.
2. Detectar y recuperar los bloqueos, este mecanismo hace que el sistema operativo mate a uno de los procesos que está produciendo el interbloqueo y luego lo vuelve a cargar en memoria, para elegir cuál de los procesos bloquear se tiene en cuenta la prioridad, el tiempo de proceso, el tiempo de recurso utilizados, las necesidades de los recursos y la facilidad para suspender y reanudar dicho proceso.
3. Ignorar el problema, no es la más recomendable, ya que se va a estar desperdiciando memoria y se pueden generar más interbloqueos.

Otro caso que puede ser provocada por los interbloqueos es la inanición o espera indefinida de un proceso que espera un recurso que está siendo ocupado por un proceso que está bloqueado.