Las prestaciones que puede ofrecer un ordenador dependen en gran medida de la: 
- Organización.
- Capacidad de almacenamiento.
- Velocidad de acceso a memoria.

### Divicion de Memorias

En un sentido amplio, la memoria de una computadora puede dividirse en tres grupos según la ubicación: 
- Memoria interna al procesador.
- Memoria principal (interna).
	- **DRAM (Dinamica):** Estas memorias semiconductoras se diseñan empleando transistores MOS (Metal Oxido Semiconductor), sin embargo estos transistores van descargándose lentamente. Para evitar la pérdida de información, es necesario refrescar las memorias a intervalos regulares. Las DRAM tienen mas capacidad que las SRAM pero estas ultimas son mas rapidas.
	- **SRAM (Estaticas):** Estas son memorias semiconductoras que estan construida a partir de transistores bipolares. Es poco probable que estas tensiones cambien. Las SRAM tiene mucha mas velocidad que las DRAM pero su capacidad es menor
- Memoria secundaria (externa o masiva).

#### Tiempo de Acceso y Tiempo de Ciclo
Existen dos parámetros básicos que indican la velocidad con que se intercambia información con la memoria:

- **Tiempo de Acceso(Ta):** Es el tiempo medio que se emplea en leer una unidad de información de la memoria.
- **Tiempo de Ciclo(Tc):** Es el tiempo mínimo medio entre dos operaciones sucesivas de lectura.

## Objetivos de los Sistemas de Memoria

Los principales objetivos que deben alcanzarse en el diseño de un sistema de memoria son los siguientes:

1. Debe proporcionar una capacidad de almacenamiento adecuada.
2. El coste por bit debe ser reducido.
3. Los programadores deben ser liberados del tedioso trabajo de realizar tareas de gestión de la memoria (como dividir grandes programas en un conjunto de segmentos menores que quepan en la memoria disponible). 
4. Todos los algoritmos de gestión de la memoria deben diseñarse de forma que den lugar a una utilización eficiente del espacio.

## Direcconamiento en las Memorias

##### Memorias Asociativas
Son memoria direccionable por su contenido, no necesita una dirección física para acceder a los datos. En esta tipo de organización los datos se almacenan según el esquema:

> ![[ARC-memoriaAsi.png]]

El valor de la clave K se compara de forma simultánea con los valores de todas las claves almacenadas en la memoria. Si alguna de ellas coincide, se leen los datos correspondientes.
La información debe mantenerse en un tipo especial de memoria que permita el acceso basado en el contenido al elemento almacenado. Existen siete componentes típicos que componen este tipo de organizacion:

1. **Registro de entrada (B):** Este registro se emplea como buffer. Contiene la información que va a escribirse en la memoria y que se va a buscar.
2. **Registro máscara (M):** Este registro se emplea principalmente para indicarnos cuales de los bits que conforman el dato son partes de la clave y cuales no, es decir, El bit del registro de entrada se utilizará en el proceso de búsqueda sólo si el correspondiente bit del registro mascara es 1. 
3. **Registro de salida (Z):** En este registro se almacenan los datos que se obtienen de la memoria asociativa.
4. **Matriz asociativa:** Se trata de una colección de celdas de memoria básicas organizadas en forma de matriz.
5. **Lógica de comparación:** Se trata de un circuito combinacional cuyo propósito es detectar la correspondencia entre una clave dada k y el valor asociado que se almacena en la matriz.
> ![[ARcMemAsic5.png]]
6. **Registro de coincidencias:** El propósito de este registro es recibir el resultado generado por la lógica de comparación. El registro F está formado por una matriz de biestables tipo D que se ponen en 1 o 0 dependiendo del resultado de la comparacion.
> ![[ARC-MemAsic7.png]]
7. **Lógica de selección:** Normalmente, este subsistema obtiene la dirección de la palabra cuya clave coincide con la indicada y la dirige al registro de salida.

Podemos concluir entonses que la estructura general de un sistema de memoria asociativa seria de tal manera:

> ![[ARC-MemAsiEstru 1.png]]

##### Memoria Coordenada
Cada unidad de memoria que compone a la RWM (RWM, Read Write Memory) se considera como un registro direccionable, de modo que la totalidad de la memoria puede contemplarse como una colección de estos registros direccionables. Asociados con cada unidad RWM existen dos tipos de registros:

- **El registro de direcciones de memoria (MAR, Memory Address Register):** El MAR se emplea como puntero a una dirección de memoria. Contiene la dirección de la posición de memoria deseada.
- **El registro de datos de memoria (MBR, Memory Buffer Register):** El propósito del MBR es el de actuar como un buffer para todas las operaciones de transferencias de datos.
## Jerarquia de Memorias

Existe una regla la 90/10 que se puede plantear como el principio de localidad de referencia. Esto quiere decir que, un programa emplea un 90% de su tiempo de ejecución en sólo un 10% del código.
La localidad de referencia se aplica a los accesos a datos también. Se observan dos tipos diferentes de localidades de referencia: 
- **La Localidad Temporal:** Si se referencia un elemento, tenderá a ser referenciado pronto.
- **La Localidad Espacial:** Si se referencia un elemento, los elementos cercanos a él tenderán a ser referenciados pronto.

> ![[ARC-JerarquiaMemoria.png]]

> ![[ARC-jerarquiaMEm.png]]

### Principios de la Jerarquia de Memoria

- La mínima unidad de información que puede estar presente o no presente en la jerarquía de dos niveles se denomina bloque.

> **Bloque:** Es la unidad mínima de transferencia entre cache y la memoria principal. Corresponde a un conjunto de palabras contiguas en memoria. Las cache incluyen una etiqueta de dirección en cada bloque que identifica la dirección de la estructura del bloque.

- El éxito o fracaso de un acceso al nivel superior se denomina acierto o fallo.
	- Un acierto (hit) es un acceso a memoria que se encuentra en el nivel superior.
	- Un fallo (miss) significa que no se encuentra en ese nivel.
- La frecuencia de aciertos o tasa de aciertos, es la fracción de accesos a memoria encontrados en el nivel superior.
- La frecuencia de fallos, es la fracción de accesos a memoria no encontrados en el nivel superior.

### Memoria Cache
> La memoria cache es una memoria especial que se ubica entre la CPU y la memoria principal, la cual contiene todos los datos que se utilizan mas frecuentemente por el procesador.
> ![[ARC-Cache.png]]

Forma de Operar de una Cache: 
1. La dirección generada por el procesador es comparada con datos almacenados en el cache.
2. Si el dato está presente, el procesador lo lee desde el cache.
3. Si el dato está ausente, se transfiere desde la memoria principal al cache.
4. Si es necesario se reemplaza uno de los datos presentes en el cache.

#### Esquemas de Ubicación de Bloques en la Cache

- **Correspondencia Directa:** Cada bloque solamente tiene un lugar donde puede aparecer en la cache.
> ![[ARC-Ubi1.png]]
- **Correspondencia Totalmente Asociativa:** Un bloque puede colocarse en cualquier parte de la cache.
> ![[ARC-Ubi2.png]]
- **Correspondencia Asociativa por Conjunto:** Un bloque puede colocarse en un conjunto restringido de lugares de la cache. Un conjunto es un lugar de dos o más bloques de la cache. Un bloque se hace corresponder primero a un conjunto y despues el bloque se puede colocar en cualquier parte del conjunto.
> ![[ARC-Ubi3.png]]

#### Sustitucion de Bloques en Cache
- En la correspondencia directa no hay elección.
- Con la totalmente asociativa o la asociativa por conjuntos, hay varios bloques a elegir cuando se produce un fallo. Podemos examinar varias estrategias:
	- **Aleatoria:** No basada en el grado de utilización, sobre escribe el nuevo bloque ensima de un bloque elegido al azar.
	- **Menos recientemente usado (LRU) o utilizado menos recientemente:** Se sustituye el bloque que se ha mantenido en caché por más tiempo sin haber sido referenciado. Es de Mejor Desempeño que el Aleatorio pero es más Complejo de Implementar.
	- **Utilizado menos frecuentemente (LFU):** Se sustituye el bloque que ha experimentado menos accesos. Se asocia un contador a cada línea.
	- **Primero en entrar primero en salir (FIFO):** Se sustituye el bloque que ha estado más tiempo en cache.

#### Formas de Escritura en Cache
Hay dos opciones básicas para escribir en la cache: 
- **Escritura directa (write through o store through):** La información se escribe en el bloque de la cache y en el bloque de la memoria de nivel inferior.
- **Posescritura( Write back):** La información se escribe sólo en el bloque de la cache. Bloque modificado de la cache se escribe en memoria solo cuando es reemplazado.

## Memoria Virtual

Problemas de la Memoria Principal:
- Cada programa maneja un espacio de memoria independiente.
- La suma de los espacios de memoria activos es muy grande.

Hace creer a los programas que existe una memoria principal de gran tamaño, con esto logramos explotar la localidad de acceso a través de la jerarquía de memoria simplificando asi el manejo de memoria. Algunas de las motivaciones para estudiar la memoria virtual:

1. Permitir compartir eficientemente la memoria entre diversos programas.
2. Eliminar los problemas que presenta una memoria pequeña y limitada.

Ventajas Principales de la Memoria Virtual 
1. Permite una Traducción de Direcciones Simple y Eficiente
2. Permite Crear Instancias de Memoria Compartida
3. Permite Establecer Esquemas de Protección de Memoria

### Funcionamiento de la Memoria Virtual

La memoria principal almacena sólo los datos/instrucciones más utilizados el resto se encontrara en la memoria secundaria(Disco) o sea, la memoria virtual actúa como cache de la información residente en el disco para tomar ventaja de la localidad espacial, la memoria es dividida en bloques, que en la terminología de memoria virtual se llaman **Páginas**, Con las cuales se transfieren datos entre memoria real y disco.

> ![[ARC-MeMVirt.png]]

Hay dos tipos de direcciones, las de memoria virtual y las de memoria física. Por lo Tanto, se hace necesaria una traducción de direcciones. Estos tipos de direcciones permiten que los programas posean espacios de memoria independientes, consiguiendo así:

1. Las direcciones generadas por programas en ejecución son direcciones virtuales.
2. Estas direcciones son traducidas a direcciones de memoria real.

> ![[ARC-MemVirt2.png]]

La traducción de direcciones se realiza a través de tablas de páginas, las cualen indican:

1. Si la página está en memoria real o hay que traerla del disco.
2. Cual es la dirección en memoria real.
3. Establecen algunos permisos de acceso.

Para un mejor desempeño las tablas de páginas residen en memoria, la traducción y validación de acceso es realizada por hardware en la unidad de manejo de memoria.

> ![[ARC-MEmVirt3.png]]

### Esquema de Ubicacion de Paginas en Memoria

Como sabemos, a mayor grado de asociatividad, menor tasa de desaciertos. Por otro lado, la penalidad de desacierto en memoria virtual es altamente significativa, ya que el tiempo de acceso al disco del orden de milisegundos, esto implica que la tasa de desaciertos tiene que ser casi nula para lograr esto la mejor solución es ubicación completamente asociativa. Esto implica que páginas lógicamente contiguas pueden no estar físicamente contiguas en la memoria principal.

#### Como encotrar una Pagina en Memoria

**Pasos del Proceso de Traducción de Direcciones:**

1. El programa emite una dirección virtual.
2. La MMU determina la tabla de páginas adecuada y la lee desde memoria.
3. Si la página no está en memoria real, la MMU produce una excepción de falta de página(Page Fault) y se transfiere el control al Sistema Operativo.
4. Si la página está en memoria, pero el programa no posee privilegios para accesar a la Página, se produce una excepción de protección(Protection Fault) y se transfiere el control al Sistema Operativo.
5. Si la página está en memoria y el programa tiene derecho de acceso, se lee el dato o instrucción desde memoria principal.

#### Esquemas de Reemplazo de Páginas en Memoria

Como la penalidad de desacierto es tan grande, es crítico elegir la página que causará la menor tasa de desaciertos, algunos de los algoritmos utilizados son:

- **Página Menos Recientemente Usada (LRU):** Es una buena aproximación al optimo, Pues la página menos recientemente utilizada probablemente no será referenciada en el futuro cercano. Esta solución requiere mantener una lista de páginas en memoria ordenada por tiempo de ultima referencia lo que es difícil de implementar por Hardware.
- **Primera en Entrar, Primera en Salir (FIFO):** Implica reemplazar la página más antigua, lo que es fácil de implementar, pero tiene el inconveniente de que no reconoce la localidad temporal.
- **Página No Recientemente Usada (NRU):** Implica tener un Bit de referencia asociado a cada página que es manejado por la MMU. Se coloca el Bit en 1 cada vez que la página es referenciada y cada cierto tiempo todos los Bits de referencia se ponen en 0, la página a reemplazar es la que tiene el Bit de referencia en 0.

#### Esquema de Manejo de Escritura en Memoria

Al Igual que en las Caches Existen Dos Alternativas: 
- **Escritura Sincronizada (Write-Through):** Escribir en memoria y en disco cada vez que se hace una escritura.
- **Escritura Asincrónica (Write-Back):** Escribir sólo en memoria y respaldar en el disco al reemplazar la página.

La opción elegida para la memoria virtual es la ***escritura asincrónica***, como el acceso al disco es tan lento, no resulta práctico ejecutar una copia sincronizada del contenido de la memoria. Además, el acceso a disco se realiza siempre por bloques, lo que hace más cómoda y conveniente la escritura asincrónica.
Para que esto sea posible el sistema operativo debe conocer cuándo los contenidos de una página que está en memoria han sido modificados pues estos deben ser escritos en el disco antes de reemplazar la página. Ademas se debe agregar un Bit de modificación (Dirty Bit) por cada página en memoria, este es puesto en 1 cada vez que el programa escribe en la página.

