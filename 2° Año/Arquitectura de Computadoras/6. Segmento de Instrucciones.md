##### Recordatorio

El ciclo de instrucción de la CPU, incluye los siguientes subciclos:

- **Captación o Búsqueda:** Lleva la siguiente instrucción de la memoria a la CPU.
- **Ejecución:** Interpreta el código de operación y llevar a cabo la operación indicada.

y en [[5. Entrada y Salida de la Computadora]] vimos el concepto de *interrupción*. y si estas están habilitadas y ha ocurrido una interrupción, salva el estado del proceso actual y atiende la interrupción(ver imagen del ciclo de instrucción con interrupción de la unidad anterior para mas claridad).

> **Pasos en el ciclo de Instrucción**
> ![[ARC-cicloEj.png]]

---

## Segmentación de Instrucciones: Pipelining

La idea principal es que las instrucciones utilizan recursos distintos en distintas etapas de la ejecución, entonces se ejecutan múltiples instrucciones simultáneamente siempre y cuando TODAS se encuentren en distintas etapas de ejecución.

##### ¿Por qué a la segmentación se le llama Pipelining?

Porque al igual que en una tubería, se aceptan entradas nuevas en un extremo antes de que las anteriores sean salidas en el otro extremo.

> ###### Ejemplo Practico
> ![[ARC-EjSegmentacion.png]]
> ![[ARC-Segmentacion2.png]]

Para aplicar este concepto a la ejecución de instrucciones, debemos darnos cuenta de que una instrucción tiene varias etapas: **La Busqueda/Captación de la instrucción y la Ejecución de esta misma.**
Hay períodos en la ejecución de una instrucción en los que no se accede a memoria principal. Este tiempo podría utilizarse en captar la siguiente instrucción en paralelo con la ejecución de la actual.

##### ¿Cómo se ejecuta la segmentación?
- En cada ciclo se inicia la ejecución de una instrucción.
- Existen múltiples instrucciones en ejecución.
- Se inicia una ejecución en cada ciclo de reloj.

Algunos puntos a tener en cuenta a de la segmentación
- No mejora la latencia individual, pero la ejecución de las instrucciones es en el mismo tiempo que si se hicieran en forma secuencial.
- Mejora la productividad (throughput) global.
- Está limitada por la instrucción más lenta.
- Si las etapas están desbalanceadas la mejora a conseguir se reduce.

Para evitar el desbalanceamiento, y no reducir la efectividad potencial del pipelining, se descompone el procesamiento de la instrucción, para que las etapas tengan duraciones similares, de la siguiente forma:

- **Buscar Instrucción** (FI - Fetch Instruction).
- **Decodificar Instrucción** (DI - Decode Instruction).
- **Calcular Operandos** (CO - Calculate Operands).
- **Buscar Operandos** (FO - Fetch Operands).
- **Ejecutar instrucción** (EI - Execute Instruction).
- **Escribir Operando** (WO - Write Operand).

> **Ejemplo de como funciona esta idea**
> ![[ARC-EjSegmentacion2.png]]
> Si las seis etapas no son de igual duración, habrá cierta espera en algunas etapas del cauce.

Este modelo supone que siempre se recorrera las seis etapas del cauce, pero no siempre es así. Por ejemplo una instrucción de carga no necesita la etapa de WO.
La instrucción de bifurcación condicional, pueden invalidar varias captaciones de instrucciones.

> ![[ARC-EjSegmentacion3.png]]

### Riesgos del Pipelining
La segmentación de instrucciones es una técnica poderosa para aumentar las prestaciones pero requiere un diseño muy cuidadoso si se desean obtener resultado óptimos, donde se debe tener en cuenta los siguientes aspectsos:

- **Estructurales:** ignifica que la circuitería no es capaz de soportar la combinación de instrucciones que se desea ejecutar en el mismo ciclo. Es decir, ocurren conflictos de Hardware en distintas etapas de la ejecución. La idea central para evitar este tipo de hechos es que:
	1. Cada unidad funcional de memoria puede ser usada sólo una vez por instrucción.
	2. Cada unidad funcional debe ser usada en el mismo estado por todas las instrucciones.
	3. Una Solución posible es definir un estado de memoria que no hace nada, o insertar un ciclo ocioso por hardware.

- **De control:** La idea es tomar una decisión basada en los resultados de una instrucción mientras las otras se están ejecutando. El problema surge cuando se debe esperar la ejecución de una etapa del ciclo para tomar la decisión y esto obliga a tener un tiempo ocioso, para resolver este problema se presentan dos posibles soluciones.
	1. Bloqueos después de cada salto, pero se tendra que esperar la proxima instrucción.
	2. Predicción de saltos, ejecutar el salto en forma paralela con todas las instrucciones, con el inconveniente de que si se erra la predicción el proceso se tenga que iniciar de nuevo. Por lo general, se intenta predecir que el salto no se ejecutará, cuando se acierta, el procesador segmentado funcionará a máxima velocidad y de esta forma el procesador sólo se bloqueará cuando los saltos son ejecutados, pero lo ideal es tener predicciones para los dos caso: se ejecutan los salto, o no se ejecutan.

- **De Datos:** Una instrucción depende del resultado previo que todavía esta en el pipeling, por lo tanto es necesario actualizar a tiempo el valor de las variables que van a ser ocupadas.

La segmentación incrementa el número de instrucciones que se ejecutan a la vez, y también su rapidez, el resultado obtenido al utilizar esta técnica no depende de la metodología escogida, sino que también del set de instrucciones del procesador.

## Procesador Supersegmentado y Superescalar

La evolución lógica de los diseños de cauces segmentados dio lugar a la aparición de dos técnicas de ejecución de mayores prestaciones, por un lado *Los Procesadores Supersegmentados* y por otro *Los Procesadores Superescalares*.

##### Procesadores Supersegmentados
Muchas operaciones no necesitan todo un ciclo de reloj para su ejecución. Obtendremos mayores prestaciones subdividiendo el ciclo de reloj en sub-intervalos más pequeñas (y, por tanto, más rápidas) y se transmiten los datos a la mayor velocidad del ciclo de reloj. El tiempo para las instrucciones individuales no varía, pero aumenta el grado del paralelismo e incrementa la aceleración percibida.

> ![[ARC-Supersegmentacion.png]]

##### Procesadores Superescalar
Se pueden llevar a cabo más de una instrucción simultáneamente, lo que nos lleva a tener que duplicar algunas o todas las partes de la PU/ALU. Pero a su vez nos brinda bastantes ventajas.

1. Captar múltiples instrucciones al mismo tiempo.
2. Ejecutar sumas y multiplicaciones simultáneamente.
3. Ejecutar carga/almacenamiento, mientras se lleva a cabo una operación en ALU.

El grado de paralelismo y, por tanto, la aceleración de la máquina aumentan, ya que se ejecutan más instrucciones en paralelo.

> ![[ARC-Superescalar.png]]
> **Aqui ina comparación entre ambas**
> ![[ARC-Comparacion.png]]

## Procesamiento Paralelo

- Mejorar el rendimiento de una máquina con un solo procesador.
	- Paralelismo a nivel instrucción – ILP.
- Arquitecturas de sistemas con varios procesadores.
	- Paralelismo a nivel proceso.

> Organización de un proceador segun la taxanomia de Flynn
> ![[ARC-Taxonomio.png]]
