## Interpolación
La interpolación es un método utilizado para estimar valores desconocidos que se encuentran dentro del rango de un conjunto discreto de puntos de datos conocidos. Se utiliza principalmente para construir nuevos puntos de datos dentro del rango de un conjunto de puntos de datos conocidos. La interpolación se utiliza en diversos campos como la ingeniería, gráficos por computadora y análisis de datos para predecir valores intermedios, suavizar datos y completar puntos de datos faltantes. Utiliza polinomios para interpolar los puntos de datos. La forma más común es la interpolación de Lagrange.
$$P(x)=\Sigma_{i = 0}^n​ y_i​ \varPi^n_{j = 0, \ j \neq i} \frac{x-x_j}{x_i - x_j}$$
En la práctica supongamos que tenemos 4 puntos $(1, 2), (3,4), (5,6), (7,8)$, entonces nuestro polinomio tendrá la siguiente duerma:
$$P(x) = y_0 \cdot L_0(x) + y_1 \cdot L_1(x)  + y_2 \cdot L_2(x) + y_3 \cdot L_3(x)$$
Donde cada $L_i$ estará compuesta de la siguiente manera de acuerdo a la fórmula seguida:
1. $L_0(x) = 2 \cdot \frac{(x - 3)(x - 5)(x - 7)}{(1 - 3)(1 - 5)(1 - 7)} = 2 \cdot \frac{(x - 3)(x - 5)(x - 7)}{48}$
2. $L_1(x) = 4 \cdot \frac{(x - 1)(x - 5)(x - 7)}{(3 - 1)(3 - 5)(3 - 7)} = 4 \cdot \frac{(x - 1)(x - 5)(x - 7)}{16}$
3. $L_2(x) = 6 \cdot \frac{(x - 1)(x - 3)(x - 7)}{(5 - 1)(5 - 3)(5 - 7)} = 6 \cdot \frac{(x - 1)(x - 3)(x - 7)}{-16}$
4. $L_3(x) = 8 \cdot \frac{(x - 1)(x - 3)(x - 5)}{(7 - 1)(7 - 3)(7 - 5)} = 8 \cdot \frac{(x - 1)(x - 3)(x - 5)}{64}$

>[!tldr] Criterios para la Aplicación de la Interpolación
>- Los datos deben estar dentro del rango de los puntos de datos conocidos.
>- El método elegido depende de la suavidad deseada y la eficiencia computacional.
## Regresión
La regresión es un método estadístico utilizado para modelar y analizar las relaciones entre una variable dependiente y una o más variables independientes. Se utiliza para predecir el valor de la variable dependiente en función de los valores de las variables independientes. La regresión se utiliza ampliamente en economía, biología, ingeniería y ciencias sociales para predicción, pronóstico y determinación de relaciones causales.
Una forma de análisis de regresión en la que la relación entre la variable independiente $x$ y la variable dependiente $y$ se modela como un polinomio de grado $n$. Construyendo un sistema de ecuaciones lineales de la siguiente forma:
$$\begin{bmatrix}
1 & x_0 & x_0^2 & \cdots & x_0^m \\
1 & x_1 & x_1^2 & \cdots & x_1^m \\
1 & x_2 & x_2^2 & \cdots & x_2^m \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_n & x_n^2 & \cdots & x_n^m
\end{bmatrix}
\cdot
\begin{bmatrix}
a_0 \\
a_1 \\
a_2 \\
\vdots \\
a_m 
\end{bmatrix}
= 
\begin{bmatrix}
y_0 \\
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix}$$

>[!note] Error del Método de Mínimos Cuadrados
>Generalmente el método presentado es el método de mejor ajuste o de mínimos cuadrados y se utiliza para calcular regresiones de cualquier grado, este tipo de métodos tiene el siguiente error:
>
>$$\Sigma_{k = 0}^n (P_m(x_k) - y_k)^2$$
>
>Donde $P_m(x_k)$ es el valor de $y$ predicho por la fuención de regresión calculada a partir de los datos conocidos.

El grado de los polinomios va a depender del tipo de regresión que deseemos realizar. La forma de resolver esta matriz, teniendo en cuenta que es un sistema del tipo $A\cdot X = B$ consta de los siguientes pasos:
1. Se multiplica por la transpuesta de $A$ a ambos lados de la igualdad:

$$A^t \cdot A \cdot X = A^t \cdot B$$
2. Se resuelve la multiplicación de $A^t \cdot A$, lo que nos deja con una matriz cuadrada.
3. Se resuelve la multiplicación de $A^t \cdot B$ para obtener el nuevo resultado.
4. Una vez teniendo que se convierte la matriz del lado derecho en cuadrada se resuelve el sistema de ecuaciones de manera normal. Supongamos que $A^t \cdot A = H$ (sabiendo que $H$ es una matriz cuadrada) y que $A^t \cdot B = Y$ es un resultado intermedio, entonces se resuelve la siguiente matriz con el método que resulta más conveniente:
$$H \cdot X = Y$$
Donde el resultado de resolver ese sistema de ecuaciones va a ser un vector $X$ cuyas componentes son los coeficientes de la función de regresión.
>[!tldr] Criterios para la Aplicación de la Regresión
>- En regresión múltiple, es importante que las variables independientes no sean linealmente dependientes entre sí.
>- Para que una regresión sea significativa, debe haber suficiente variabilidad en los datos. Si todos los puntos de datos son muy similares o idénticos, la regresión no podrá capturar ninguna relación significativa entre las variables.
>- Aunque no es un requisito que todos los puntos sean únicos, tener puntos de datos idénticos puede afectar la capacidad del modelo para ajustarse adecuadamente a los datos.
>- Hay varios supuestos que deben cumplirse para que los resultados de una regresión sean válidos, como la linealidad, la independencia de los errores, la homocedasticidad (varianza constante de los errores) y la normalidad de los errores.

