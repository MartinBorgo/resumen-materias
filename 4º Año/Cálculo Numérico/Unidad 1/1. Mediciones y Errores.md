
Supongamos que $x$ es un número real, para expresarlo en un sistema de numeración de base $b$, se lo puede describir de la siguiente manera.

$$
x = d_1 \ d_2 \ d_3, d_4 \ d_5 \ d_6 \ d_7 ...
$$
Siendo $d_i$ la cantidad de dígitos del sistema de numeración elegido para representar dicho número, algunos de los más utilizados son el **binario**, el **hexadecimal** y el **decimal**.

>[!tldr] Notación Científica
>Un número puede ser representado de diversas maneras, por ejemplo, supongamos que queremos expresar el número **3,5643**. Este mismo podría ser representado de la siguiente forma:
>$$
>3,5643 = 10^1.3 + 10^{-1}.5 + 10^{-2}.6 + 10^{-3}.4 10^{-4}.3
>$$
>Otra forma de expresar ese número es moviendo la parte entera al lado de los decimales, haciendo que la parte entera sea nula, quedando de la siguiente forma:
>$$
>x = b^e.0, d_1 \ d_2 \ d_3 \ d_4 \ d_5 \ d_6 \ d_7
>$$
>Donde $b$ es la base del sistema de numeración elegido, $e$ el exponente que representa la cantidad de veces que se desplaza la coma. Al resto de números que se encuentran por detrás de la coma se los denomina ***mantisa***.

Al usar y almacenar estos números en la computadora, las cifras de la mantisa no pueden ser infinitas, debido a las limitaciones físicas que poseen las computadoras. En consecuencia, hay que cortar la mantisa, y este corte se hace a los ***t-dígitos***.

$$
x = b^e.0,\delta_1 \ \delta_2 \ \delta_3 \ \delta_4 \dots \delta_t
$$

---

Al usar la computadora, se usa el sistema binario, donde $b = 2$, y las cifras o dígitos en esa base de este sistema numérico compuesta por el conjunto {0, 1} se denominan “bits”

1. Para representar **números enteros** tradicionalmente, se usan dos bytes para representar los números de *simple precisión, 4 bytes para la *doble precisión*. En ambos casos el primer bit se reserva para el signo. Debido a las propiedades de las potencias de 2, en algunos ordenadores los números negativos se representan como el ***complemento a 2***, es decir, $x \longrightarrow x + 2 - 2^{16}$.
2. Para representar números reales, se lo puede hacer de dos formas:
	1. Punto Fijo -> Se considera un número fijo $n$ de decimales, cortando esa cantidad en t-dígitos, tal que $t < n$. Por Ej.: $n = 6$ y $t=4$, el mayor número en este caso sería el 99,9999 mientras que el menor sería 0,0004.
	2. Punto Flotante -> La representación de punto flotante se corresponde con la notación científica normalizada, dada por la siguiente expresión:

$$
x = \varepsilon \ 0, \delta_1 \ \delta_2 \ \delta_3 \ \delta_4 \dots \delta_t. b^e
$$
En donde:
- $\varepsilon$ representa el signo.
- $b$ la base del sistema numérico.
- $e$ un exponente entero.
- $t$ el número de dígitos significativos.
- $\delta_1 \ \delta_2 \ \delta_3 \ \delta_4 \dots \delta_t$ la parte fraccionaria significativa.

Si la computadora admite solo $t$ cifras significativas, el redondeo se hace al número más próximo. Dado el número:

$$
x = \varepsilon \ 0, \delta_1 \ \delta_2 \ \delta_3 \ \dots \delta_t \ \delta_{t +1} \ \delta_{t+2}.10^e
$$

El redondeo para ese número utilizando el punto flotante $fl(x)$ es:

$$ 
\begin{cases} 
fl(x) = x = 0.\delta_1 \ \delta_2 \ \delta_3 \dots \delta_n \ 10^e & \text{si } \delta_{n+1} < 5 \\
fl(x) = x = 0.\delta_1 \ \delta_2 \ \delta_3 \dots(\delta_n+1) \ 10^e & \text{si } \delta_{n+1} \geq 5
\end{cases}
$$

---

### Cotas de Error

Las cotas de error son valores que indican cuánto puede desviarse el resultado de una aproximación o medición del valor verdadero o exacto. En este caso, las cotas de error de redondeo serán:

- **Error Absoluto**: $E_a = fl(x)-x$, que con su valor absoluto nos queda $|E_a| \leq 0,5.10^{e-t}$.
- **Error Relativo**: $E_r = \frac{E_a}{x}$, que con su valor absoluto nos queda $|E_r| \leq 0,5.10^{-t}$.

El error se aplica para indicar la inexactitud y la imprecisión de las mediciones. El error numérico es igual a la diferencia entre el ***valor verdadero*** y ***el aproximado***:

$$
E_v= \text{Valor verdadero} - \text{Valor aproximado}
$$

El ***error relativo fraccional*** resulta de normalizar el error respecto al valor verdadero:

$$
\text{Error relativo fraccional} = \frac{\text{Error Verdadero}}{\text{Valor Verdadero}}
$$
El ***error relativo porcentual de aproximación*** está dado por:

$$
E_a = \frac{\text{Aproximación Actual} - \text{Aproximación Previa}}{\text{Aproximación Actual}}.100
$$

De acuerdo con Scarborough, se tiene la seguridad de que el resultado es correcto en al menos $t$ cifras significativas si se cumple el siguiente criterio:

$$
\in_s = (o,5.10^{2-t})\%
$$

En donde $\in_s$ es la ***tolerancia prefijada***.

---

### Errores en la Resolución Numérica

Cuando utilizamos métodos numéricos para resolver problemas matemáticos, las respuestas que obtenemos no son exactas, debido a que existe incertidumbre en los datos, además de realizar simplificaciones en le modelo real, o errores de truncamiento y redondeo.

#### Error de Truncamiento

Se refiere al error que se comete cuando se utiliza una versión simplificada o truncada de un proceso matemático que, de otra forma, sería más complejo o incluso infinito en naturaleza. En el ejemplo de las series de Taylor, el error de truncamiento aparece cuando utilizamos solo un número fijo de términos de la serie para realizar la aproximación. Esto quiere decir que a mayor cantidad de términos utilicemos para la aproximación menor será el error en su aproximación.

Cuando se aproxima una función $f(x)$ por su serie de Taylor alrededor de un punto $a$, solo se utilizan los primeros $n$ términos, y la serie de Taylor se convierte en un polinomio de Taylor de grado $n$. La diferencia entre el valor real de la función $f(x)$ y el valor del polinomio de Taylor de grado $n$ es lo que llamamos error de truncamiento. Este error es estimado utilizando la siguiente fórmula:

$$
R_n = \frac{f^{(n+1)}(\xi)}{(n+1)!}(x-a)^{n+1}
$$
##### Propagación de Errores

Los errores de los números pueden propagarse a través de las funciones matemáticas. Por ejemplo, cuando multiplicamos dos números que tienen error, nos gustaría saber el error de ese producto.
Sea $f(x)$ función de la variable independiente $x$. Si consideramos que $\overline{x}$ es una aproximación de $x$, tratemos de evaluar el efecto de la discrepancia, entre el uso de $x$ y su aproximación $\overline{x}$, o sea, queremos estimar

$$
\Delta f(\overline{x}) = |f(x) - f(\overline{x})|
$$

El problema es que se desconoce el valor de $x$ y se tiene su aproximación $\overline{x}$. Este problema se supera, si $\overline{x}$ está cerca de $x$ y $f(x)$ es ***continua y diferenciable***. Si se satisfacen las condiciones, usamos la serie de Taylor para calcular $f(x)$ cerca de $f(\overline{x})$.

$$
f(x) = f(\bar{x}) + f'(\bar{x}) \cdot (x - \bar{x}) + \frac{f''(\bar{x})}{2!} \cdot (x - \bar{x})^2 + \frac{f'''(\bar{x})}{3!} \cdot (x - \bar{x})^3 + \cdots + \frac{f^{(n)}(\bar{x})}{n!} \cdot (x - \bar{x})^n + R_n
$$

Si nos quedamos con los dos primeros términos del desarrollo y pasamos $f(\overline{x})$ al primer miembro, queda la expresión:

$$
f(x) - f(\overline{x}) \cong f'(\overline{x})(x - \overline{x}) = \Delta f(\overline{x}) \cong |f(\overline{x})|.|(x - \overline{x})|
$$

Que representa una estimación del error de la función y $\Delta x = |x - \overline{x}|$ representa una estimación del error de $x$. La fórmula anterior proporciona la capacidad de aproximar el error de una función, mediante la derivada de la función y una estimación del error de la variable independiente.

#### Error de Redondeo

