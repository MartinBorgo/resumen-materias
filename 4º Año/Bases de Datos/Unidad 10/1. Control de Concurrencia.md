
En un entorno de multiprogramación es posible ejecutar varias transacciones de manera concurrente, por esa razón es necesario que el gestor de la base de datos controle la interacción entre las transacciones para evitar se destruya la consistencia en la base de datos.
Estos controles se realizan por mecanismos que se conocen como esquemas de control de concurrencia conocidos como ***cronogramas (Schedules)*** los cuales representan el orden cronológico en que se ejecutan las instrucciones en el sistema. Para ayudar a identificar las ejecuciones que garantizan la consistencia, se presentará el concepto de ***serializabilidad***.

>[!note] Concepto de Serializabilidad
>La serializabilidad de una transacción asegura que una planificación de transacciones concurrentes es correcta y consistente. Una planificación es serializable si el resultado de su ejecución es el mismo que se obtendría si las transacciones se ejecutaran en algún orden secuencial. En otras palabras, aunque las transacciones se ejecuten de manera concurrente, una planificación es serializable si se puede reordenar de tal manera que el efecto combinado de las transacciones sea igual al de alguna ejecución en serie de esas transacciones manteniendo así la consistencia de la base de datos.

Cuando se ejecutan transacciones de forma concurrente en una base de datos, es posible que la planificación de estas no siga un orden en serie, lo que significa que no se procesan de manera secuencial una tras otra. Esta falta de secuencialidad puede dar lugar a inconsistencias temporales, que son la principal causa de las inconsistencias en las planificaciones concurrentes.

## Equivalencia de Conflictos

Dado un cronograma $S$ en la que hay dos operaciones consecutivas $I_i$ e $I_k$ de las transacciones $T_i$ y $T_k$ respectivamente.

- Si $I_i$ e $I_k$ se refieren a datos distintos, entonces podemos intercambiar el orden de $I_i$ e $I_k$ sin que esto afecte el resultado de las instrucciones del cronograma. Sin embargo, si $I_i$ e $I_k$ se refieren al mismo dato $Q$, el orden de los pasos puede ser importante. Las operaciones de lectura concurrentes no son relevantes, ya que ambas transacciones inicialmente leerán el mismo valor de $Q$. Las operaciones críticas son las de escritura.
- Si $I_i = read(Q)$ y $I_k = write(Q)$, el orden de $I_i$ e $I_k$ si importa, ya que si $T_k$ escribe antes que $T_i$ lea, el valor leído por $T_i$ es el escrito por $T_k$. Lo mismo ocurre en caso inverso, es decir, si $I_i = write(Q)$ y $I_k = read(Q)$.
- Si $I_i = write(Q)$ y $I_k = write(Q)$, el orden de $I_i$ e $I_k$ si importa, ya que afecta al valor de $Q$ que lea la siguiente transacción, a este problema de aquí se lo conoce como **race condition**.

Se dice que $I_i$ e $I_k$ están en conflicto, si son operaciones de transacciones distintas sobre el mismo dato, y por lo menos una de estas instrucciones es una operación de escritura. Por otro lado si un cronograma $S$ puede transformarse en un cronograma $S'$ mediante una serie de intercambios de instrucciones no conflictivas, se dice que son ***equivalentes en conflictos***. Se dice que un cronograma $S$ es ***serializable en conflictos*** si es equivalente en conflictos a un cronograma en serie.

## Equivalencia en Vistas

Dado dos cronogramas $S$ y $S'$ en las que el mismo conjunto de transacciones participa en ambos cronogramas. Se dice que los cronogramas $S$ y $S'$ son equivalentes en vistas si se cumplen las siguientes condiciones:

1. Para cada dato $Q$, si la transacción $T_i$ lee el valor inicial de $Q$ en $S$, entonces la transacción $T_i$ también debe leer el valor inicial de $Q$ en $S'$.
2. Para cada dato $Q$, si la transacción $T_i$ ejecuta una operación de lectura en $S$, y ese valor fue producido por la transacción $T_k$ (si existe), entonces $T_i$ también debe leer el valor de $Q$ producido por $T_k$ en $S'$.
3. Para cada dato $Q$, la transacción (si existe) que ejecuta la operación de escritura final en $S$, debe ejecutar la operación de escritura final en $S'$.

Un cronograma $S$ se dice que es serializable en vistas si es equivalente en vistas a un cronograma en serie. Por ejemplo el siguiente cronograma no es serializable en conflictos, sino que es serializable en cuanto a vista.

![[equivalencia-vista.png]]

En este caso ese cronograma concurrente es equivalente al siguiente cornograma en serie $<T_2 - T_3 - T_5>$.

>[!tldr] Escrituras Ciegas
>En el ejemplo anterior $T_3$ y $T_5$ realizan operaciones de escritura sin antes haber realizado ninguna operaciones de lectura, a este comportamiento se los llama ***escritura ciega***.

## Prueba de Serializabilidad

Consiste en construir un grafo de precedencia $G = (V, E)$, donde $V$ es un conjunto de vértices y $E$ es un conjunto de aristas. El conjunto de vértices consta de todas las transacciones que participan en el cronograma. El conjunto de aristas consta de todas las aristas $T_i \Rightarrow T_k$ para las cuales se cumple una de las siguientes condiciones:

- $T_i$ ejecuta $write(Q)$ antes que $T_k$ ejecute $read(Q)$.
- $T_i$ ejecuta $read(Q)$ antes que $T_k$ ejecute $write(Q)$.
- $T_i$ ejecuta $write(Q)$ antes que $T_k$ ejecute $write(Q)$.

Si el grafo de precedencia tiene un ciclo, entonces el cronograma no es serializable en conflictos, véase un ejemplo en la siguiente imagen.

![[ejemplo-serializacion.png]]

## Esquemas de Control de Concurrencia

En la unidad anterior se estudió que una de las propiedades fundamentales de las transacciones es el aislamiento. Cuando se ejecutan varias transacciones concurrentemente en la base de datos, puede que deje de conservarse la propiedad de aislamiento. Es necesario que el sistema controle la interacción entre las transacciones concurrentes; dicho control se lleva a cabo a través de uno de los muchos mecanismos existentes llamado ***esquema de control de concurrencia***.

### Protocolos Basados en Bloqueos

Consisten en permitir que una transacción acceda a un dato, sólo si tiene actualmente el bloqueo de ese dato. Existen varios modos de bloquear un dato, en primer lugar trataremos dos modos:

- **Compartido (S)**: Si un transacción $T_i$ ha obtenido un bloqueo de un dato $Q$ en modo compartido, entonces $T_i$ puede leer el dato $Q$ pero no escribir $Q$.
- **Exclusivo (X)**: Si la transacción $T_i$ obtuvo un bloqueo de un dato $Q$ en modo exclusivo, entonces solo $T_i$ puede leer y escribir $Q$.

El **Scheduler** es el componente encargado de asignar los recursos a las distintas transacciones y de gestionar el orden cronológico en que se ejecutan las instrucciones en el sistema de gestión de bases de datos. Este planificador de recibe un ***schedule de entrada***, que consiste en las diversas operaciones ordenadas cronológicamente según cómo el gestor de bases de datos recibe las instrucciones. El Scheduler procesa esta entrada y obteniendo un ***schedule de salida***, que es el orden cronológico resultante del control de concurrencia que realiza.
Cuando una transacción desbloquea datos inmediatamente después de su último acceso, puede comprometer la serializabilidad de la transacción. Para evitar esto, se puede mantener el bloqueo en los datos hasta el final de la transacción, es decir, liberar los datos únicamente una vez que la transacción ha sido comprometida (Commit). Aunque esta estrategia preserva la serializabilidad de la transacción, puede dar lugar a otro problema de concurrencia conocido como **deadlock**.

#### Protocolos de Bloqueo de dos Fases

Este protocolo requiere que todas las transacciones hagan sus solicitudes de bloqueo y desbloqueo en dos fases:

1. **Fase de crecimiento**: Una transacción puede obtener bloqueos pero no puede liberar ninguno.
2. **Fase de encogimiento**: Una transacción puede liberar bloqueos pero no puede solicitar ninguno nuevo.


Este protocolo garantiza la serializabilidad en conflictos, sin embargo no previene la aparición de situaciones de deadlock. Otro problema que puede surgir con este protocolo es el **retroceso en cascada** de varias transacciones. Esto ocurre debido a las **lecturas no comprometidas** (dirty reads), donde una transacción puede leer datos modificados por otra transacción que aún no se ha comprometido. Para solucionar este problema, se puede liberar los bloqueos exclusivos (exclusive locks) únicamente al realizar el commit de la transacción. Esta estrategia se conoce como **Read Committed** y evita que las transacciones lean datos que no han sido definitivamente guardados en la base de datos.
Las ***conversiones de modos de bloqueo*** son una alternativa para aumentar la concurrencia en bases de datos, ya que algunas transacciones solo necesitan un bloqueo exclusivo al final de su ejecución.

- **Upgrade**: Conversión de un bloqueo en modo compartido a un bloqueo exclusivo.
- **Downgrade**: Conversión de un bloqueo exclusivo a un bloqueo en modo compartido.

Es importante tener en cuenta que el **upgrade** solo puede realizarse durante la fase de crecimiento del protocolo de bloqueo en dos fases, mientras que el **downgrade** solo puede realizarse durante la fase de encogimiento. Además, si una transacción intenta un **upgrade** en un recurso $Q$, puede verse obligada a esperar si otra transacción ya tiene un bloqueo compartido en $Q$.

### Protocolos Basados en Hora de Entrada

Estos protocolos garantizan la serializabilidad seleccionando por adelantado un orden entre las transacciones.  El método más conocido empleado por este tipo de protocolos es el de **Estampillas de Tiempo (timestamp ordering)**, en el cual: 

1. A cada transacción $T_i$, el sistema le asigna una hora de entrada fija y única representada por $ts(T_i)$.
2. Para cualquier transacción $T_k$ que entra después de $T_i$, se cumple que $ts(T_i) < ts(T_k)$.
3. La hora de entrada asignada a cada transacción determina el orden de serializabilidad, si $ts(T_i) < ts(T_k) \Rightarrow <T_i - T_k>$.

Algunos métodos que se pueden utilizar para implementar este sistema son:

1. Utilizar la hora del sistema como $ts$.
2. Utilizar un contador lógico que se incremente después de asignar una nueva $ts$.

Más alla del método utilizado para asignar los timestamp a cada transacción. Para implementara este sistema asociamos dos valores de $ts$ en cada dato $Q$.

- $w-ts(Q)$: Representa la mayor $ts$ de cualquier transacción que ejecutó con éxito la operación de escritura en $Q$.
- $r-ts(Q)$: Representa la mayor $ts$ de cualquier transacción que ejecutó con éxito la operación de lectura en $Q$.

Estos datos se actualizan cada vez que se ejecuta una lectura o escritura en $Q$. De esta manera el protocolo garantiza que todas las operaciones de lectura y escritura que puedan entrar el conflicto se ejecuten de acuerdo al orden de $ts$.
Al igual que los algoritmos de bloqueo en dos fases, las lecturas no comprometidas pueden provocar un retraso en cascada, con la diferencia que en este caso se le agrega el problema de ***transacciones no recuperables***, ya que una transacción $T_i$ que leyó datos de una transacción $T_k$, no se puede comprometer hasta que no se comprometa $T_k$.

>[!tldr] Regla de Escritura de Thomas
>Las reglas de escritura de Thomas son un conjunto de reglas utilizadas en el control de concurrencia, estas reglas ayudan a manejar conflictos de escritura y lectura entre transacciones de manera eficiente. De forma resumida estas reglas dicen lo siguiente:
>- Si $ts(T_i) < r-ts(Q)$ la transacción debe abortarse porque estaría escribiendo en un dato que ya ha sido leído por una transacción posterior.
>- Si $ts(T_i) < w-ts(Q)$ la operación de escritura se descarta sin abortar la transacción porque el dato ya ha sido escrito por una transacción más reciente.
>- Si ninguna de las condiciones anteriores se cumplen se realiza la escritura y se actualiza la estampilla de tiempo de escritura del dato.

#### Mecanismos de Validación

Resulta conveniente utilizar un método de evaluación optimista en aquellos casos en que la mayoría de las transacciones son de sólo lectura, la tasa de conflictos entre las transacciones puede ser baja. Así, muchas de esas transacciones, si se ejecutasen sin la supervisión de un esquema de control de concurrencia, llevarían no obstante al sistema a un estado consistente. Aplicando métodos de alternativos de validación podemos disminuir la sobrecarga del sistema sin perder consistencia en la base de datos.
La dificultad de reducir la sobrecarga está en que no se conocen de antemano las transacciones que estarán involucradas en un conflicto. Para obtener dicho conocimiento se necesita un esquema para supervisar el sistema.
Por lo general cada transacción $T_i$ se ejecuta en dos o tres fases diferentes durante su tiempo de vida dependiendo de si es una transacción de sólo lectura o una de actualización. Las fases son las siguientes:

1. **Fase de lectura**: Durante esta fase tiene lugar la ejecución de la transacción $T_i$. Se leen los valores de varios elementos de datos y se almacenan en variables locales.
2. **Fase de validación**: La transacción $T_i$ realiza una prueba de validación para determinar si puede copiar en la base de datos las variables locales temporales que tienen los resultados de las operaciones escribir sin causar una violación de la secuencialidad.
3. **Fase de escritura**: Si la transacción $T_i$ tiene éxito en la validación entonces las actualizaciones reales se aplican a la base de datos. En otro caso, $T_i$ retrocede.

Para realizar la prueba de validación se necesita conocer el momento en que tienen lugar las distintas fases de las transacciones $T_i$ . Por lo tanto se asocian tres marcas temporales distintas a la transacción $T_i$ :

- $Ini(T_i)$: Hora de comenzó de $T_i$.
- $Val(T_i)$: Hora en la que $T_i$ terminó su fase de lectura y comenzó su fase de validación.
- $Ter(T_i)$: Hora en la que $T_i$ terminó su fase de escritura.

La comprobación de validación para la transacción $T_i$ exige que, para toda transacción $T_k$ con $ts(T_k) < ts(T_i)$, se cumplan una de las dos condiciones siguientes:

1. $Ter(T_k) <  Ini(T_i)$. Puesto que $T_k$ completa su ejecución antes de que comience $T_i$.
2. El conjunto de todos los elementos de datos que escribe $T_k$ tiene intersección vacía con el conjunto de elementos de datos que lee $T_i$ , y $T_k$ completa su fase de escritura antes de que $T_i$ comience su fase de validación.

El esquema de validación evita automáticamente los retrocesos en cascada, ya que las escrituras reales tiene lugar sólo después que la transacción se haya comprometido. Sin embargo, existe una posibilidad de inanición de las transacciones largas debido a una secuencia de transacciones cortas conflictivas que provoca reinicios repetidos de la transacción larga. Para evitar la inanición es necesario bloquear las transacciones conflictivas de forma temporal para permitir que la transacción larga termine.

### Esquemas Multiversión

Los esquemas de control de concurrencia tratados hasta aquí, garantizan la serializabilidad retrasando la transacción o bien abortando la transacción que solicitó la operación. Este problema puede evitarse si se mantiene las copias antiguas de todos los datos en el sistema.
En los sistema multiversión cada operación de escritura sobre $Q$ crea una nueva versión del dato $Q$. Cuando se realiza una operación de lectura sobre este dato, el sistema selecciona una de las versiones de $Q$ para leerse.
La técnica más utilizada para los esquema multiversión es la de estampillas de tiempo, en donde a cada dato $Q$ se le asocia una secuencia de versiones $<Q_1, Q_2, \cdots, Q_N>$, donde cada versión $Q_k$ contiene tres campos de información:

- **Contenido**: Valor de la versión $Q_k$.
- $w-ts(Qk)$: estampilla de tiempo de la transacción que creó la versión $Q_k$.
- $r-ts(Qk)$: estampilla de tiempo de la transacción más joven que haya leído con éxito la versión $Q_k$.

Una transacción $T_i$ crea una versión $Q_k$ del dato $Q$, cuando ejecuta la operación de escritura sobre $Q$. El campo contenido tendrá el valor que escribió $T_i$ y $w-ts(Q_k) = r-ts(Q_k) = ts(T_i)$. El valor $r-ts(Q_k)$ puede modificarse cuando una transacción $T_j$ lee $Q_k$ y $r-ts(Q_k) < ts(T_j)$.
Si una operación $T_i$ solicita una operación de lectura o escritura sobre $Q$, y $Q_k$ es una versión de $Q$ cuya $ts$ de escritura es la $ts$ más grande, menor que $ts(T_i)$, entonces se lleva a cabo una de las siguientes operaciones:

1. Si $T_i$ quiere realizar una lectura sobre $Q$, entonces el valor devuelto es el contenido de la versión $Q_k$.
2. Si $T_i$ quiere realizar una operación de lectura sobre $Q$, y $ts(T_i) < r-ts(Q_k)$, entonces la transacción $T_i$ retrocede; en caso contrario se crea una nueva versión $Q_i$.

La justificación de la primera operación es clara. Una transacción lee la versión más reciente que viene antes de ella en el tiempo. La segunda regla fuerza a que se aborte una transacción que realice una escritura tardía de $Q$. Siendo más precisos, si $T_i$ intenta escribir una versión que alguna otra transacción haya leído, entonces no se puede permitir que dicha escritura tenga éxito.

>[!tldr] Ventajas y Desventajas de los Esquemas Miltiversión
>- **Ventajas**:
>	- Las operaciones de lectura nunca fallan y nunca se tiene que esperar.
>- **Desventajas**:
>	- La lectura de un dato tiene también que actualizar $r-ts(Q_k)$, que resulta en dos accesos potenciales a disco en vez de uno.
>	- Los conflictos entre transacciones se resuelven a través de retrocesos en lugar de esperas, lo que puede llegar a generar un retroceso en cascada.

## Inserciones y Supreciones

Algunas transacciones, no sólo requieren accesos a datos que ya existen, sino también la posibilidad de crear nuevos datos o eliminar datos, en este caso deberemos contemplar estas dos nuevas operaciones:

- $delete(Q)$: elimina al dato $Q$ de la base de datos.
- $insert(Q)$: inserta un nuevo dato $Q$ a la base de datos y le da una valor inicial.

Sean $I_i$ e $I_k$ instrucciones de las transacciones $T_i$ y $T_k$ respectivamente, que aparecen en un cronograma $S$ en orden consecutivo. Sea $I_i = delete(Q)$ una instrucción a ejecutar.

- $I_k = read(Q)$: $I_i$ e $I_k$ tienen conflictos. Si $I_i$ viene antes de $I_k$, $T_k$ tendrá un error lógico, ya que ese registro ya habrá sido eliminado. Si $I_k$ viene antes de $I_i$, $T_k$ puede ejecutar la operación de lectura con éxito.
- $I_k = write(Q)$: $I_i$ e $I_k$ tienen conflictos. Si $I_i$ viene antes de $I_k$, $T_k$ tendrá un error lógico, ya que ese registro ya habrá sido eliminado. Si $I_k$ viene antes de $I_i$, $T_k$ puede ejecutar la operación de escritura con éxito.
- $I_k = delete(Q)$: $I_i$ e $I_k$ tienen conflictos. Si $I_i$ viene antes de $I_k$, $T_k$ tendrá un error lógico, ya que ese registro ya habrá sido eliminado. Si $I_k$ viene antes de $I_i$, $T_k$ puede ejecutar la operación de eliminación con éxito, pero ahora arrojará error $T_i$.
- $I_k = insert(Q)$: $I_i$ e $I_k$ tienen conflictos. Si $Q$ no existe antes de las ejecuciones de $I_i$ e $I_k$, entonces si $I_i$ se ejecuta antes de $I_k$, $T_i$ producirá un error lógico porque intentará eliminar un registro que no existe. Sin embargo, si $I_k$ se ejecuta antes de $I_i$, esto no ocurrirá. Por otro lado, si $Q$ existía antes de las ejecuciones de $I_i$ e $I_k$, se producirá un error lógico si $I_k$ se ejecuta antes de $I_i$ porque $I_k$ intentará insertar un registro que ya existe, en caso contrario no ocurrirá ningún error.

La forma de hacer frente a estos conflictos va a depender del protocolo utilizado por la base de datos para manejar la concurrencia, en caso de emplear un bloqueo de dos fases el registro debe tener un bloqueo exclusivo en ese dato antes de poder realizar la eliminación. En cambio, en caso de emplear ordenación por hora de entrada se debe realizar una prueba similar a la que se realiza con la operación de escritura:

- Si $ts(T_i) < r-ts(Q)$, se rechaza la eliminación y $T_i$ retrocede. Esto es porque el valor de $Q$ que $T_i$ iba a suprimir, ya ha sido leído por una transacción $T_j$ con $ts(T_j) > ts(T_i)$.
- Si $ts(T_i) < w-ts(Q)$, se rechaza la eliminación y $T_i$ retrocede. Esto es porque una transacción $T_j$ con $ts(T_j) > ts(T_i)$ ha escrito $Q$.
- Si $T_i \geq w-ts(Q)$ y $T_i \geq r-ts(Q)$, la operación de eliminación se ejecutara sin problema alguno.

Por su parte, la operación inserción tiene conflictos con las operaciones de lectura, escritura y eliminación, dado que no se puede realizar estas operaciones si el dato sobre el cual operar no existe. Dado que las inserciones le asigna un valor a $Q$, este se trata igual que la operación escritura para propósitos de control de concurrencia. Bajo el protocolo de bloqueo de dos fases, si $T_i$ realiza una operación de inserción, a $T_i$, se le da un bloqueo exclusivo en el dato $Q$ recién creado. Mientras que bajo el protocolo de ordenación por hora de entrada, si $T_i$ realiza la operación de inserción, los valores $r-ts(Q)$ y $w-ts(Q)$ se ponen en $ts(T_i)$.

### Fenómeno Fantasma

Sea $T_k$ una transacción que ejecuta la siguiente consulta:

```sql
SELECT SUM(saldo)
	FROM cuenta
	WHERE nombre_sucursal = 'Concordia';
```

Y $T_j$ otra transacción que ejecuta la siguiente inserción:

```sql
INSERT INTO cuenta VALUES (‘Concordia’, C-201, 900)
```

Sea $P$ un cronograma que involucra a $T_k$ y $T_j$. Se espera que haya un conflicto potencial debido a las razones siguientes:

1. Si $T_k$ utiliza la tupla que ha insertado recientemente $T_j$ para calcular la suma de los saldos, entonces $T_k$ lee el valor que ha escrito $T_j$. Así, en un cronograma serializable equivalente a $P$, $T_j$ debe ir antes de $T_k$.
2. Si $T_k$ no utiliza la tupla que ha insertado recientemente $T_j$ para calcular la suma de los saldos, entonces en un cronograma serializable equivalente a $P$, $T_k$ debe ir antes de $T_j$.

En el segundo caso $T_k$ y $T_j$ no acceden a ninguna tupla común, y sin embargo ambas transacciones están en conflicto por una tupla fantasma. Si bien este conflicto no es detectado si se realiza el control de concurrencia con granularidad de tupla, esto es un problema el resto de métodos.
Este problema recibe el nombre de ***fenómeno fantasma***. Para evitar este fenómeno se permite que $T_k$ impida a otras transacciones crear nuevas tuplas en la relación *cuenta* cuyo campo nombre_sucursal sea Concordia. Aun así, la solución más simple a este problema consiste en bloquear la relación *cuenta* en modo compartido.
En este caso las transacciones como $T_k$ , que lean tuplas pertenecientes a la relación cuenta, tendrían que bloquear el elemento de datos correspondientes a la relación en modo compartido. Mientras que las transacciones como $T_j$, que actualicen tuplas pertenecientes a la relación cuenta, tendrían que bloquear el elemento de datos en modo exclusivo. De este modo $T_k$ y $T_j$ tendrían un conflicto en un elemento de datos real, en lugar de tenerlo en uno fantasma, con el inconveniente de que baja el grado de concurrencia, ya que se impide que dos transacciones que inserten distintas tuplas en la relación se ejecuten concurrentemente.
Otra solución es utilizar el ***protocolo de bloqueo de índice***. Sea una transacción Ti, el protocolo opera de la siguiente manera:

1. Toda relación debe tener al menos un índice.
2. $T_i$ puede acceder a las tuplas de una relación únicamente después de haberlas encontrado primero a través de uno o más índices de la relación.
3. Si $T_i$ realiza una búsqueda debe bloquear en modo compartido todos los nodos hoja índices a los que accede.
4. $T_i$ no puede insertar, borrar o actualizar una tupla $t_i$ en una relación $r$ sin actualizar todos los índices de $r$. $T_i$ debe obtener bloqueos exclusivos sobre todos los nodos hoja índice que están afectados por la inserción, el borrado o la actualización.
5. Hay que cumplir las reglas del protocolo de bloqueo en dos fases.

>[!caution] Acaración sobre el Procedimiento
>En este caso solo se esta describiendo el procedimientos del protocolo de bloqueo por índice para los indices de árbol B⁺.
