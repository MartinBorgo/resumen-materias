Una de las propiedades fundamentales de las transacciones es el aislamiento. Cuando se ejecutan varias transacciones concurrentemente en la base de datos, puede que deje de conservarse la propiedad de aislamiento. Es necesario que el sistema controle la interacción entre las transacciones concurrentes; dicho control se lleva a cabo a través de uno de los muchos ***esquemas de control de concurrencia***.
El ***planificador (Scheduler)*** es el componente de las bases de datos encargado de asignar los recursos a las distintas transacciones y de gestionar el orden cronológico en que se ejecutan las instrucciones en el sistema de gestión de bases de datos. Este planificador recibe un ***schedule de entrada***, que consiste en las diversas operaciones ordenadas cronológicamente según cómo el gestor de bases de datos recibe las instrucciones, procesa esta entrada y obteniendo un ***schedule de salida***, que es el orden cronológico resultante del control de concurrencia que realiza.
## Esquemas Basados en Bloqueos
Los esquemas basados en bloqueos consisten en permitir que una transacción acceda a un dato, solo si ésta tiene actualmente un bloqueo sobre dicho dato. Existen varios modos de bloquear un dato, pero solo abarcaremos el esquema más básico que consta de dos modos de bloqueo:
- **Compartido (S)**: Si una transacción $T_i$ ha obtenido un bloqueo de un dato $Q$ en modo compartido, entonces $T_i$ puede leer el dato $Q$ pero no escribir $Q$. Este modo permite que otras transacciones puedan acceder y leer el dato sin problema alguno.
- **Exclusivo (X)**: Si la transacción $T_i$ obtuvo un bloqueo de un dato $Q$ en modo exclusivo, entonces solo $T_i$ puede leer y escribir $Q$. Este modo es el más restrictivo y permite que solo la transacción que bloqueo el dato pueda leer y modificar este mismo.

Cuando una transacción desbloquea datos inmediatamente después de su último acceso, puede comprometer la serializabilidad de la transacción. Para evitar esto, se puede mantener el bloqueo en los datos hasta el final de la transacción, es decir, liberar los datos una vez que la transacción se haya comprometido. Aunque esta estrategia preserva la serializabilidad de la transacción, puede dar lugar a ***interbloqueos***.

>[!tldr] Inanición
>Supongamos que una transacción $T_i$ tiene bloqueado un dato $Q$ en modo compartido, si una transacción $T_j$ quiere bloquear el dato de forma exclusiva va a tener que esperar hasta que $T_i$ libere dicho dato. El problema surge cuando otras transacciones también bloqueen de forma compartida a $Q$, produciendo una espera indefinida de la transacción $T_j$.
>Se puede evitar la inanición de las transacciones al conceder los bloqueos de la siguiente manera, cuando una transacción $T_i$ solicita un bloqueo sobre un dato $Q$ en un modo particular $M$, el gestor de control de concurrencia concede el bloqueo siempre que:
>
>1. No exista otra transacción que posea un bloqueo sobre $Q$ en un modo que esté en conflicto con el modo $M$.
>2. No existe otra transacción que esté esperando un bloqueo sobre $Q$ y que lo haya solicitado antes que $T_i$.
#### Protocolos de Bloqueo de dos Fases
Este protocolo requiere que todas las transacciones hagan sus solicitudes de bloqueo y desbloqueo en dos fases:
1. **Fase de crecimiento**: Una transacción puede obtener bloqueos, pero no puede liberar ninguno.
2. **Fase de encogimiento**: Una transacción puede liberar bloqueos, pero no puede solicitar ninguno nuevo.

Este protocolo garantiza la serializabilidad en conflictos. Sin embargo, no previene la aparición de interbloqueos. Otro problema que puede surgir con este protocolo es el ***retroceso en cascada*** de varias transacciones, esto ocurre debido a las ***lecturas no comprometidas*** o lecturas sucias (dirty reads), donde una transacción puede leer datos modificados por otra transacción que aún no ha sido comprometida. Para solucionar este problema se puede implementar un protocolo de bloqueo riguroso en dos faces, el cual bloquea todos los registros que va a utilizar en modo exclusivo y libera los bloqueos únicamente cuando la transacción se compromete. Esta estrategia se conoce como ***Read Committed*** y evita que las transacciones lean datos que no han sido definitivamente guardados en la base de datos.
Aunque esta técnica reduce los retrocesos en cascada, también disminuye la concurrencia, ya que algunas transacciones pueden quedar en la espera de ciertos recursos. Las ***conversiones de modos de bloqueo*** en una técnica alternativa que aumenta la concurrencia en las bases de datos, puesto que existen transacciones que solo necesitan un bloqueo exclusivo al final de su ejecución. Esto introduce al protocolo dos nuevos métodos:
- **Upgrade**: Conversión de un bloqueo en modo compartido a un bloqueo exclusivo.
- **Downgrade**: Conversión de un bloqueo exclusivo a un bloqueo en modo compartido.

Es importante tener en cuenta que el **upgrade** solo puede realizarse durante la fase de crecimiento del protocolo de bloqueo en dos fases, mientras que el **downgrade** solo puede realizarse durante la fase de encogimiento. Además, si una transacción intenta un **upgrade** en un recurso $Q$, puede verse obligada a esperar si otra transacción ya tiene un bloqueo compartido en $Q$.
### Protocolo Basados en Grafos
El protocolo de bloqueo de dos fases es necesario para asegurar la secuencialidad en ausencia de información sobre el acceso a los datos. Sin embargo, con información adicional sobre el orden de acceso, se pueden desarrollar protocolos alternativos.
El modelo más simple exige que se tenga un conocimiento sobre el orden al que se accede a los datos, una forma sencilla de brindar esta información es formando un grafo dirigido acíclico o árbol. El protocolo de árbol, solo permite bloquear datos de forma exclusiva, respetando las siguientes reglas:
1. El primer bloqueo de $T_i$ , puede ser en cualquier dato. A partir de ese momento, $T_i$ puede bloquear un dato $Q$ sólo si $T_i$ tiene actualmente bloqueado al padre de $Q$.
2. Los datos pueden desbloquearse en cualquier momento.
3. Si $T_i$ desbloqueo un dato, entonces $T_i$ no puede volver a bloquearlo nuevamente.

Este protocolo asegura la serializabilidad y evita interbloqueos, pero no garantiza la recuperabilidad ni tampoco la ausencia de retrocesos en cascadas. Para asegurar estos dos últimos factores se pueden mantener los bloqueos hasta el final de la transacción.
Aunque el protocolo de árbol evita interbloqueos, puede requerir bloqueos adicionales, reduciendo la concurrencia. Existen planificaciones posibles con el protocolo de dos fases que no son posibles con el de árbol, y viceversa.
## Esquemas Basados en Hora de Entrada
Estos protocolos garantizan la serializabilidad seleccionando por adelantado un orden entre las transacciones. El método más conocido empleado por este tipo de protocolos es el de **estampillas de tiempo (timestamp ordering)**, en el cual:
1. A cada transacción $T_i$, el sistema le asigna una hora de entrada fija y única representada por $ts(T_i)$.
2. Para cualquier transacción $T_k$ que entra después de $T_i$, se cumple que $ts(T_i) < ts(T_k)$.
3. La hora de entrada asignada a cada transacción determina el orden de serializabilidad, si $ts(T_i) < ts(T_k) \Rightarrow <T_i - T_k>$.

Algunos métodos para implementar las estampillas de tiempo incluyen el uso de la hora del sistema o la utilización de un contador lógico que se incrementa cada vez que se asigna una nueva $ts$. Generalmente, esta última opción es la más utilizada por las bases de datos.
Más allá del método utilizado para asignar los marcas de tiempo a cada transacción. Para implementar este sistema de forma adecuada necesitas asociamos dos valores de $ts$ a cada dato $Q$.
- $w-ts(Q)$: Representa la mayor $ts$ de la transacción más joven que ejecutó con éxito la operación de escritura en $Q$.
- $r-ts(Q)$: Representa la mayor $ts$ de la transacción más joven que ejecutó con éxito la operación de lectura en $Q$.

>[!note] Aclaración sobre la Actualización de la Estampilla de Tiempo de los Datos
>Las estampillas de tiempo de lectura y escritura asociada a cada dato no siempre se actualiza cuando una transacción accede o modifica el dato en cuestión. Estas estampillas se actualizan únicamente si la transacción que modifico o accedió al dato es más nueva que la última transacción que realizó dicha acción.

De esta manera el protocolo garantiza que todas las operaciones de lectura y escritura que puedan entrar el conflicto se ejecuten de acuerdo al orden de $ts$.
### Protocolo de Ordenación por Marca de Tiempo
Al igual que los protocolos de bloqueo en dos fases, las lecturas no comprometidas pueden provocar un retraso en cascada, con la diferencia que en este caso se le agrega el problema de ***transacciones no recuperables***, ya que una transacción $T_i$ que leyó datos de una transacción $T_k$, no se puede comprometer hasta que no se comprometa $T_k$. La versión más pura y básica de este protocolo realiza las lecturas y escrituras siguiendo estos dos criterios:
- Si $T_i$ solicita una lectura sobre un dato $Q$, entonces se debe cumplir que $ts(T_i) \geq w-ts(Q)$, en caso de que esta condición se cumpla se ejecuta la operación de lectura y se actualiza la estampilla de tiempo de lectura sobre $Q$ de la siguiente manera $r-ts(Q) = max[r-ts(Q), ts(T_i)]$. Si esta condición no se cumple esto implica que $T_i$ está intentando leer un valor que fue sobreescrito por una transacción más joven, por lo tanto, la transacción retrocede.
- Si $T_i$ solicita una escritura sobre un dato $Q$, entonces se debe cumplir que $ts(T_i) \geq r-ts(Q) \wedge ts(T_i) \geq w-ts(Q)$ en caso de que ambas condiciones se cumplan se ejecuta la operación de escritura y se actualiza la estampilla de tiempo de escritura sobre $Q$ de la siguiente manera $w-ts(Q) = ts(T_i)$. Si una de las dos condiciones no se cumple $T_i$ retrocederá, puesto que o llego tarde a realizar la escritura de dicho valor o dicho valor a escribir es obsoleto porque una transacción más joven sobreescribió ese valor con anterioridad.

Las ***reglas de escritura de Thomas*** son una pequeña modificación al procedimiento de escritura la cual ayuda a mejorar el grado de concurrencia, manejando los conflictos de escritura entre transacciones de manera más eficiente. De forma resumida la regla de Thomas modifica levemente las acciones que se realizan al momento de escribir un dato. Esta regla dicen lo siguiente:
- Si $T_i$ solicita una escritura sobre un dato $Q$, entonces se debe cumplir que $ts(T_i) \geq r-ts(Q) \wedge ts(T_i) \geq w-ts(Q)$ en caso de que ambas condiciones se cumplan se ejecuta la operación de escritura y se actualiza la estampilla de tiempo de escritura sobre $Q$ de la siguiente manera $w-ts(Q) = ts(T_i)$. Si la segunda condición no es cumplida por $T_i$, el planificador simplemente ignora la operación de escritura y continua normalmente con su ejecución, esto evita el retroceso innecesario de la transacción. $T_i$ solo retrocederá si no puede cumplir con la primera condición establecida en el protocolo.
### Protocolos Basados en Validación (Optimistas)
En ocasiones particulares, como aquellas donde se realizan muchas más transacciones de lectura que de escritura, resulta conveniente utilizar un método de evaluación optimista, debido a que la tasa de conflictos entre las transacciones es baja. Así, muchas de esas transacciones, si se ejecutasen sin la supervisión de un esquema de control de concurrencia, llevarían no obstante al sistema a un estado consistente. Aplicando métodos alternativos de validación podemos disminuir la sobrecarga del sistema sin perder consistencia en la base de datos.
La dificultad de reducir la sobrecarga está en que no se conocen de antemano las transacciones que estarán involucradas en un conflicto. Para obtener dicho conocimiento se necesita un esquema para supervisar el sistema.
Por lo general cada transacción $T_i$ se ejecuta en dos o tres fases diferentes durante su tiempo de vida dependiendo de si es una transacción de solo lectura o una que involucra escrituras. Las fases son las siguientes:
1. **Fase de lectura**: Durante esta fase tiene lugar la ejecución de la transacción $T_i$ se leen los valores de varios elementos de datos y se almacenan en variables locales.
2. **Fase de validación**: La transacción $T_i$ realiza una prueba de validación para determinar si puede copiar en la base de datos las variables locales temporales que tienen los resultados de las operaciones de escritura sin causar una violación de la secuencialidad.
3. **Fase de escritura**: Si la transacción $T_i$ tiene éxito en la validación entonces las actualizaciones reales se aplican a la base de datos. En otro caso, $T_i$ retrocede.

Para realizar la prueba de validación se necesita conocer el momento en que tienen lugar las distintas fases de las transacciones $T_i$. Por lo tanto, se asocian tres marcas temporales distintas a la transacción $T_i$ :
- $Ini(T_i)$: Hora de comienzo de $T_i$.
- $Val(T_i)$: Hora en la que $T_i$ terminó su fase de lectura y comenzó su fase de validación.
- $Ter(T_i)$: Hora en la que $T_i$ terminó su fase de escritura.

El proceso de validación para la transacción $T_i$ exige que, para toda transacción $T_k$ con $ts(T_k) < ts(T_i)$, se cumplan una de las dos condiciones siguientes:
1. $Ter(T_k) < Ini(T_i)$. Puesto que $T_k$ completa su ejecución antes de que comience $T_i$.
2. El conjunto de todos los elementos de datos que escribe $T_k$ tiene intersección vacía con el conjunto de elementos de datos que lee $T_i$, y $T_k$ completa su fase de escritura antes de que $T_i$ comience su fase de validación.

El esquema de validación evita automáticamente los retrocesos en cascada, ya que las escrituras reales tiene lugar solo después que la transacción se haya comprometido. Sin embargo, existe una posibilidad de inanición de las transacciones largas debido a una secuencia de transacciones cortas conflictivas que provoca reinicios repetidos de la transacción larga. Para evitar la inanición es necesario bloquear las transacciones conflictivas de forma temporal para permitir que la transacción larga termine.
## Esquemas Multiversión
Los esquemas de control de concurrencia tratados hasta aquí, garantizan la serializabilidad retrasando la transacción o bien abortando la transacción que solicitó una operación. Este problema puede evitarse si se mantiene las copias antiguas de todos los datos en el sistema.
En los sistemas multiversión cada operación de escritura sobre $Q$ crea una nueva versión del dato $Q$. Cuando se realiza una operación de lectura sobre este dato, el sistema selecciona una de las versiones de $Q$ para leerse.
La técnica más utilizada para los esquemas multiversión es la de estampillas de tiempo, en donde a cada dato $Q$ se le asocia una secuencia de versiones $<Q_1, Q_2, \dots, Q_N>$, donde cada versión $Q_k$ contiene tres campos de información:
- **Contenido**: Valor de la versión $Q_k$.
- $w-ts(Qk)$: estampilla de tiempo de la transacción que creó la versión $Q_k$.
- $r-ts(Qk)$: estampilla de tiempo de la transacción más joven que leyó con éxito la versión $Q_k$.

Una transacción $T_i$ crea una versión $Q_k$ del dato $Q$, cuando ejecuta la operación de escritura sobre $Q$. El campo contenido tendrá el valor que escribió $T_i$ y $w-ts(Q_k) = r-ts(Q_k) = ts(T_i)$. El valor $r-ts(Q_k)$ puede modificarse cuando una transacción $T_j$ lee $Q_k$ y $r-ts(Q_k) < ts(T_j)$.
Si una transacción $T_j$ solicita una operación de lectura o escritura sobre $Q$, y $Q_k$ es una versión de $Q$ cuya estampilla de tiempo de escritura es el $ts$ más grande, menor que $ts(T_j)$, entonces se lleva a cabo una de las siguientes operaciones:
1. Si $T_j$ quiere realizar una lectura sobre $Q$, entonces el valor devuelto es el contenido de la versión $Q_k$.
2. Si $T_j$ quiere realizar una operación de escritura sobre $Q$, y $ts(T_j) < r-ts(Q_k)$, entonces la transacción $T_i$ retrocede; en caso contrario se crea una nueva versión $Q_i$.

La justificación de la primera operación es clara, una transacción lee la versión más reciente que viene antes de ella en el tiempo. La segunda regla fuerza a que se aborte una transacción que realice una escritura tardía de $Q$. Siendo más precisos, si $T_j$ intenta escribir una versión que alguna otra transacción haya leído, entonces no se puede permitir que dicha escritura tenga éxito.
Las versiones que ya no se necesitan se borran basándose en la regla siguiente. Supóngase que hay dos versiones, $Q_k$ y $Q_j$, de un elemento de datos y que ambas tienen $w-ts$ menor que la marca temporal de la transacción más antigua en el sistema, lo que significa que ni una de esas versiones será utilizada por ninguna de las transacciones activas en el sistema, por ende, estas pueden ser borradas.

>[!tldr] Ventajas y Desventajas de los Esquemas Miltiversión
>- **Ventajas**:
>	- Las operaciones de lectura nunca fallan y nunca se tiene que esperar.
>- **Desventajas**:
>	- La lectura de un dato tiene también que actualizar $r-ts(Q_k)$, que resulta en dos accesos potenciales a disco en vez de uno.
>	- Los conflictos entre transacciones se resuelven a través de retrocesos en lugar de esperas, lo que puede llegar a generar un retroceso en cascada.
## Inserciones y Eliminación de Datos
Algunas transacciones, no solo requieren accesos a datos que ya existen, sino también la posibilidad de crear nuevos datos o eliminar datos, en este caso deberemos contemplar estas dos nuevas operaciones:
- $delete(Q)$: Elimina el dato $Q$ de la base de datos.
- $insert(Q)$: Inserta un nuevo dato $Q$ a la base de datos y le da un valor inicial.

Sean $I_i$ e $I_k$ instrucciones de las transacciones $T_i$ y $T_k$ respectivamente, que aparecen en un cronograma $S$ en orden consecutivo. Sea $I_i = delete(Q)$ una instrucción a ejecutar, se pueden dar una de las siguientes situaciones:
- Si $I_k = read(Q)$ entonces $I_i$ e $I_k$ tienen conflictos solo si $I_i$ viene antes de $I_k$. $T_k$ tendrá un error lógico, ya que ese registro ya habrá sido eliminado.
- Si $I_k = write(Q)$ entonces $I_i$ e $I_k$ tienen conflictos solo si $I_i$ viene antes de $I_k$. $T_k$ tendrá un error lógico, porque el registro no existe.
- Si $I_k = delete(Q)$ entonces $I_i$ e $I_k$ tienen conflictos si $I_i$ viene antes de $I_k$. $T_k$ tendrá un error lógico, puesto que el registro ya habrá sido eliminado. Lo mismo ocurre si $I_k$ viene antes de $I_i$.
- Si $I_k = insert(Q)$ entonces $I_i$ e $I_k$ tienen conflictos, porque si $Q$ no existe antes de las ejecuciones de $I_i$ e $I_k$, entonces si $I_i$ se ejecuta antes de $I_k$, $T_i$ producirá un error lógico porque intentará eliminar un registro que no existe. Sin embargo, si $I_k$ se ejecuta antes de $I_i$, esto no ocurrirá. Por otro lado, si $Q$ existía antes de las ejecuciones de $I_i$ e $I_k$, se producirá un error lógico si $I_k$ se ejecuta antes de $I_i$ porque $I_k$ intentará insertar un registro que ya existe, en caso contrario no ocurrirá ningún error.

La forma de hacer frente a estos conflictos va a depender del protocolo utilizado por la base de datos para manejar la concurrencia, en caso de emplear un bloqueo de dos fases el registro debe tener un bloqueo exclusivo en ese dato antes de poder realizar la eliminación. En cambio, en caso de emplear un equema basado en hora de entrada se debe realizar una prueba similar a la que se realiza con la operación de escritura:
- Si $ts(T_i) < r-ts(Q)$, se rechaza la eliminación y $T_i$ retrocede. Esto es porque el valor de $Q$ que $T_i$ iba a suprimir, ya ha sido leído por una transacción $T_j$ con $ts(T_j) > ts(T_i)$.
- Si $ts(T_i) < w-ts(Q)$, se rechaza la eliminación y $T_i$ retrocede. Esto es porque una transacción $T_j$ con $ts(T_j) > ts(T_i)$ ha escrito $Q$.
- Si $T_i \geq w-ts(Q) \wedge T_i \geq r-ts(Q)$ la operación de eliminación se ejecutara sin problema alguno.

Por su parte, la operación inserción tiene conflictos con las operaciones de lectura, escritura y eliminación, dado que no se puede realizar estas operaciones si el dato sobre el cual se opera no existe.
Dado que las inserciones le asigna un valor a $Q$, este se trata igual que la operación escritura para propósitos de control de concurrencia. Bajo el protocolo de bloqueo de dos fases, si $T_i$ realiza una operación de inserción, a $T_i$ se le da un bloqueo exclusivo en el dato $Q$ recién creado. Mientras que bajo el protocolo de ordenación por hora de entrada, si $T_i$ realiza la operación de inserción, los valores $r-ts(Q) = w-ts(Q) = ts(T_i)$, es decir, los valores de lectura y escritura para el nuevo dato son el mismo que la transacción que la introdujo a la base de datos.
### Fenómeno Fantasma
Sea $T_k$ una transacción que ejecuta la siguiente consulta:
```sql
SELECT SUM(saldo)
	FROM cuenta
	WHERE nombre_sucursal = 'Concordia';
```

Y $T_j$ otra transacción que ejecuta la siguiente inserción:
```sql
INSERT INTO cuenta VALUES ('Concordia', 'C-201', 900)
```

Sea $P$ un cronograma que involucra a $T_k$ y $T_j$. Se espera que haya un conflicto potencial debido a las razones siguientes:
1. Si $T_k$ utiliza la tupla que ha insertado recientemente $T_j$ para calcular la suma de los saldos, entonces $T_k$ lee el valor que ha escrito $T_j$. Así, en un cronograma serializable equivalente a $P$, $T_j$ debe ir antes de $T_k$.
2. Si $T_k$ no utiliza la tupla que ha insertado recientemente $T_j$ para calcular la suma de los saldos, entonces en un cronograma serializable equivalente a $P$, $T_k$ debe ir antes de $T_j$.

En el segundo caso $T_k$ y $T_j$ no acceden a ninguna tupla común, y sin embargo ambas transacciones están en conflicto por una tupla fantasma. Si bien este conflicto no es detectado si se realiza el control de concurrencia con granularidad de tupla, esto es un problema para el resto de métodos.
Este problema recibe el nombre de ***fenómeno fantasma***. Para evitar este fenómeno se permite que $T_k$ impida a otras transacciones crear nuevas tuplas en la relación *cuenta* cuyo campo `nombre_sucursal` sea Concordia. Aun así, la solución más simple a este problema consiste en bloquear la relación `cuenta` en modo compartido.
En este caso las transacciones como $T_k$ , que lean tuplas pertenecientes a la relación cuenta, tendrían que bloquear el elemento de datos correspondientes a la relación en modo compartido. Mientras que las transacciones como $T_j$, que actualicen tuplas pertenecientes a la relación cuenta, tendrían que bloquear el elemento de datos en modo exclusivo. De este modo $T_k$ y $T_j$ tendrían un conflicto en un elemento de datos real, en lugar de tenerlo en uno fantasma, con el inconveniente de que baja el grado de concurrencia, ya que se impide que dos transacciones que inserten distintas tuplas en la relación se ejecuten concurrentemente.
Otra solución es utilizar el ***protocolo de bloqueo de índice***. Sea una transacción $T_i$, el protocolo opera de la siguiente manera:
1. Toda relación debe tener al menos un índice.
2. $T_i$ puede acceder a las tuplas de una relación únicamente después de haberlas encontrado primero a través de uno o más índices de la relación.
3. Si $T_i$ realiza una búsqueda debe bloquear en modo compartido todos los nodos hoja índices a los que accede.
4. $T_i$ no puede insertar, borrar o actualizar una tupla $t_i$ en una relación $r$ sin actualizar todos los índices de $r$. $T_i$ debe obtener bloqueos exclusivos sobre todos los nodos hoja índice que están afectados por la inserción, el borrado o la actualización.
5. Hay que cumplir las reglas del protocolo de bloqueo en dos fases, es decir, contar con una primera etapa donde solo se realizan bloqueos y una segunda en donde solo se librean estos bloqueos.

>[!caution] Acaración sobre el Procedimiento
>En este caso solo se esta describiendo el procedimientos del protocolo de bloqueo por índice para los indices de árbol B⁺.

