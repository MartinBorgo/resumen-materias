Al especificar un valor de punto de compromiso para cada nodo, se asegura de que el servidor más crítico no se bloquee si se produce un fallo durante la fase de preparación o confirmación. Para establecer la ***commit point strength*** de una base de datos basta con agregar una línea adicional en el archivo de configuración durante la inicialización de esta misma. Este valor solo se utilizará para determinar el punto de commit en una transacción distribuida.
>[!note] Punto de Compromiso y Fuerza del Punto de Compromiso
>En una transacción distribuida, el *punto de compromiso* es el momento en el que se decide que una transacción puede ser finalizada y sus cambios aplicados de manera permanente. Este punto es crucial porque asegura que todos los nodos involucrados en la transacción estén de acuerdo en que la transacción puede ser completada sin errores.
>Por otro lado, cuando hablamos de *fuerza del punto de compromiso* (*commit point strenght*) se refiere a la importancia del nodo que se elige para almacenar el punto de compromiso. Un nodo con una alta *commit point strength* es uno que es menos probable que falle y que está siempre disponible. Esto es importante porque si el nodo que almacena el punto de compromiso falla podría producir un bloqueo en el sistema.

Dado que el punto de compromiso almacena información sobre el estado de la transacción, este debe ser almacenado en un nodo que no se caiga a menudo y que siempre esté disponible en caso de que otros nodos necesiten información sobre el estado de la transacción. Por lo que se recomienda que la *commit point strength* se establezca en función de la cantidad de datos críticos que se comparten en la base de datos. Esto significa que si una base de datos maneja datos muy importantes, el nodo que almacena el punto de compromiso debe ser especialmente robusto y confiable.
## Resolución de Transacciones Dudosas en Oracle
El compromiso en tres fases asegura que todos los nodos se comprometan o retrocedan en forma conjunta. En caso de que suceda alguno de los siguientes problemas la transacción se convierte en ***dudosa*** (In-Doubt):
1. Un servidor que ejecuta el software de la base de datos se bloquea.
2. Se desconectan de la red dos o más nodos que estaban involucrados en la transacción global.
3. Se produce un error de software no manejado.

En la mayoría de los casos, la base de datos resuelve automáticamente la transacción que está en duda a través de un ***proceso de recuperación***. Aunque el proceso de resolución de dicho problema depende de la fase en la que se encuentre la transacción distribuida. Si el error ocurre durante la fase de preparación, sucede la siguiente secuencia de eventos:
1. Un usuario se conecta a un cliente y ejecuta una transacción de forma distribuida.
2. El coordinador global de la transacción pide a todas las bases de datos involucradas que se comprometan o que retrocedan de acuerdo a las órdenes que esté mismo dé.
3. Una de las bases de datos se bloquea antes de emitir su respuesta al coordinador.
4. Se ejecuta el proceso de recuperación y hace que la transacción retroceda en cada base de datos involucrada en la transacción global, una vez que el sistema caído se haya restaurado.

En caso de que el error ocurra en la fase de compromiso, la secuencia de eventos que sucede es la siguiente:
1. Un usuario se conecta a un cliente y ejecuta una transacción de forma distribuida.
2. El coordinador global de la transacción pide a todas las bases de datos involucradas que se comprometan o que retrocedan de acuerdo a las órdenes que esté mismo dé.
3. El coordinador recibe el mensaje *prepared* por parte de los demás nodos involucrados.
4. El coordinador confirma la transacción localmente y luego envía un mensaje de *commit* al resto de nodos para que ellos también comprometan la transacción.
5. Una de las bases de datos involucradas recibe el mensaje, pero no puede responder debido a un fallo de red.
6. El proceso de recuperación hace que la transacción se comprometa en dicha base de datos una vez que esta se recupere del fallo de red.

Puede que existan ocasiones en las que se tenga que resolver los fallos en las transacciones de forma manual, ya sea porque una transacción en duda tiene bloques en los datos críticos o segmentos en *undo* o porque lo que causo el fallo, ya sea de sistema, red o software, no puede ser solucionado rápidamente.
Cuando se resuelve una transacción de forma manual, primero se debe identificar el número de transacción en cuestión, bases de datos como Oracle te permiten consultar ciertas vistas para saber que bases de datos están involucradas en dicha transacción. En caso de que sea necesario se puede forzar un compromiso o un retroceso, aunque esto suele usarse en casos extremos.
## Control de Concurrencia en Sistemas Distribuidos
Al momento de realizar las transacciones en los sistemas distribuidos se da por supuesto que cada sitio participa en la ejecución de un protocolo de compromiso para garantizar la atomicidad global de las transacciones.
>[!tldr] Control de Concurrencia sin Réplica y Por Fragmentación
>El esquema más sencillo de concurrencia es centralizando todas las relaciones en un solo nodo, dichas relaciones no poseerán ningún tipo de réplica o fragmentación. Un único nodo contiene toda la base de datos y brinda los servicios de datos al resto de nodos. Este esquema es fácil de implementar y todo el control de concurrencia se realiza de forma centralizada, con la desventaja que este tipo de sistemas tiene una menor tolerancia al fallo.
>Otro esquema alternativo es asignar a cada localidad un fragmento de datos distinto, por ejemplo, que cada sucursal bancaria maneje solo los datos de sus propios clientes, de esta forma cada consulta específica de datos se hará sobre una única localidad. Este enfoque aumenta la tolerancia a fallos, permite la utilización de datos remotos.

Los diferentes protocolos de bloqueo mencionados en la unidad anterior se pueden utilizar en entornos distribuidos. La única modificación que hay que incorporar es el modo en que el gestor de bloqueos trata los datos replicados, a partir de esa modificación se pueden aplicar distintos enfoques:
- **Gestor único de bloqueos**: Implica que un único gestor $S_i$, maneje todas las solicitudes de bloqueo y desbloqueo. Cuando una transacción necesita bloquear un dato, envía la solicitud a $S_i$, este decide si conceder el bloqueo o retrasarlo hasta que sea posible. Las lecturas de datos se pueden realizar desde cualquier sitio con una réplica, pero las escrituras requieren la participación de todos los sitios con réplicas. Este esquema es sencillo de implementar y facilita el manejo de interbloqueos, ya que todas las solicitudes se concentran en un solo sitio. Sin embargo, se pueden producir cuello de botella en $S_i$, además de presentar cierta vulnerabilidad, porque si $S_i$ falla, se pierde el control de concurrencia, lo que requiere detener el procesamiento o aplicar un esquema de recuperación.
- **Gestión distribuida de bloques**: Distribuye la función de gestor de bloqueos entre varios sitios, donde cada sitio maneja localmente las solicitudes de bloqueo y desbloqueo para los datos almacenados en ese sitio. Cuando una transacción desea bloquear un dato no replicado, envía la solicitud al gestor local del sitio correspondiente. Si el dato ya está bloqueado en un modo incompatible, la solicitud se retrasa hasta que pueda concederse. Una vez aprobada, se notifica al sitio de origen. Este esquema disminuye el cuello de botella y mantiene una implementación sencilla. Sin embargo, el manejo de interbloqueos es más complejo porque las solicitudes se gestionan en múltiples sitios, lo que puede generar interbloqueos globales que requieren algoritmos modificados para su detección y resolución.
- **Copia principal**: Se designa una de las réplicas del dato $Q$ como copia principal de dicho dato, esta copia principal reside en un sitio único, denominado ***sitio principal*** de $Q$. Cuando una transacción necesita bloquear $Q$, solicita el bloqueo en su sitio principal, y la solicitud se gestiona de la misma manera que para datos no replicados. Esto simplifica la implementación del control de concurrencia. Sin embargo, si el sitio principal falla, el dato $Q$ se vuelve inaccesible, incluso si otras réplicas están disponibles en otros sitios.
### Manejo de Concurrencia en Esquemas Con Réplica
Como ya mencionamos cuando hablamos de [[2. Recuperacion de Fallos en las Transacciones|recuperación ante fallos]], uno de los enfoques más sencillos que se puede utilizar para mejorar la disponibilidad es utilizar un ***servidor central primario*** y un base de datos espejo la cual, en caso de que el servidor central caiga, se tomará a la copia secundaria como primaria y se redireccionará todas las peticiones a esta misma. Una alternativa más conveniente sería tener un sitio primario para cada fragmento, aumentando así la disponibilidad al máximo.
Dado que existe un lugar central donde se almacenan los datos, todo el control de concurrencia y la asignación de los bloqueos puede realizarse en el mismo sitio primario. Pueden existir casos extremos en los que un nodo distinto al primario esté encargado de asignar los bloqueos, tal y como se describió con anterioridad.
>[!tldr] Control Concurrencia en Esquemas de Copia Primaria Mediante Manejo de Token
>Una alternativa al anterior esquema propuesto es realizar el control de concurrencia mediante el intercambio de *tokens* entre los distintos nodos de la red, este esquema separa la administración de los datos de su ubicación física. Cada dato tiene tokens de lectura ($r-token$) y un único token de escritura ($w-token$). El administrador del dato posee un token que circula bajo demanda.
>Para obtener un $r-token$, una transacción envía solicitudes a todos los nodos, estos nodos pueden responder:
>- ***OK*** si el nodo tiene un $r-token$ o ningún token, o si tiene un $w-token$ pero no necesita. En tal caso destruye el token de escritura para luego responder a la petición afirmativamente.
>- ***Deny*** si el nodo en cuestión tiene un $w-token$ y lo necesita.
> 
>La transacción recibe un $r-token$ y confirma la reserva si colecta $n$ confirmaciones positivas, o espera/aborta si recibe una confirmación negativa. Para obtener un $w-token$, la transacción también envía solicitudes a todos los nodos, estos nodos pueden responder:
>- ***OK*** si el nodo no tiene un token, anotando una reserva, o si tiene un token, pero no lo necesita. En tal caso destruye los tokens que no utiliza y anotando una reserva. 
>- ***Deny*** si el nodo tiene un token y lo necesita o si tiene anotado un reserva de $w-token$.
> 
>La transacción recibe un $w-token$ y confirma la reserva si colecta $n$ confirmaciones positivas, o espera/aborta y destruye la reservas si recibe una confirmación negativa.

Se puede aumentar mucho más la disponibilidad y tiempos de acceso teniendo más de una réplica de las relaciones o fragmentos. En estos casos se deja que cada localidad administre sus propias copias, de esta manera se logra una mayor concurrencia, tolerancia a fallos y disponibilidad.
Como cada localidad maneja y gestiona sus propias réplicas se necesita mecanismos para el control de las réplicas garantizando así la consistencia de cada una de las réplicas. Cada cambio que se haga a nivel de réplica individual debe ser reflejado en el resto de réplicas para mantener la consistencia en los datos. Existen diversos protocolos y métodos que se utilizan para mantener la consistencia entre réplicas:
- **Read One - Write All (ROWA)**: En este protocolo para realizar una lectura sobre un dato $Q$ se dirige a la primera copia libre que se encuentre de dicho dato y lo lee. En caso de ya conocer la ubicación de $Q$ el traspaso de mensajes será mínimo. Para escribir el dato $Q$ primero se deben bloquear todas las réplicas de dicho dato para posteriormente modificarlos de forma atómica.
- **Protocolo de mayoría**: Este protocolo funciona de la siguiente manera, si se quiere leer o escribir un dato $Q$ que se replica en $n$ localidades diferentes, entonces la transacción debe enviar una solicitud de bloqueo a la mayoría de las réplicas para poder realizar la operación.
- **Protocolo de consenso de quorum**: Este protocolo es una generalización del protocolo de mayoría. Este protocolo asigna a cada localidad un peso no negativo. Además, asigna a las operaciones de lectura y escritura sobre un dato $Q$ dos enteros denominados ***quorum de lectura*** $Q_r$ y ***quorum de escritura*** $Q_w$. Para poder realizar una operación de lectura o escritura una transacción debe bloquear las suficientes réplicas de forma tal que la suma de sus pesos sea superior a la de $Q_r$ o $Q_w$ respectivamente.

>[!note] Inconveniente del Protocolo de Mayoría y de Consenso de Quorum
>El principal problema del protocolo de mayoría es que pueden ocurrir interbloqueos extremadamente complejos que requieran de técnicas mucho más refinadas para la detección de estos mismos.
>Algo similar sucede con el protocolo de consenso de quorum, si bien este es una generalización del de mayoría, dependiendo de como se asignen los pesos y los quorums este se puede comportar igual al protocolo de mayoría. 

Todos los enfoques anteriores se centraban en el uso de esquemas de bloqueo para manejar la concurrencia. Sin embargo, en las bases de datos distribuidas también es posible gestionar la concurrencia mediante un enfoque basado en marcas temporales o utilizando réplicas con niveles reducidos de consistencia.
## Resolución de Interbloqueos
Los algoritmos de evasión, prevención y detección de interbloqueos pueden utilizarse en sistemas distribuidos, aunque requieren modificaciones. Dado que la prevención de interbloqueos introduce esperas y retrocesos innecesarios, además de involucrar más sitios de los necesarios en la ejecución de una transacción, se suele optar por otros enfoques.
>[!info] Prevención de Interbloqueos Utilizando Tiempos de Espera (Timeout)
>Una de las formas más simples de prevenir interbloqueos es utilizando periodos de espera mínimos para abortar o retroceder las transacciones, en este tipo de esquemas el tiempo de espera debe ser lo suficientemente corto como para que las transacciones que están interbloqueo no retengan los bloqueos por mucho tiempo, y lo suficientemente largo como para que no se produzcan retroceso de transacciones que no están en interbloqueo.
>Este enfoque, al contrario que el de grafos de espera no requiere del envío y recepción de mensajes, además que no suele abortar transacciones que no están en interbloqueos. La principal desventaja es que este método es propenso a abortar todas las transacciones que están en interbloqueo en lugar de solo abortar una, que por lo general suele ser suficiente para acabar con el interbloqueo.

Si se permite que los interbloqueos ocurran y se confía en su detección, entonces el principal desafío de los sistemas distribuidos radicaría en la mantención del ***grafo de espera***. Para dar solución a este problema, cada sitio guarda un ***grafo local de espera*** que refleja las transacciones locales y no locales que solicitan recursos en ese sitio. Si un grafo local tiene un ciclo, se ha producido un interbloqueo.
La ausencia de ciclos en los grafos locales no garantiza que no haya interbloqueos a nivel global, ya que la combinación de grafos locales puede formar un ciclo. En un enfoque centralizado, un sitio coordinador mantiene un grafo global de espera, que combina todos los grafos locales. Si se detecta un ciclo en este grafo global, se selecciona una transacción como víctima para retroceder. Sin embargo, este enfoque puede generar retrocesos innecesarios debido a ciclos falsos causados por la desincronización en la comunicación entre sitios.
>[!tldr] Problemas del Enfoque Centralizado
>En los enfoques centralizados, el sistema es mucho más vulnerable ante la falla del nodo encargado de mantener el grafo de espera global, además gran parte del tráfico es concentrado por este nodo, si bien el tráfico en términos generales es reducido es un factor a recalcar. Este tipo de enfoques posee los mismos problemas que los protocolo de bloqueo centralizados.
>Optando por un enfoque más distribuido aumentaría la tolerancia a fallas. En este caso cada nodo envía, recibe y fusiona los grafos de espera, de esta manera cada nodo será consciente de la ocurrencia de un interbloqueo ya sea local o global. En este esquema el tráfico de red aumenta considerablemente, no obstante si los mensajes intercambiados entre nodos no contiene mucha información se puede anexar los grafos de espera locales a estos mismos en un intento por reducir la saturación de la red.  

Se puede utilizar también los protocolos basados en estampillas de tiempo, en este caso se asigna una estampilla de tiempo a cada transacción, de esta forma se garantiza que no se produzcan ciclos en el grafo de espera global. El control de concurrencia se puede realizar utilizando los enfoque de Esperar-Morir o Herir-Espera de acuerdo a las necesidades.