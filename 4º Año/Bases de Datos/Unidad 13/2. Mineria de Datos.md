La ***minería de datos (DM)*** consiste en la extracción no trivial de conocimiento que reside de manera implícita en los datos. Es un proceso analítico diseñado para explorar grandes cantidades de datos en búsqueda de patrones consistentes y/o relaciones sistemáticas entre variables, y luego validar el hallazgo aplicando los patrones encontrados a nuevos conjuntos de datos.
La información o conocimiento previamente desconocido puede ser de gran utilidad en procesos de toma de decisiones. La minería de datos agrupa un conjunto de técnicas cuyo objetivo es extraer conocimiento procesable que se encuentra implícito en las bases de datos. Si bien la cantidad de datos puede ser gigantescas, este conjunto en bruto de datos no dice nada por sí mismo, es por eso que resulta conveniente realizar un procesamiento de estos mismos con el fin de generar nueva información que sea de utilidad para la toma de decisiones.
## Clasificación de Tipos de Datos
Los datos que conforman los distintos atributos de un registro pueden ser de distintos tipos, cada uno de este tipo de datos tiene un conjunto de propiedades diferentes. Los datos pueden ser:
- **Nominales**: Aquellos datos sobre los cuales solo se pueden realizar operaciones de distinción, como en el caso de los colores, localidades o nombres. 
- **Ordinales**: Datos sobre los cuales se pueden realizar operaciones de distinción y de orden, como es el caso de un ranking o talles.
- **Intervalos**: Datos sobre los que se pueden realizar operaciones de distinción, orden y adición, como por ejemplo fechas, temperatura medida en grados Celsius, entre otras.
- **Proporcionales**: Datos sobre los cuales se pueden realizar operaciones de distinción, adición, orden y multiplicación. Por ejemplo: temperatura en grados Kelvin, longitudes, tiempos o conteos.

>[!tldr] Propiedades de los Datos
>Nos referimos a propiedades como el conjunto de operaciones que se pueden realizar sobre un dato en particular. Dichas operaciones pueden ser clasificadas como:
>- **Distinción**: Abarca las operaciones de igualdad y desigualdad ($= | \neq$).
>- **Orden**: Abarca las operaciones de mayor y menor ($< | >$).
>- **Adición**: Abarca las operaciones de suma y resta ($+ | -$).
>- **Multiplicación**: Abarca las operaciones de multiplicación y división ($* | /$).
## Metodologías para Minería de Datos
Las metodologías de minería de datos son marcos estructurados y sistemáticos que guían el proceso de extraer conocimiento útil a partir de grandes volúmenes de datos. Las más conocidas son ***CRISP-DM (Cross Industry Standard Process for Data Mining)*** y ***KDD (Knowledge Discovery in Databases)***.
El principal objetivo de este tipo de metodologías es transformar los datos en bruto de forma tal que los mismos resulten útiles para la toma de decisiones.
### Proceso Estándar Interindustrial para el Minado de Datos (CRISP-DM)
Es una metodología utilizada para estructurar, guiar y organizar proyectos de minería y análisis de datos. Esta metodología es útil para ilustrar cómo una empresa puede pasar de tener un objetivo de negocio general, a implementar una solución de análisis de datos para tomar decisiones proactivas. Esta metodología cuenta con las siguientes fases:
1. **Comprensión del negocio**: En esta fase se definen los objetivos del proyecto, se evalúa la situación actual y se establecen las metas de minería de datos.
2. **Comprensión de los datos**: Esta fase incluye la recolección inicial, descripción, exploración y verificación de la calidad de los datos. Todas estas acciones se llevan a cabo con el fin de verificar la presencia de valores nulos o atípicos, comprender como están distribuidos los datos, etc.
3. **Preparación de los datos**: En esta fase se realizan tareas como la limpieza de los datos, la selección de variables relevantes, la transformación, además del formateo e integración de diferentes fuentes de datos.
4. **Modelado**: En esta etapa se seleccionan las técnicas de minería de datos más apropiadas a aplicar sobre los datos, se construye el o los modelos y se realiza una evaluación preliminar de los mismos. En esta etapa también se suele ajustar los parámetros o recalibrar las variables en caso de que el modelo producido no cumpla con los objetivos fijados.
5. **Evolución**: En esta fase se valoran los resultados obtenidos por el modelo verificando su precisión y confiabilidad, además se revisa el proceso, se determinan los próximos pasos y se verifica si el modelo obtenido cumple con los objetivos. Se revisan métricas como precisión, sensibilidad y especificidad para asegurarse de que el modelo sea efectivo y tenga una tasa de error baja.
6. **Despliegue**: Esta etapa abarca la implementación del modelo en un entorno real, su monitoreo y mantenimiento, la documentación del proyecto y la revisión final del proyecto completo.
### Descubrimiento de Conocimiento en Bases de Datos (KDD)
Esta metodología brinda un proceso sistemático para identificar patrones potencialmente útiles y comprensibles en los datos. Este método se utiliza para convertir datos brutos en conocimiento útil mediante un enfoque estructurado. El proceso típico de la minería de datos consta de los siguientes pasos:
1. Selección del conjunto de datos.
2. Análisis de las propiedades de los datos y preprocesamiento.
3. Transformación del conjunto de datos de entrada.
4. Seleccionar y aplicar la técnica de minería de datos, para la ***extracción de patrones*** en los datos.
5. Interpretación y evaluación de datos, muchas veces este paso conlleva la generación de nuevo conocimiento.

A grandes rasgos, el proceso comienza con el proceso de selección, en donde se identifican y recopilan los datos relevantes para el análisis, determinando las fuentes de datos y las variables importantes para el objetivo del proyecto. En algunos casos, también es necesario realizar un muestreo de los registros disponibles.
El siguiente paso es el análisis de las propiedades de los datos, que implica la construcción y revisión de histogramas, diagramas de dispersión con el fin de identificar de valores atípicos y detectar valores nulos. Posteriormente, se procede al preprocesamiento donde se limpian los datos, eliminando el ruido, manejando los valores faltantes y se resuelven las inconsistencias para asegurar la calidad de los datos.
A continuación, se realiza la transformación de los datos de entrada, donde los datos se convierten a un formato adecuado para la minería, incluyendo la reducción de dimensionalidad, normalización y discretización de variables continuas cuando sea necesario. Al final de esta etapa, se obtiene una tabla de datos lista para aplicar la técnica de minería seleccionada.
El siguiente paso consiste en seleccionar y aplicar la técnica de minería de datos más apropiada de acuerdo al conjunto de datos y el objetivo a alcanzar. Esto puede implicar la construcción de un modelo predictivo, de clasificación o de segmentación, utilizando alguna de las siguientes técnicas:
- Visualización.
- Redes Neuronales.
- Regresión (lineal, no lineal, múltiple, logística).
- Inducción (árboles de decisión o modelos basados en reglas).
- Modelos Estadísticos.
- Análisis de Clusters.

El resultado de esta etapa es un ***modelo de conocimiento*** que representa patrones de comportamiento observados o relaciones de asociación entre las variables. Es posible emplear varias técnicas al mismo tiempo para generar distintos modelos, aunque cada técnica puede requerir una transformación deferente de los datos.
Finalmente, se realiza la interpretación y evaluación de los datos, donde los patrones descubiertos son analizados y validados para determinar si representan conocimiento útil y significativo para el objetivo del proyecto. En esta etapa, los resultados se presentan de manera comprensible para los usuarios finales, utilizando visualizaciones y reportes apropiados. Si se han generado varios modelos mediante diferentes técnicas, se deben comparar para seleccionar el que mejor se ajuste al problema. En caso de que ningún modelo cumpla con las expectativas, se deben modificar los pasos anteriores para generar nuevos modelos.
## Minería de Datos Supervisada y No Supervisada
Las técnicas de minería de datos se puede dividir en dos grandes enfoques, el supervisado y el no supervisado. El enfoque supervisado se basa en hacer predicciones a futuro utilizando datos históricos etiquetados, donde las variables objetivo ya están definidas. Un ejemplo sería predecir el riesgo de un cliente para otorgar un préstamo. Por otro lado, el enfoque no supervisado utiliza datos no etiquetados, buscando patrones o estructuras dentro de los datos para organizar y agrupar la información.
Las funciones de minería de datos, son divididas en dos grandes categorías los ***métodos predictivos***, que utilizan variables conocidas para predecir valores futuros o desconocidos de otras variables, y los ***métodos descriptivos***, que buscan patrones interpretables por humanos para describir los datos. Existen varias técnicas para la minería de datos que se clasifican según su función o la clase de aplicación en que se usan. Estas incluyen:
- **Asociación**.
- **Patrones secuenciales o temporales**.
- **Clasificación**.
- **Segmentación**.
- **Regresión**.
- **Detección de desviaciones o anomalías**.

Las ***funciones de asociación*** consisten en reglas que asocian atributos de un conjunto de datos con otros. Estas reglas son una forma eficiente de descubrir relaciones entre elementos dentro de un conjunto de registros utilizando estrategias orientadas a conjuntos. La base para estas funciones es un conjunto de ítems y registros, donde las reglas tienen la siguiente forma lógica: 
$$A_1 ∧ A_2 ∧ \cdots ∧ A_n \rightarrow C$$
Un ejemplo típico en el ámbito de ventas en supermercados podría ser que el 80% de las veces, la compra de papas fritas y maníes implica la compra de cerveza ($\text{Papa Frita} \wedge \text{Maníes} \rightarrow \text{Cervezas}$). El porcentaje asociado con cada regla representa el ***factor de confianza*** de la misma, indicando la probabilidad de que la regla se cumpla en los datos.
Las ***funciones de secuenciación*** analizan registros relacionados para identificar patrones que ocurren repetidamente en un cierto período de tiempo. La clave de estas reglas es el factor temporal, que las diferencia de otras reglas. Un ejemplo en ventas sería descubrir las secuencias de productos que suelen comprarse los clientes antes de adquirir un producto específico.
Las ***funciones de clasificación*** se basa en el aprendizaje supervisado, donde los sistemas aprenden a partir de ejemplos o datos históricos para formular reglas que permitan clasificar los datos en categorías predefinidas. Esto implica mapear un conjunto de atributos a una clase específica utilizando una técnica de clasificación en particular. Existen dos tipos de modelos en la clasificación:
- **Modelo descriptivo**: Describe las características que definen o diferencian clases.
- **Modelo predictivo**: Predice la clase a la que pertenece un objeto desconocido.

Las técnicas de clasificación que pueden utilizar estas funciones incluyen árboles de decisión, clasificación basada en reglas, análisis discriminante, redes neuronales, máquinas de soporte vectorial y redes de Bayes.
Las ***funciones de clustering*** o segmentación consisten en dividir una base de datos en grupos similares según algún criterio o métrica. A diferencia de la clasificación, en clustering no se conocen previamente los grupos o clases, sino que se busca identificarlos a partir de los datos. Existen varios tipos de segmentación, entre los cuales se encuentran:
- **Exclusiva**: Cada objeto se asigna a un único cluster.
- **Solapada**: Un objeto puede pertenecer a varios clusters simultáneamente.
- **Borrosa (Fuzzy)**: Cada objeto pertenece a un cluster con un nivel de membresía entre 0 y 1.
- **Completa**: Todos los objetos son asignados a un cluster.
- **Parcial**: Algunos objetos no se asignan por dudas sobre sus atributos.
- **Particional**: Cada objeto se encuentra en un cluster.
- **Jerárquica**: Los clusters se organizan en un árbol, donde cada nodo es la unión de sus hijos.

Entre las técnicas de segmentación más comunes están:
- **Jerárquico aglomerativo**: Agrupa pares de clusters sucesivamente hasta formar un único cluster. Esta técnica permite visualizar los segmentos mediante un dendrograma.
- **DBSCAN**: Agrupa objetos basándose en la densidad, ignorando regiones de baja densidad (ruido). Esta técnica tiene la ventaja de que no requiere conocer el número de clusters a priori.
- **K-means**: Agrupa objetos en función de su similitud con un centroide. Esta técnica requiere que el número de clusters se define previamente.
- **K-medoid**: Similar a K-means, pero agrupa objetos en función de su similitud con el objeto más representativo.

La ***regresión*** es una técnica que predice el valor de una variable basándose en los valores de otras variables independientes. Por ejemplo, se puede predecir los importes de ventas de nuevos productos en función de los gastos de publicidad, estimar la velocidad del viento considerando la temperatura, humedad y presión atmosférica, o utilizar series de tiempo para pronosticar índices bursátiles.
Por otro lado, la ***detección de desviaciones y anomalías*** tiene como objetivo identificar comportamientos que se desvían significativamente de lo normal. Entre sus aplicaciones comunes están la detección de fraudes con tarjetas de crédito y la identificación de intrusos en redes informáticas. Existen varios esquemas de detección dentro de los cuales se encuentran los basados en gráficos o estadísticas, los basados en distancia y los basados en modelos.

