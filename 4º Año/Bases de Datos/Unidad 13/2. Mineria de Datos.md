La ***minería de datos (DM)*** consiste en la extracción no trivial de conocimiento que reside de manera implícita en los datos. Es un proceso analítico diseñado para explorar grandes cantidades de datos en búsqueda de patrones consistentes y/o relaciones sistemáticas entre variables, y luego validar el hallazgo aplicando los patrones encontrados a nuevos conjuntos de datos.
La información o conocimiento previamente desconocido puede ser de gran utilidad en procesos de toma de decisiones. La minería de datos agrupa un conjunto de técnicas cuyo objetivo es extraer conocimiento procesable que se encuentra implícito en las bases de datos. El proceso típico de la minería de datos consta de los siguientes pasos:
1. Selección del conjunto de datos.
2. Análisis de las propiedades de los datos (Preprocesamiento).
3. Transformación del conjunto de datos de entrada.
4. Seleccionar y aplicar la técnica de minería de datos, para la ***extracción de patrones*** en los datos.
5. Interpretación y evaluación de datos, muchas veces este paso conlleva la generación de nuevo conocimiento.

>[!note] El Procesamiento de los Datos
>Si bien la cantidad de datos puede ser gigantescas, este conjunto en bruto de datos no dice nada por sí mismo, es por eso que resulta conveniente realizar un procesamiento de estos mismos con el fin de generar nueva información que sea de utilidad para la toma de decisiones.

Los datos que conforman los distintos atributos de un registro pueden ser de distintos tipos, cada uno de este tipo de datos tiene un conjunto de propiedades diferentes. Los datos pueden ser:
- **Nominales**: Aquellos datos sobre los cuales solo se pueden realizar operaciones de distinción, como en el caso de los colores, localidades o nombres. 
- **Ordinales**: Datos sobre los cuales se pueden realizar operaciones de distinción y de orden, como es el caso de un ranking o talles.
- **Intervalos**: Datos sobre los que se pueden realizar operaciones de distinción, orden y adición, como por ejemplo fechas, temperatura medida en grados Celsius, entre otras.
- **Proporcionales**: Datos sobre los cuales se pueden realizar operaciones de distinción, adición, orden y multiplicación. Por ejemplo: temperatura en grados Kelvin, longitudes, tiempos o conteos.

>[!tldr] Propiedades de los Datos
>Nos referimos a propiedades como el conjunto de operaciones que se pueden realizar sobre un dato en particular. Dichas operaciones pueden ser clasificadas como:
>- **Distinción**: Abarca las operaciones de igualdad y desigualdad ($= | \neq$).
>- **Orden**: Abarca las operaciones de mayor y menor ($< | >$).
>- **Adición**: Abarca las operaciones de suma y resta ($+ | -$).
>- **Multiplicación**: Abarca las operaciones de multiplicación y división ($* | /$).

A grandes rasgos, el proceso comienza con la selección de las variables objetivo, que son aquellas que se desean predecir, calcular o inferir. A la par, se eligen las variables independientes que serán utilizadas para realizar los cálculos o procesos necesarios. En algunos casos, también es necesario realizar un muestreo de los registros disponibles.
El siguiente paso es el análisis de las propiedades de los datos, que incluye la revisión de histogramas, diagramas de dispersión, la identificación de valores atípicos y la detección de ausencia de datos (valores nulos). Es fundamental también identificar valores erróneos, incorrectos o datos faltantes durante este proceso de preprocesamiento.
Posteriormente, se realiza la transformación del conjunto de datos de entrada, adaptándolo según el análisis previo para prepararlo para la técnica de minería de datos más adecuada al problema. Esto puede implicar cambios en los formatos, escalas u otras características. Al final de esta etapa, se obtiene una tabla de datos lista para aplicar la técnica de minería seleccionada.
El siguiente paso es seleccionar y aplicar la técnica de minería de datos más apropiada. Esto puede implicar la construcción de un modelo predictivo, de clasificación o de segmentación, utilizando alguna de las siguientes técnicas:
- Visualización.
- Redes Neuronales.
- Regresión (lineal, no lineal, múltiple, logística)
- Inducción (árboles de decisión o modelos basados en reglas).
- Modelos Estadísticos.
- Análisis de Clusters.

Con la aplicación de la técnica o técnicas adecuadas se procede a la extracción de patrones. El resultado es un ***modelo de conocimiento*** que representa patrones de comportamiento observados o relaciones de asociación entre las variables del problema. Es posible emplear varias técnicas al mismo tiempo para generar distintos modelos, aunque cada técnica puede requerir una transformación deferente de los datos.
Finalmente, se realiza la interpretación y evaluación de los datos. El modelo obtenido debe validarse para asegurar que las conclusiones son válidas y satisfactorias. Si se han generado varios modelos mediante diferentes técnicas, se deben comparar para seleccionar el que mejor se ajuste al problema. En caso de que ningún modelo cumpla con las expectativas, se deben modificar los pasos anteriores para generar nuevos modelos.
## Data Mining Supervisado y No Supervisado
La minería de datos se puede dividir en dos grandes enfoques el supervisado y el no supervisado. El enfoque supervisado se basa en hacer predicciones a futuro utilizando datos históricos etiquetados, donde las variables objetivo, también llamada target, ya están definidas. Un ejemplo sería predecir el riesgo de un cliente para otorgar un préstamo. Por otro lado, el enfoque no supervisado utiliza datos no etiquetados, buscando patrones o estructuras dentro de los datos para organizar y agrupar la información.
Las funciones de minería de datos, son divididas en dos grandes categorías los ***métodos predictivos***, que utilizan variables conocidas para predecir valores futuros o desconocidos de otras variables, y los ***métodos descriptivos***, que buscan patrones interpretables por humanos para describir los datos. Existen varias técnicas para la minería de datos que se clasifican según su función o la clase de aplicación en que se usan. Estas incluyen:
- **Asociación**.
- **Patrones secuenciales o temporales**.
- **Clasificación**.
- **Segmentación**.
- **Regresión**.
- **Detección de desviaciones o anomalías**.

Las ***funciones de asociación*** consisten en reglas que asocian atributos de un conjunto de datos con otros. Estas reglas son una forma eficiente de descubrir relaciones entre elementos dentro de un conjunto de registros utilizando estrategias orientadas a conjuntos. La base para estas funciones es un conjunto de ítems y registros, donde las reglas tienen la siguiente forma lógica: 
$$A_1 ∧ A_2 ∧ \cdots ∧ A_n \rightarrow C$$

Un ejemplo típico en el ámbito de ventas en supermercados podría ser que el 80% de las veces, la compra de papas fritas y maníes implica la compra de cerveza ($\text{Papa Frita} \wedge \text{Maníes} \rightarrow \text{Cervezaas}$). El porcentaje asociado con cada regla representa el ***factor de confianza*** de la misma, indicando la probabilidad de que la regla se cumpla en los datos.
Las ***funciones de secuenciación*** analizan registros relacionados para identificar patrones que ocurren repetidamente en un cierto período de tiempo. La clave de estas reglas es el factor temporal, que las diferencia de otras reglas. Un ejemplo en ventas sería descubrir las secuencias de productos que suelen comprarse los clientes antes de adquirir un producto específico.
Las ***funciones de clasificación*** se basa en el aprendizaje supervisado, donde los sistemas aprenden a partir de ejemplos o datos históricos para formular reglas que permitan clasificar los datos en categorías predefinidas. Esto implica mapear un conjunto de atributos a una clase específica utilizando una técnica de clasificación en particular. Existen dos tipos de modelos en la clasificación:
- **Modelo descriptivo**: Describe las características que definen o diferencian clases.
- **Modelo predictivo**: Predice la clase a la que pertenece un objeto desconocido.

Las técnicas de clasificación que pueden utilizar estas funciones incluyen árboles de decisión, clasificación basada en reglas, análisis discriminante, redes neuronales, máquinas de soporte vectorial y redes de Bayes.
Las ***funciones de clustering*** o segmentación consisten en dividir una base de datos en grupos similares según algún criterio o métrica. A diferencia de la clasificación, en clustering no se conocen previamente los grupos o clases, sino que se busca identificarlos a partir de los datos. Existen varios tipos de segmentación, entre los cuales se encuentran:
- **Exclusiva**: Cada objeto se asigna a un único cluster.
- **Solapada**: Un objeto puede pertenecer a varios clusters simultáneamente.
- **Borrosa (Fuzzy)**: Cada objeto pertenece a un cluster con un nivel de membresía entre 0 y 1.
- **Completa**: Todos los objetos son asignados a un cluster.
- **Parcial**: Algunos objetos no se asignan por dudas sobre sus atributos.
- **Particional**: Cada objeto se encuentra en un cluster.
- **Jerárquica**: Los clusters se organizan en un árbol, donde cada nodo es la unión de sus hijos.

Entre las técnicas de segmentación más comunes están:
- **Jerárquico aglomerativo**: Agrupa pares de clusters sucesivamente hasta formar un único cluster. Esta técnica permite visualizar los segmentos mediante un dendrograma.
- **DBSCAN**: Agrupa objetos basándose en la densidad, ignorando regiones de baja densidad (ruido). Esta técnica tiene la ventaja de que no requiere conocer el número de clusters a priori.
- **K-means**: Agrupa objetos en función de su similitud con un centroide. Esta técnica requiere que el número de clusters se define previamente.
- **K-medoid**: Similar a K-means, pero agrupa objetos en función de su similitud con el objeto más representativo.

>[!tldr] Regresión y Detección de Desviaciones y Anomalías
>La ***regresión*** es una técnica que predice el valor de una variable basándose en los valores de otras variables independientes. Por ejemplo, se puede predecir los importes de ventas de nuevos productos en función de los gastos de publicidad, estimar la velocidad del viento considerando la temperatura, humedad y presión atmosférica, o utilizar series de tiempo para pronosticar índices bursátiles.
>Por otro lado, la ***detección de desviaciones y anomalías*** tiene como objetivo identificar comportamientos que se desvían significativamente de lo normal. Entre sus aplicaciones comunes están la detección de fraudes con tarjetas de crédito y la identificación de intrusos en redes informáticas. Existen varios esquemas de detección dentro de los cuales se encuentran los basados en gráficos o estafísticas, los basados en distancia y los basados en modelos.

