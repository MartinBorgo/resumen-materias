El diseño de las bases de datos relacionales requiere que encontremos una “buena” colección de esquemas de relación. Un mal diseño podría introducir repeticiones de información, potenciales inconsistencias, anomalías en la modificación, anomalías en la inserción y eliminación e incluso una imposibilidad de representar determinada información.
El objetivo principal del diseño relacional, es generar un conjunto de esquemas relacionales que permita:

1. Almacenar la información sin redundancias innecesarias.
2. Asegurar que estén representadas las relaciones entre los atributos.
3. Recuperar fácilmente esa información.
4. Facilitar el chequeo de actualizaciones para la violación de restricciones de integridad de la base de datos.

>[!tldr] Notación Utilizada en el Diseño Relacional
>Al igual que muchas otras cosas, el diseño relacional esta respaldado por una fuerte teoría matemática, para este casos se utilizara la siguiente notación.
>- **Atributos**: Se utiliza las primeras letras del abecedario en mayúscula ($A$, $B$, $C$, $A_1$, $A_2$).
>- **Conjuntos de Atributos**: Se utilizan las últimas letras del abecedario en mayúscula ($U$, $V$, $W$, $X$, $Y$, $X_1$, $X_2$).
>- **Tuplas**: Se utilizan las últimas letras del abecedario en minuscula. Además $t[X]$ se refiere a los valores de $X$ en la tupla $t$.
>- **Valores de atributos**: Se utiliza las primeras letras del abecedario en minúscula.
>- **Esquema de las Relaciones**: Se suele utilizar normalmente las letras $S$ y $R$.
>- **Relaciones**: Se suelen utilizar las letras $r$ y $s$ en minúscula.
>- **Claves**: Se utiliza la letra $K$ más un subindice para especificar las claves de las relaciones.

La forma más normal de poseer un buen diseño es a través de la descomposición de los esquemas. Dada una relación $R$, nosotros podemos descomponer esta relación en $R_1$ y $R_2$ siempre y cuando se cumpla que $R_1 \cup R_2 = R$, es decir la unión de ambos esquemas posee todos los atributos que su esquema original.
Cuando descomponemos un relación, lo que tenemos que conseguir es lograr un join sin perdidas. Para explicar mejor este concepto supongamos que tenemos un esquema $R$ que fue dividido en $R_1$ y $R_2$, un join si perdidas se da cuando al realizar la operación $R_1 \Join R_2$ obtenemos exactamente la misma cantidad de elementos que estaban en $R$. Véase el ejemplo:

![[join-sin-perdida.png]]

En este caso no se cumple la condición de join sin perdida, ya que al realizar la reunión entre los esquemas $R_1$ y $R_2$, se obtiene una tupla extra que no forma parte de la relación $r$.
Las metas del diseño relacional en este caso es idear una teoría para decidir de manera automática si un esquema de relación $R$ está en una ***buena forma***. En caso de que este no lo este, se debe descomponerlo en una serie de conjuntos de sub-esquemas $\{R_1, R_2, ... , R_n\}$ tal que:

1. Cada sub-esquema de la relación $R_i$ está en buena forma.
2. La descomposición sea de join sin perdida.

La teoría se basa en las dependencias funcionales y las dependencias multivaluadas.

## Dependencias Funcionales

Las dependencias funcionales son restricciones del conjunto de relaciones legales que describen una relación entre dos conjuntos de atributos en una tabla. Una dependencia funcional indica que si conoces el valor de un conjunto de atributos, puedes determinar de manera unívoca el valor del resto de los atributos. Una dependencia funcional es un tipo de
restricción que constituye una generalización del concepto de clave.
Considere un esquema de relación $R$, donde $X \subseteq R$ e $Y \subseteq R$, la dependencia funcional $X \rightarrow Y$, que si lee como $X$ determina a $Y$, se cumple que para todos los pares de tuplas $t_1$ y $t_2$ en la relación $r(R)$ en el esquema $R$ -> $t_1[X] = t_2[X] \Rightarrow t_1[Y] = t_2[Y]$.

>[!tldr] Claves Candidatas y Super Claves
>Se dice que $K$ es una super clave de para el esquema de $R$ si $K \rightarrow R$, es decir, que los valores de $K$ son suficientes para identificar de manera unívoca las tupals en $R$.
>Por otro lado, $K$ es una clave candidata de $R$ si $K \rightarrow R \land \neg \exists X \subset K / X \rightarrow R$. Es decir, no existe un valor del subconjunto $X$ que pueda determinar $R$.

Las dependencias funcionales nos permiten expresar restricciones que no pueden expresarse usado superclaves.

### Uso de las Dependencias Funcionales

Las dependencias funcionales pueden ser utilizadas para realizar las siguientes cuestiones:

- Testear relaciones para ver si son legales para un determinado conjunto de dependencias funcionales dados. Si una relación $r$ es legal para un conjunto $F$ de dependencias funcionales se dice que $r$ satisface a $F$.
- Especificar restricciones sobre el conjunto de relaciones legales. Se dice que $F$ se cumple en $R$ si todas las relaciones legales en $R$ satisfacen el conjunto $F$ de dependencias funcionales.

Puede que una instancia específica de un esquema, pueda satisfacer una dependencia funcional aún cunado la dependencia funcional no se cumple para todas las instancias legales, es decir, puede haber al menos una instancia que cumpla con las dependencias funcionales mientras que el resto de las instancias no.

>[!tldr] Dependencias Funcionales Triviales
>Un dependencia funcional se considera trivial cuando esta es satisfecha por todas las instancias de una relación. Por ejemplo:
>- $nombre\_cliente, numero\_prestamos \rightarrow nombre\_cliente$: Esta dependencia se considera trivial, ya que número de prestamos y el nombre de cliente siempre va a determinarse el nombre del cliente.
>- $nombre\_cliente \rightarrow nombre\_cliente$: Es trivial, ya que el mismo nombre siempre se puede determinar a si mismo.
>
>De manera más general, decimos que $X \rightarrow Y$ es trivial si $Y \subseteq X$.

### Clausura o Cierre de un Conjunto de Dependencias Funcionales.

La **clausura de un conjunto de Dependencias Funcionales**, denotada por $F^+$, es el conjunto de todas las dependencias funcionales que se pueden inferir lógicamente a partir de un conjunto dado $F$ de dependencias funcionales. Esto incluye todas las dependencias funcionales originales en $F$ más todas aquellas que se pueden derivar utilizando los axiomas de Armstrong.
Los ***axiomas de Armstrong*** son reglas básicas utilizadas para derivar todas las posibles dependencias funcionales que se pueden inferir de un conjunto dado de dependencias funcionales. Estos axiomas son:

1. **Reflexividad (Trivialidad)**: Si $Y \subseteq X \Rightarrow X \rightarrow Y$. Esto es bastante directo; si tienes un conjunto de atributos $X$, entonces esos atributos pueden determinar cualquier subconjunto Y de sí mismos.
2. **Aumento**: Si $X \rightarrow Y \Rightarrow ZX \rightarrow ZY$. Esto significa que si una dependencia funciona para un conjunto de atributos, se le agrega más atributos a ambos lados de la dependencia, esta seguirá determinando al otro conjunto de atributos.   
3. **Transitividad**: Si $X \rightarrow Y \land Y \rightarrow Z \Rightarrow X \rightarrow Z$. Si un conjunto de atributos puede determinar un segundo conjunto, y ese segundo conjunto puede determinar un tercero, entonces el primer conjunto también puede determinar el tercero.

Estas axiomas se dicen que son sensatos, porque no generan dependencias funcionales incorrectas y completas ya que estas reglas te permiten inferir todas las dependencias funcionales de un conjunto cualquiera $F$ de dependencias funcionales.
Se puede simplificar el calculo de $F^+$ agregando las siguientes reglas adicionales:

- **Union**: Si $X \rightarrow Y \land X \rightarrow Z \Rightarrow X \rightarrow YZ$. Si un conjunto de atributos $X$ determina $Y$ y también determina $Z$, entonces $X$ determina la combinación de $Y$ y $Z$. Esta regla permite combinar dependencias funcionales que comparten su lado izquierdo.
- **Descomposición**: Si $X \rightarrow YZ \Rightarrow X \rightarrow Y \land X \rightarrow Z$. Si un conjunto de atributos $X$ determina un conjunto combinado de atributos $YZ$, entonces puedes separar ese conjunto y afirmar que $X$ determina $Y$ y $X$ determina $Z$ por separado.
- **Pseudo Transición**: Si $X \rightarrow Y \land ZY \rightarrow W \Rightarrow ZX \rightarrow W$. Si un conjunto de atributos $X$ determina otro conjunto $Y$, y una combinación de $Y$ con otro conjunto $Z$ determina un tercer conjunto $W$, entonces la combinación de $Z$ con $X$ también determinará $W$.

Estas reglas adicionales pueden ser inferidas aplicando una combinación de los axiomas de Armstrong.

### Clausura de un Conjunto de Atributos

Dado un conjunto de atributos $X$, se define la clausura de $X$ en $F$ como $X_F^+$. Esta clausura representa todos los atributos que pueden ser determinados funcionalmente por $X$ dado el conjunto de dependencias funcionales $F$, tal que $X \rightarrow Y \in F^+ \Rightarrow Y \subseteq X^+$. Esta clausura se puede calcular a través del siguiente algoritmo:

![[calc-causura-atributo.png]]

La clausura de de los conjuntos de atributos se utilizan para:

- Encontrar super claves. Para verificar si $X$ es una super clave, se calcula $X^+$, y se chequea si $X^+$ contiene a todos los atributos de $R$.
- Verificar dependencias funcionales. Para chequear si una dependencia funcional $X \rightarrow Y$ se cumple, se puede chequear si $Y \subseteq X^+$. Se calcula $X^+$ y se chequea si $Y$ forma parte. Esto es de mucha utilidad, ya que es una forma fácil, útil y poco costosa de realizar una verificación.
- Calcular $F^+$. Para cada $X \subseteq R$, encontrar su clausura $X^+$, y para cada $Y \subseteq X^+$, obtenemos una dependencia funcional $X \rightarrow Y$.

### Coberturas Canónicas

Puede que un conjunto de dependencias funcionales contenga dependencias redundantes que se pueden inferir a partir de otras dependencias o incluso que existan dependencias funcionales tengan partes redundantes. Una ***cobertura canónica*** de $F$ es un conjunto minimal de dependencias funcionales equivalente a $F$, que no tiene dependencias redundantes o partes de una dependencia redundante.
Dos conjuntos de dependencias son equivalentes si $F_1^+ = F_2^+ \Rightarrow F_1 \equiv F_2$. Pero como no es conveniente calcular las clausuras para cada $F_i$, se puede chequear las equivalencias de las siguiente manera $F_1 \vdash F_2 \land F_2 \vdash F_1 \Rightarrow F_1 \equiv F_2$, es decir, todas las dependencias funcionales de $F_2$ pueden ser inferidas a partir de $F_1$ y viceversa, si esto es posible ambos entonces $F_1$ es una cobertura canónica de $F_2$.

>[!tldr] Atributos Extraños
>Un **atributo extraño** en una dependencia funcional es un atributo que aunque esté presente en el lado izquierdo o derecho de la dependencia, no es necesario para establecer la relación de dependencia. En otras palabras, el atributo puede ser eliminado sin afectar la validez de la dependencia funcional.
>- **Atributos extraños a Izquierda**: Dada una dependencia funcional $X \rightarrow Y$ en un conjunto de dependencias $F$. Un atributo $C$ es extraño en $X$ si $C \in X$ y aún puedes deducir $Y$ de $X$ sin $C$. Es decir, $(X -C) \rightarrow Y$. Formalmente se debe cumplir que $F \vdash F' = (F - \{X \rightarrow Y\}) \cup \{(X - C) \rightarrow Y\}$.
>- **Atributos Extraños a Derecha**: Un atributo $C$ es extraño en $Y$ si $C \in Y$ y eliminar $C$, la nueva dependencia $X \rightarrow (Y − C)$ todavía permite inferir $F$. Formalmente se debe cumplir que $F' = F - \{X \rightarrow Y\} \cup \{X \rightarrow (Y - C)\} \vdash F$.
>
>En todos los casos mencionados, la inferencia de dependencias funcionales en dirección opuesta es directa, porque una dependencia funcional que impone condiciones más estrictas incluye naturalmente aquellas que son menos estrictas.
>
>Se puede verificar si un atributo es extraño tanto por izquierda como por derecha de la siguiente manera:
>
>- Para testear si el atributo $C \in X$ es extraño en $X$, primero se calcula $(\{\} - C)^+$ usando las dependencias del conjunto $F$, luego se chequea si esta clausura contiene a $Y$, si es así $C$ es extraño en $X$.
>- Para testear si el atributo $C \in Y$ es extraño en $Y$, primero se calcula la clausura $X^+$ usando solo las dependencias en $F' = F - \{X \rightarrow Y\} \cup \{X \rightarrow (Y - C)\}$, luego se chequea si $X^+$ en $F'$ contiene a $C$, si es así, $C$ es extraño.

Una cobertura canónica para $F$ es un conjunto de dependencias $F_C$ tal que, $F \vdash F_C \land F_C \vdash F$. Además ninguna dependencia funcional en $F_C$ contiene atributos extraños  y cada lado izquierdo de las dependencias funcionales en $F_C$ es único.
